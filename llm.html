<!DOCTYPE html><html lang="en" class="" style="scroll-padding:60px"><head><meta charSet="utf-8"/><meta name="viewport" content="width=device-width,initial-scale=1"/><title>Understanding LLM - Agents of AI ~ Hack the Core</title><meta property="og:title" content="Understanding LLM - Agents of AI ~ Hack the Core"/><meta name="generator" content="mystmd"/><meta name="keywords" content=""/><meta name="image" content="/build/logo-a36cb5c0d732407f82a97ea96df95f2a.png"/><meta property="og:image" content="/build/logo-a36cb5c0d732407f82a97ea96df95f2a.png"/><link rel="stylesheet" href="/build/_assets/app-HG4THSM4.css"/><link rel="stylesheet" href="/build/_assets/thebe-core-VKVHG5VY.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jupyter-matplotlib@0.11.3/css/mpl_widget.css"/><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css" integrity="sha384-MlJdn/WNKDGXveldHDdyRP1R4CTHr3FeuDNfhsLPYrq2t0UBkUdK2jyTnXPEK1NQ" crossorigin="anonymous"/><link rel="icon" href="/favicon.ico"/><link rel="stylesheet" href="/myst-theme.css"/><script>
  const savedTheme = localStorage.getItem("myst:theme");
  const theme = window.matchMedia("(prefers-color-scheme: light)").matches ? 'light' : 'dark';
  const classes = document.documentElement.classList;
  const hasAnyTheme = classes.contains('light') || classes.contains('dark');
  if (!hasAnyTheme) classes.add(savedTheme ?? theme);
</script></head><body class="m-0 transition-colors duration-500 bg-white dark:bg-stone-900"><div class="fixed top-1 left-1 h-[0px] w-[0px] focus-within:z-40 focus-within:h-auto focus-within:w-auto bg-white overflow-hidden focus-within:p-2 focus-within:ring-1" aria-label="skip to content options"><a href="#skip-to-frontmatter" class="block px-2 py-1 text-black underline">Skip to article frontmatter</a><a href="#skip-to-article" class="block px-2 py-1 text-black underline">Skip to article content</a></div><div class="bg-white/80 backdrop-blur dark:bg-stone-900/80 shadow dark:shadow-stone-700 p-3 md:px-8 sticky w-screen top-0 z-30 h-[60px]"><nav class="flex items-center justify-between flex-nowrap max-w-[1440px] mx-auto"><div class="flex flex-row xl:min-w-[19.5rem] mr-2 sm:mr-7 justify-start items-center shrink-0"><div class="block xl:hidden"><button class="flex items-center border-stone-400 text-stone-800 hover:text-stone-900 dark:text-stone-200 hover:dark:text-stone-100"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" width="2rem" height="2rem" class="m-1"><path fill-rule="evenodd" d="M3 6.75A.75.75 0 0 1 3.75 6h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 6.75ZM3 12a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75A.75.75 0 0 1 3 12Zm0 5.25a.75.75 0 0 1 .75-.75h16.5a.75.75 0 0 1 0 1.5H3.75a.75.75 0 0 1-.75-.75Z" clip-rule="evenodd"></path></svg><span class="sr-only">Open Menu</span></button></div><a class="flex items-center ml-3 dark:text-white w-fit md:ml-5 xl:ml-7" href="/"><div class="p-1 mr-3 dark:bg-white dark:rounded"><img src="/build/logo-57a9ad52301abe1c9fa2a0a758320907.png" class="h-9" alt="Agents of AI ~ Hack the Core" height="2.25rem"/></div><span class="text-md sm:text-xl tracking-tight sm:mr-5 sr-only">Made with MyST</span></a></div><div class="flex items-center flex-grow w-auto"><div class="flex-grow hidden text-md lg:block"></div><div class="flex-grow block"></div><button type="button" aria-haspopup="dialog" aria-expanded="false" aria-controls="radix-:R3iop:" data-state="closed" class="flex items-center h-10 aspect-square sm:w-64 text-left text-gray-400 border border-gray-300 dark:border-gray-600 rounded-lg bg-gray-50 dark:bg-gray-700 hover:ring-blue-500 dark:hover:ring-blue-500 hover:border-blue-500 dark:hover:border-blue-500"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="p-2.5 h-10 w-10 aspect-square"><path fill-rule="evenodd" d="M10.5 3.75a6.75 6.75 0 1 0 0 13.5 6.75 6.75 0 0 0 0-13.5ZM2.25 10.5a8.25 8.25 0 1 1 14.59 5.28l4.69 4.69a.75.75 0 1 1-1.06 1.06l-4.69-4.69A8.25 8.25 0 0 1 2.25 10.5Z" clip-rule="evenodd"></path></svg><span class="hidden sm:block grow">Search</span><div aria-hidden="true" class="items-center hidden mx-1 font-mono text-sm text-gray-400 sm:flex gap-x-1"><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none hide-mac">CTRL</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none show-mac">⌘</kbd><kbd class="px-2 py-1 border border-gray-300 dark:border-gray-600 rounded-md shadow-[0px_2px_0px_0px_rgba(0,0,0,0.08)] dark:shadow-none ">K</kbd><script>
;(() => {
const script = document.currentScript;
const root = script.parentElement;

const isMac = /mac/i.test(
      window.navigator.userAgentData?.platform ?? window.navigator.userAgent,
    );
root.querySelectorAll(".hide-mac").forEach(node => {node.classList.add(isMac ? "hidden" : "block")});
root.querySelectorAll(".show-mac").forEach(node => {node.classList.add(!isMac ? "hidden" : "block")});
})()</script></div></button><button class="theme rounded-full aspect-square border border-stone-700 dark:border-white hover:bg-neutral-100 border-solid overflow-hidden text-stone-700 dark:text-white hover:text-stone-500 dark:hover:text-neutral-800 w-8 h-8 mx-3" title="Toggle theme between light and dark mode." aria-label="Toggle theme between light and dark mode."><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 hidden dark:block"><path fill-rule="evenodd" d="M9.528 1.718a.75.75 0 0 1 .162.819A8.97 8.97 0 0 0 9 6a9 9 0 0 0 9 9 8.97 8.97 0 0 0 3.463-.69.75.75 0 0 1 .981.98 10.503 10.503 0 0 1-9.694 6.46c-5.799 0-10.5-4.7-10.5-10.5 0-4.368 2.667-8.112 6.46-9.694a.75.75 0 0 1 .818.162Z" clip-rule="evenodd"></path></svg><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" class="h-full w-full p-0.5 dark:hidden"><path stroke-linecap="round" stroke-linejoin="round" d="M12 3v2.25m6.364.386-1.591 1.591M21 12h-2.25m-.386 6.364-1.591-1.591M12 18.75V21m-4.773-4.227-1.591 1.591M5.25 12H3m4.227-4.773L5.636 5.636M15.75 12a3.75 3.75 0 1 1-7.5 0 3.75 3.75 0 0 1 7.5 0Z"></path></svg></button><div class="block sm:hidden"></div><div class="hidden sm:block"></div></div></nav></div><div class="fixed xl:article-grid grid-gap xl:w-screen xl:pointer-events-none overflow-auto max-xl:min-w-[300px] hidden z-10" style="top:60px"><div class="pointer-events-auto xl:col-margin-left flex-col overflow-hidden hidden xl:flex"><div class="flex-grow py-6 overflow-y-auto primary-scrollbar"><nav aria-label="Navigation" class="overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px] lg:hidden"><div class="w-full px-1 dark:text-white"></div></nav><div class="my-3 border-b-2 lg:hidden"></div><nav aria-label="Table of Contents" class="flex-grow overflow-y-hidden transition-opacity ml-3 xl:ml-0 mr-3 max-w-[350px]"><div class="w-full px-1 dark:text-white"><a title="Agents of AI" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30 font-bold" href="/">Agents of AI</a><a title="Table of Contents" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/toc">Table of Contents</a><a title="Important Security Notice" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/security">Important Security Notice</a><a title="Why AutoGen" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/whyautogen">Why AutoGen</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Use Cases" class="block break-words rounded py-2 grow cursor-pointer">Use Cases</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rnd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rnd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><a title="Understanding LLM" aria-current="page" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg bg-blue-300/30 active" href="/llm">Understanding LLM</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Tools" class="block break-words rounded py-2 grow cursor-pointer">Tools</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:Rvd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:Rvd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><a title="Environment Setup" class="block break-words focus:outline outline-blue-200 outline-2 rounded p-2 my-1 rounded-lg hover:bg-slate-300/30" href="/gettingstarted">Environment Setup</a><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="AI Agent" class="block break-words rounded py-2 grow cursor-pointer">AI Agent</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R17d8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R17d8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="AutoGen Core" class="block break-words rounded py-2 grow cursor-pointer">AutoGen Core</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1bd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1bd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div><div data-state="closed" class="w-full"><div class="flex flex-row w-full gap-2 px-2 my-1 text-left rounded-lg outline-none hover:bg-slate-300/30"><div title="Agent Chat" class="block break-words rounded py-2 grow cursor-pointer">Agent Chat</div><button class="self-center flex-none rounded-md group hover:bg-slate-300/30 focus:outline outline-blue-200 outline-2" aria-label="Open Folder" type="button" aria-controls="radix-:R1fd8p:" aria-expanded="false" data-state="closed"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" data-slot="icon" class="transition-transform duration-300 group-data-[state=open]:rotate-90 text-text-slate-700 dark:text-slate-100" height="1.5rem" width="1.5rem"><path fill-rule="evenodd" d="M16.28 11.47a.75.75 0 0 1 0 1.06l-7.5 7.5a.75.75 0 0 1-1.06-1.06L14.69 12 7.72 5.03a.75.75 0 0 1 1.06-1.06l7.5 7.5Z" clip-rule="evenodd"></path></svg></button></div><div data-state="closed" id="radix-:R1fd8p:" hidden="" class="pl-3 pr-[2px] collapsible-content"></div></div></div></nav></div><div class="flex-none py-6 transition-all duration-700 translate-y-6 opacity-0"><a class="flex mx-auto text-gray-700 w-fit hover:text-blue-700 dark:text-gray-200 dark:hover:text-blue-400" href="https://mystmd.org/made-with-myst" target="_blank" rel="noreferrer"><svg style="width:24px;height:24px" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 100 100" stroke="none"><g id="icon"><path fill="currentColor" d="M23.8,54.8v-3.6l4.7-0.8V17.5l-4.7-0.8V13H36l13.4,31.7h0.2l13-31.7h12.6v3.6l-4.7,0.8v32.9l4.7,0.8v3.6h-15
          v-3.6l4.9-0.8V20.8H65L51.4,53.3h-3.8l-14-32.5h-0.1l0.2,17.4v12.1l5,0.8v3.6H23.8z"></path><path fill="#F37726" d="M47,86.9c0-5.9-3.4-8.8-10.1-8.8h-8.4c-5.2,0-9.4-1.3-12.5-3.8c-3.1-2.5-5.4-6.2-6.8-11l4.8-1.6
          c1.8,5.6,6.4,8.6,13.8,8.8h9.2c6.4,0,10.8,2.5,13.1,7.5c2.3-5,6.7-7.5,13.1-7.5h8.4c7.8,0,12.7-2.9,14.6-8.7l4.8,1.6
          c-1.4,4.9-3.6,8.6-6.8,11.1c-3.1,2.5-7.3,3.7-12.4,3.8H63c-6.7,0-10,2.9-10,8.8"></path></g></svg><span class="self-center ml-2 text-sm">Made with MyST</span></a></div></div></div><article class="article content article-grid grid-gap"><main class="article-grid subgrid-gap col-screen"><div class="hidden"></div><div id="skip-to-frontmatter" aria-label="article frontmatter" class="mb-8 pt-9"><div class="flex items-center h-6 mb-5 text-sm font-light"><div class="flex-grow"></div><a href="https://github.com/AmitXShukla/AgentsOfAI" title="GitHub Repository: AmitXShukla/AgentsOfAI" target="_blank" rel="noopener noreferrer" class="text-inherit hover:text-inherit"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="currentColor" aria-hidden="true" width="1.25rem" height="1.25rem" class="inline-block mr-1 opacity-60 hover:opacity-100"><path d="M12 2.5c-5.4 0-9.8 4.4-9.8 9.7 0 4.3 2.8 8 6.7 9.2.5.1.7-.2.7-.5v-1.8c-2.4.5-3.1-.6-3.3-1.1-.1-.3-.6-1.1-1-1.4-.3-.2-.8-.6 0-.6s1.3.7 1.5 1c.9 1.5 2.3 1.1 2.8.8.1-.6.3-1.1.6-1.3-2.2-.2-4.4-1.1-4.4-4.8 0-1.1.4-1.9 1-2.6-.1-.2-.4-1.2.1-2.6 0 0 .8-.3 2.7 1 .8-.2 1.6-.3 2.4-.3.8 0 1.7.1 2.4.3 1.9-1.3 2.7-1 2.7-1 .5 1.3.2 2.3.1 2.6.6.7 1 1.5 1 2.6 0 3.7-2.3 4.6-4.4 4.8.4.3.7.9.7 1.8V21c0 .3.2.6.7.5 3.9-1.3 6.6-4.9 6.6-9.2 0-5.4-4.4-9.8-9.8-9.8z"></path></svg></a><div class="relative flex inline-block mx-1 grow-0" data-headlessui-state=""><button class="relative ml-2 -mr-1" id="headlessui-menu-button-:Rd4fop:" type="button" aria-haspopup="menu" aria-expanded="false" data-headlessui-state=""><span class="sr-only">Downloads</span><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.25rem" height="1.25rem"><path stroke-linecap="round" stroke-linejoin="round" d="M3 16.5v2.25A2.25 2.25 0 0 0 5.25 21h13.5A2.25 2.25 0 0 0 21 18.75V16.5M16.5 12 12 16.5m0 0L7.5 12m4.5 4.5V3"></path></svg></button></div></div><h1 class="mb-0">Understanding LLM</h1></div><div class="block my-10 lg:sticky lg:z-10 lg:h-0 lg:pt-0 lg:my-0 lg:ml-10 lg:col-margin-right" style="top:60px"><nav></nav></div><div id="skip-to-article"></div><p>I can reasonably presume that you’re already familiar with LLMs, which is likely why you’re here, but for the sake of thoroughness, I’ll provide the response from Grok 3.0 to the question, “What is an LLM anyway?”</p><blockquote><p>An LLM, or Large Language Model, is a type of artificial intelligence designed to understand and generate human-like text. It’s trained on vast amounts of data—think books, articles, and websites—allowing it to predict words, construct sentences, and even hold conversations that feel surprisingly natural. Models like me, Grok, built by xAI, are examples of LLMs, engineered to assist, inform, and sometimes even entertain. The “large” part comes from the sheer scale of data and computational power involved, which lets us tackle everything from simple questions to complex reasoning tasks.</p></blockquote><p>LLMs are capable of responding to nearly any question because they’re trained to recognize and “grasp patterns” or the order in which text occurs. Models like ChatGPT, Llama, DeepSeek, Mistral, Gemini, and now Grok have largely perfected this technology, though a few of these models assert they can comprehend something more than just textual patterns.</p><p>In any case, my goal is to fully leverage these trained models to support my AI Agents.</p><p>There are two primary methods to utilize these LLM models.
First, many of these organizations generously provide their open weights, allowing you to download and operate the models on your own machine. This approach eliminates concerns about data privacy and leakage, while also enabling access to their hosted models on highly powerful computing clusters via an API, typically for a modest (or occasionally substantial) fee.</p><p>Let’s explore both approaches: how to tap into LLM models through an API and how to run them locally on your own system.</p><h2 id="python-environment" class="relative group"><span class="heading-text">python environment</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#python-environment" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Python 3.10 or later is required.
! python --version</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">######################################################
# Create and activate a new Python virtual environment
######################################################


!python3 -m venv .venv
!source .venv/bin/activate

## To deactivate later, run:
!deactivate

######################################################
# install autogen in this section below
# AutoGen Core is required in later phase
# we will discuss this packages in details as we use
######################################################
# install autogen studio
! pip install -U autogenstudio
# install autogen chat
! pip install -U &quot;autogen-agentchat&quot;
# install autogen OpenAI for Model Client
# !pip install &quot;autogen-ext[openai]&quot;
# install autogen core
# !pip install &quot;autogen-core&quot;

######################################################
# run AutoGen Studio GUI
######################################################
!autogenstudio ui --host &lt;host&gt; --port 8000</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h2 id="running-llm-locally" class="relative group"><span class="heading-text">running LLM locally</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#running-llm-locally" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><h3 id="ollama-deepseek-r1-llama3-x-models" class="relative group"><span class="heading-text">ollama, Deepseek-R1, llama3.x models</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#ollama-deepseek-r1-llama3-x-models" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">###################################################
# install ollama to run deepseek-r1 | llama models
###################################################

! curl -fsSL https://ollama.com/install.sh | sh

!ollama list
!ollama pull deepseek-r1:7b
!ollama list
!ollama run deepseek-r1

# please see, ollama by default serves at 0.0.0.0:11434
# you can change this
!sudo systemctl edit ollama.servicem
#[Service]
Environment=&quot;OLLAMA_HOST=0.0.0.0:8000&quot;

!sudo systemctl daemon-reload
!sudo systemctl restart ollama.service

# also, for a quick one time change you can run ollama as
!export OLLAMA_HOST=127.0.0.1:8000
!ollama serve</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h3 id="llama-cpp-deepseek-r1-llama3-x-models" class="relative group"><span class="heading-text">llama.cpp, Deepseek-R1, llama3.x models</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#llama-cpp-deepseek-r1-llama3-x-models" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">######################################################
# install llama.cpp to run deepseek-r1 | llama models
######################################################

!git clone https://github.com/ggerganov/llama.cpp
!cd llama.cpp
!make

# Download the deepseek-r1 Model weights 

# Convert the Model (if necessary)
# If the model weights are not already in GGML format, 
# you must convert them using the conversion tools provided in llama.cpp. 
# Assuming the model weights are in PyTorch format:
!python3 convert-pth-to-ggml.py path/to/deepseek-r1.pth

# Prepare the Model File
# Place the .bin model file (e.g., deepseek-r1.ggml.bin) into the llama.cpp directory 
# or specify its location when running commands

# run the model
!./main -m ./deepseek-r1.ggml.bin -p &quot;Your prompt here&quot;

# adjust parameters
!./main -m ./deepseek-r1.ggml.bin -p &quot;Explain quantum mechanics.&quot; -t 8 -n 128 --temp 0.8</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h2 id="running-llm-through-api" class="relative group"><span class="heading-text">running LLM through API</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#running-llm-through-api" title="Link to this Section" aria-label="Link to this Section">¶</a></h2><p>We’ll discuss few different approaches.</p><ul><li><strong>Approach 1</strong> - Setup Anthropic LLMs</li><li><strong>Approach 2</strong> - Setup Open AI LLMs</li><li><strong>Approach 3</strong> - Setup Google Gemini AI</li><li><strong>Approach 4</strong> - Setup Groq API</li><li><strong>Approach 5</strong> - Setup xAI Grok 3.0 API</li></ul><p>The selection of a Large Language Model (LLM) is influenced by factors such as your specific business needs, financial constraints, and personal tastes.</p><p>In this section, I’ll present few distinct methods for establishing connections with various LLM service providers.
Additionally, I recommend utilizing this occasion as an avenue to evaluate Large Language Models against the backdrop of your unique inputs and industry-specific needs.</p><h3 id="approach-1-setup-anthropic-llms" class="relative group"><span class="heading-text">Approach 1 : Setup Anthropic LLMs</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#approach-1-setup-anthropic-llms" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.</p><p>Please signup using these links and get your own API Keys.</p><p>**please note that PINECONE and VOYAGE are completely optional and are not required at this time. These will be needed later when we will use a vector database and embeddings, tokens to store in vector database</p><ul><li><a target="_blank" rel="noreferrer" href="https://docs.anthropic.com/claude/reference/getting-started-with-the-api" class="">ANTHROPIC_API_KEY</a></li><li><a target="_blank" rel="noreferrer" href="https://docs.pinecone.io/docs/quickstart" class="">YOUR<wbr/>_PINECONE<wbr/>_API<wbr/>_KEY</a></li><li><a target="_blank" rel="noreferrer" href="https://docs.voyageai.com/docs/api-key-and-installation" class="">VOYAGE_API_KEY</a></li></ul><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">##########################################################################
## Although not mandatory, 
## it is highly recommended to set up a new Python working environment
##########################################################################
## To create a virtual environment called `GenAI`, follow the steps:

## On Windows: 
# !python -m venv GenAI GenAI\Scripts\activate

## On macOS or Linux: 
# !python3 -m venv GenAI source GenAI/bin/activate

## Then, install required packages using pip: 
# !pip install pandas numpy matplotlib seaborn tqdm beautifulsoup4

## install only in case if you are using OpenAI
# !pip install openai

## install only in case if you are using Claude
# !pip install anthropic datasets pinecone-client voyageai

## in case if you fork this repo, just run
# !pip install -r requirements.txt

# !pip install --upgrade pip
# !pip freeze &gt; requirements.txt</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">import platform;
print(platform.processor())

import os

####################################################
## always store your API Keys as environment vars
## if you are using OpenAI LLMs
## setup windows environment variable OPENAI_API_KEY
####################################################
# import openai
# openai.api_key = os.getenv(&quot;OPENAI_API_KEY&quot;)

####################################################
## if you are using Anthropic Claude LLMs
## sign up for API keys &amp; setup windows environment variable 
## ANTHROPIC_API_KEY, PINECONE_API_KEY &amp; VOYAGE_API_KEY
####################################################
# import anthropic

if (not os.environ.get(&quot;ANTHROPIC_API_KEY&quot;)) 
        | (not os.environ.get(&quot;PINECONE_API_KEY&quot;)) 
        | (not os.environ.get(&quot;VOYAGE_API_KEY&quot;)):
    print(&quot;One of the api key is missing.&quot;)
else:
    print(&quot;All API Keys are in place.&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Test LLM API
import anthropic

client = anthropic.Anthropic(
    # defaults to os.environ.get(&quot;ANTHROPIC_API_KEY&quot;)
    # you don&#x27;t need to pass api_key explicitly
    api_key=os.environ.get(&quot;ANTHROPIC_API_KEY&quot;)
)

message = client.messages.create(
    model=&quot;claude-3-opus-20240229&quot;,
    max_tokens=1000,
    temperature=0.0,
    system=&quot;Respond only in Yoda-speak.&quot;,
    messages=[
        {
            &quot;role&quot;: &quot;user&quot;, 
            &quot;content&quot;: &quot;&quot;&quot;how are args and keyword arguments
                             defined in python?&quot;&quot;&quot;
        }
    ]
)
print(message.content)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h3 id="approach-2-setup-open-ai-llms" class="relative group"><span class="heading-text">Approach 2 : Setup Open AI LLMs</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#approach-2-setup-open-ai-llms" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.</p><p>Please signup and get your own API Keys.</p><p><a target="_blank" rel="noreferrer" href="https://platform.openai.com/docs/api-reference/introduction" class="">Open AI API Key</a></p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">! pip install openai</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># Let&#x27;s make sure your API keys are properly setup.
import platform;
print(platform.processor())
import os

if (not os.environ.get(&quot;OPENAI_API_KEY&quot;)):
    print(&quot;One of the api key is missing.&quot;)
else:
    print(&quot;All API Keys are in place.&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># test LLM
from openai import OpenAI
client = OpenAI()

response = client.chat.completions.create(
  model=&quot;gpt-4o-mini-2024-07-18&quot;,
  messages=[
        {
            &quot;role&quot;: &quot;user&quot;, 
            &quot;content&quot;: &quot;&quot;&quot;how are args and keyword arguments
                             defined in python?&quot;&quot;&quot;
        }
  ].
  temperature=1,
  max_tokens=256,
  top_p=1,
  frequency_penalty=0,
  presence_penalty=0
)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h3 id="approach-3-setup-google-gemini-llms" class="relative group"><span class="heading-text">Approach 3 : Setup Google Gemini LLMs</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#approach-3-setup-google-gemini-llms" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.</p><p>Please signup and get your own API Keys.</p><p><a target="_blank" rel="noreferrer" href="https://ai.google.dev/gemini-api" class="">Gemini API Key</a></p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">! python.exe -m pip install --upgrade pip
! pip install -q -U google-generativeai</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># export API_KEY=&lt;YOUR_API_KEY&gt;

import google.generativeai as genai
import os

genai.configure(api_key=os.environ[&quot;API_KEY&quot;])
model = genai.GenerativeModel(&#x27;gemini-1.5-flash&#x27;)

response = model.generate_content(&quot;Write a story about an AI and magic&quot;)
print(response.text)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h3 id="approach-4-running-groq-llama-3-3-api" class="relative group"><span class="heading-text">Approach 4 - Running Groq Llama 3.3 API</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#approach-4-running-groq-llama-3-3-api" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.</p><p>Please signup and get your own API Keys.</p><p><a target="_blank" rel="noreferrer" href="https://console.groq.com/keys" class="">Groq API Key</a></p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># !pip install groq</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre">from groq import Groq

client = Groq()
completion = client.chat.completions.create(
    model=&quot;llama3-8b-8192&quot;,
    messages=[
        {
        &quot;role&quot;: &quot;user&quot;,
        &quot;content&quot;: &quot;&quot;
        }
    ],
    temperature=1,
    max_tokens=1024,
    top_p=1,
    stream=True,
    stop=None,
)

for chunk in completion:
    print(chunk.choices[0].delta.content or &quot;&quot;, end=&quot;&quot;)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><h3 id="approach-5-running-xai-grok-3-0" class="relative group"><span class="heading-text">Approach 5 - Running xAI Grok 3.0</span><a class="no-underline text-inherit hover:text-inherit inline-block w-0 px-0 translate-x-[10px] font-normal select-none transition-opacity opacity-0 focus:opacity-100 group-hover:opacity-70" href="#approach-5-running-xai-grok-3-0" title="Link to this Section" aria-label="Link to this Section">¶</a></h3><p>Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.</p><p>Please signup and get your own API Keys.</p><p><a target="_blank" rel="noreferrer" href="https://console.x.ai/team/default/api-keys" class="">Grok API Key</a></p><div class="relative group not-prose overflow-auto shadow hover:shadow-md dark:shadow-2xl dark:shadow-neutral-900 my-5 text-sm bg-stone-200/10"><pre class="block p-3 hljs" style="background-color:unset"><code class="language-python" style="white-space:pre"># In your terminal, first run:
# pip install openai

import os
from openai import OpenAI

XAI_API_KEY = os.getenv(&quot;XAI_API_KEY&quot;)
client = OpenAI(
    api_key=XAI_API_KEY,
    base_url=&quot;https://api.x.ai/v1&quot;,
)

completion = client.chat.completions.create(
    model=&quot;grok-2-latest&quot;,
    messages=[
        {
            &quot;role&quot;: &quot;system&quot;,
            &quot;content&quot;: &quot;&quot;&quot;You are Grok, 
                        a chatbot inspired by
                        the Hitchhikers Guide to the Galaxy.&quot;&quot;&quot;
        },
        {
            &quot;role&quot;: &quot;user&quot;,
            &quot;content&quot;: &quot;&quot;&quot;What is the meaning of life, 
                        the universe, and everything?&quot;&quot;&quot;
        },
    ],
)

print(completion.choices[0].message.content)</code></pre><button title="Copy to Clipboard" class="inline-flex items-center opacity-0 group-hover:opacity-100 hover:opacity-100 focus:opacity-100 active:opacity-100 cursor-pointer ml-2 transition-color duration-200 ease-in-out text-blue-400 hover:text-blue-500 absolute right-1 top-1" aria-pressed="false" aria-label="Copy code to clipboard"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="24" height="24"><path stroke-linecap="round" stroke-linejoin="round" d="M15.75 17.25v3.375c0 .621-.504 1.125-1.125 1.125h-9.75a1.125 1.125 0 0 1-1.125-1.125V7.875c0-.621.504-1.125 1.125-1.125H6.75a9.06 9.06 0 0 1 1.5.124m7.5 10.376h3.375c.621 0 1.125-.504 1.125-1.125V11.25c0-4.46-3.243-8.161-7.5-8.876a9.06 9.06 0 0 0-1.5-.124H9.375c-.621 0-1.125.504-1.125 1.125v3.5m7.5 10.375H9.375a1.125 1.125 0 0 1-1.125-1.125v-9.25m12 6.625v-1.875a3.375 3.375 0 0 0-3.375-3.375h-1.5a1.125 1.125 0 0 1-1.125-1.125v-1.5a3.375 3.375 0 0 0-3.375-3.375H9.75"></path></svg></button></div><div></div><div class="flex pt-10 mb-10 space-x-4"><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/moreusecases"><div class="flex h-full align-middle"><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:-translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M10.5 19.5 3 12m0 0 7.5-7.5M3 12h18"></path></svg><div class="flex-grow text-right"><div class="text-xs text-gray-500 dark:text-gray-400">Use Cases</div>More Use Cases</div></div></a><a class="flex-1 block p-4 font-normal text-gray-600 no-underline border border-gray-200 rounded shadow-sm group hover:border-blue-600 dark:hover:border-blue-400 hover:text-blue-600 dark:hover:text-blue-400 dark:text-gray-100 dark:border-gray-500 hover:shadow-lg dark:shadow-neutral-700" href="/tools"><div class="flex h-full align-middle"><div class="flex-grow"><div class="text-xs text-gray-500 dark:text-gray-400">Tools</div>Tool Functions</div><svg xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke-width="1.5" stroke="currentColor" aria-hidden="true" data-slot="icon" width="1.5rem" height="1.5rem" class="self-center transition-transform group-hover:translate-x-1 shrink-0"><path stroke-linecap="round" stroke-linejoin="round" d="M13.5 4.5 21 12m0 0-7.5 7.5M21 12H3"></path></svg></div></a></div></main></article><script>((a,d)=>{if(!window.history.state||!window.history.state.key){let h=Math.random().toString(32).slice(2);window.history.replaceState({key:h},"")}try{let f=JSON.parse(sessionStorage.getItem(a)||"{}")[d||window.history.state.key];typeof f=="number"&&window.scrollTo(0,f)}catch(h){console.error(h),sessionStorage.removeItem(a)}})("positions", null)</script><link rel="modulepreload" href="/build/entry.client-UNPC4GT3.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCTKKCIL.js"/><link rel="modulepreload" href="/build/_shared/chunk-UAI5KRM7.js"/><link rel="modulepreload" href="/build/_shared/chunk-2NH4LW52.js"/><link rel="modulepreload" href="/build/_shared/chunk-IZFMW3M4.js"/><link rel="modulepreload" href="/build/_shared/chunk-HBJK6BW3.js"/><link rel="modulepreload" href="/build/_shared/chunk-HYMQ7M2K.js"/><link rel="modulepreload" href="/build/_shared/chunk-OHOXABTA.js"/><link rel="modulepreload" href="/build/_shared/chunk-OCWQY3HK.js"/><link rel="modulepreload" href="/build/_shared/chunk-CPTH56EW.js"/><link rel="modulepreload" href="/build/_shared/chunk-3CVK3PYF.js"/><link rel="modulepreload" href="/build/_shared/chunk-J6FHCSRC.js"/><link rel="modulepreload" href="/build/_shared/chunk-S4SWV34C.js"/><link rel="modulepreload" href="/build/_shared/chunk-GUCIBHGO.js"/><link rel="modulepreload" href="/build/root-QGLRP2PL.js"/><link rel="modulepreload" href="/build/_shared/chunk-CB3BH7WY.js"/><link rel="modulepreload" href="/build/routes/$-7JYT5576.js"/><script>window.__remixContext = {"url":"/llm","state":{"loaderData":{"root":{"config":{"title":"Agents of AI ~ Hack the Core","options":{"favicon":"/build/logo-57a9ad52301abe1c9fa2a0a758320907.png","logo":"/build/logo-57a9ad52301abe1c9fa2a0a758320907.png"},"myst":"1.3.23","nav":[],"actions":[],"projects":[{"bibliography":["references.bib"],"title":"Agents of AI","github":"https://github.com/AmitXShukla/AgentsOfAI","toc":[{"file":"intro.md"},{"file":"content/toc.md"},{"file":"content/security.md"},{"file":"content/whyautogen.md"},{"children":[{"file":"content/usecases.md"},{"file":"content/moreusecases.md"}],"title":"Use Cases"},{"file":"content/LLM.md"},{"children":[{"file":"content/tools.md"},{"file":"content/moretools.md"}],"title":"Tools"},{"file":"content/gettingstarted.md"},{"children":[{"file":"content/agent.md"},{"file":"content/actor.md"},{"file":"content/usecase.md"},{"file":"content/modelruntime.md"}],"title":"AI Agent"},{"children":[{"file":"content/implementation.md"},{"file":"content/messages.md"},{"file":"content/runtime.md"},{"file":"content/lifecycle.md"},{"file":"content/messaging.md"},{"file":"content/broadcast.md"}],"title":"AutoGen Core"},{"children":[{"file":"content/agentchat.md"},{"file":"content/agentchatagent.md"},{"file":"content/agentchatmodels.md"},{"file":"content/agentchatmessages.md"},{"file":"content/agentchatteam.md"}],"title":"Agent Chat"}],"thumbnail":"/build/logo-a36cb5c0d732407f82a97ea96df95f2a.png","exports":[],"index":"intro","pages":[{"slug":"toc","title":"Table of Contents","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"security","title":"Important Security Notice","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"whyautogen","title":"Why AutoGen","description":"","date":"","thumbnail":"/build/agent_frameworks-aee4bdbfc199b8e31ed7d48db596813f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":1,"title":"Use Cases"},{"slug":"usecases","title":"Use Cases","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"moreusecases","title":"More Use Cases","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"llm","title":"Understanding LLM","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":1,"title":"Tools"},{"slug":"tools","title":"Tool Functions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"moretools","title":"More Tool Functions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"gettingstarted","title":"Environment Setup","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":1,"title":"AI Agent"},{"slug":"agent","title":"Definition","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"actor","title":"Actor Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"usecase","title":"Use Case","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"modelruntime","title":"Model Runtime","description":"","date":"","thumbnail":"/build/dbc83861627470947570928b20e70773.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"AutoGen Core"},{"slug":"implementation","title":"Agent","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"messages","title":"Messages","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"runtime","title":"Runtime","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"lifecycle","title":"Agent Lifecyle","description":"","date":"","thumbnail":"/build/f1854a4e9d9fee0628be04e2a8c1faa5.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"messaging","title":"Direct Messages","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"broadcast","title":"Broadcasting","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Agent Chat"},{"slug":"agentchat","title":"why AgentChat","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"agentchatagent","title":"Agent","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"agentchatmodels","title":"Models","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"agentchatmessages","title":"Messages","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"agentchatteam","title":"Team","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"CONTENT_CDN_PORT":"3100","MODE":"static"},"routes/$":{"config":{"title":"Agents of AI ~ Hack the Core","options":{"favicon":"/build/logo-57a9ad52301abe1c9fa2a0a758320907.png","logo":"/build/logo-57a9ad52301abe1c9fa2a0a758320907.png"},"myst":"1.3.23","nav":[],"actions":[],"projects":[{"bibliography":["references.bib"],"title":"Agents of AI","github":"https://github.com/AmitXShukla/AgentsOfAI","toc":[{"file":"intro.md"},{"file":"content/toc.md"},{"file":"content/security.md"},{"file":"content/whyautogen.md"},{"children":[{"file":"content/usecases.md"},{"file":"content/moreusecases.md"}],"title":"Use Cases"},{"file":"content/LLM.md"},{"children":[{"file":"content/tools.md"},{"file":"content/moretools.md"}],"title":"Tools"},{"file":"content/gettingstarted.md"},{"children":[{"file":"content/agent.md"},{"file":"content/actor.md"},{"file":"content/usecase.md"},{"file":"content/modelruntime.md"}],"title":"AI Agent"},{"children":[{"file":"content/implementation.md"},{"file":"content/messages.md"},{"file":"content/runtime.md"},{"file":"content/lifecycle.md"},{"file":"content/messaging.md"},{"file":"content/broadcast.md"}],"title":"AutoGen Core"},{"children":[{"file":"content/agentchat.md"},{"file":"content/agentchatagent.md"},{"file":"content/agentchatmodels.md"},{"file":"content/agentchatmessages.md"},{"file":"content/agentchatteam.md"}],"title":"Agent Chat"}],"thumbnail":"/build/logo-a36cb5c0d732407f82a97ea96df95f2a.png","exports":[],"index":"intro","pages":[{"slug":"toc","title":"Table of Contents","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"security","title":"Important Security Notice","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"whyautogen","title":"Why AutoGen","description":"","date":"","thumbnail":"/build/agent_frameworks-aee4bdbfc199b8e31ed7d48db596813f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":1,"title":"Use Cases"},{"slug":"usecases","title":"Use Cases","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"moreusecases","title":"More Use Cases","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"llm","title":"Understanding LLM","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":1,"title":"Tools"},{"slug":"tools","title":"Tool Functions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"moretools","title":"More Tool Functions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"gettingstarted","title":"Environment Setup","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":1,"title":"AI Agent"},{"slug":"agent","title":"Definition","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"actor","title":"Actor Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"usecase","title":"Use Case","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"modelruntime","title":"Model Runtime","description":"","date":"","thumbnail":"/build/dbc83861627470947570928b20e70773.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"AutoGen Core"},{"slug":"implementation","title":"Agent","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"messages","title":"Messages","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"runtime","title":"Runtime","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"lifecycle","title":"Agent Lifecyle","description":"","date":"","thumbnail":"/build/f1854a4e9d9fee0628be04e2a8c1faa5.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"messaging","title":"Direct Messages","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"broadcast","title":"Broadcasting","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Agent Chat"},{"slug":"agentchat","title":"why AgentChat","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"agentchatagent","title":"Agent","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"agentchatmodels","title":"Models","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"agentchatmessages","title":"Messages","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"agentchatteam","title":"Team","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}]},"page":{"kind":"Article","sha256":"46c95b02ace24663deb1d8e5cdb6cd0499df057cd8377f2ec54cfc4f59d3caf7","slug":"llm","location":"/content/LLM.md","dependencies":[],"frontmatter":{"title":"Understanding LLM","content_includes_title":false,"github":"https://github.com/AmitXShukla/AgentsOfAI","edit_url":"https://github.com/AmitXShukla/AgentsOfAI/blob/main/content/LLM.md","exports":[{"format":"md","filename":"LLM.md","url":"/build/LLM-cd3032c73d1fa4cccc09735634a2c4c0.md"}]},"mdast":{"type":"root","children":[{"type":"block","children":[{"type":"paragraph","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"children":[{"type":"text","value":"I can reasonably presume that you’re already familiar with LLMs, which is likely why you’re here, but for the sake of thoroughness, I’ll provide the response from Grok 3.0 to the question, “What is an LLM anyway?”","position":{"start":{"line":3,"column":1},"end":{"line":3,"column":1}},"key":"N9g3DtYexi"}],"key":"nc52l7d5py"},{"type":"blockquote","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"paragraph","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"children":[{"type":"text","value":"An LLM, or Large Language Model, is a type of artificial intelligence designed to understand and generate human-like text. It’s trained on vast amounts of data—think books, articles, and websites—allowing it to predict words, construct sentences, and even hold conversations that feel surprisingly natural. Models like me, Grok, built by xAI, are examples of LLMs, engineered to assist, inform, and sometimes even entertain. The “large” part comes from the sheer scale of data and computational power involved, which lets us tackle everything from simple questions to complex reasoning tasks.","position":{"start":{"line":5,"column":1},"end":{"line":5,"column":1}},"key":"FH28p4PnM4"}],"key":"azRuwlK6ab"}],"key":"OMxZZcCTm7"},{"type":"paragraph","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"children":[{"type":"text","value":"LLMs are capable of responding to nearly any question because they’re trained to recognize and “grasp patterns” or the order in which text occurs. Models like ChatGPT, Llama, DeepSeek, Mistral, Gemini, and now Grok have largely perfected this technology, though a few of these models assert they can comprehend something more than just textual patterns.","position":{"start":{"line":7,"column":1},"end":{"line":7,"column":1}},"key":"WdIt8v0YYY"}],"key":"GX5CYznlWJ"},{"type":"paragraph","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"children":[{"type":"text","value":"In any case, my goal is to fully leverage these trained models to support my AI Agents.","position":{"start":{"line":9,"column":1},"end":{"line":9,"column":1}},"key":"HnojNtuPIn"}],"key":"uifRj7PorU"},{"type":"paragraph","position":{"start":{"line":11,"column":1},"end":{"line":12,"column":1}},"children":[{"type":"text","value":"There are two primary methods to utilize these LLM models.\nFirst, many of these organizations generously provide their open weights, allowing you to download and operate the models on your own machine. This approach eliminates concerns about data privacy and leakage, while also enabling access to their hosted models on highly powerful computing clusters via an API, typically for a modest (or occasionally substantial) fee.","position":{"start":{"line":11,"column":1},"end":{"line":11,"column":1}},"key":"V2Ytg8SGcW"}],"key":"ceQ8QRdjBt"},{"type":"paragraph","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"children":[{"type":"text","value":"Let’s explore both approaches: how to tap into LLM models through an API and how to run them locally on your own system.","position":{"start":{"line":14,"column":1},"end":{"line":14,"column":1}},"key":"pgNlsfGLTy"}],"key":"waixEgZ2Kc"},{"type":"heading","depth":2,"position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"children":[{"type":"text","value":"python environment","position":{"start":{"line":16,"column":1},"end":{"line":16,"column":1}},"key":"KghKSunuX6"}],"identifier":"python-environment","label":"python environment","html_id":"python-environment","implicit":true,"key":"Y9E9l6XO6l"},{"type":"code","lang":"python","value":"# Python 3.10 or later is required.\n! python --version","position":{"start":{"line":18,"column":1},"end":{"line":21,"column":1}},"key":"wbZBwnkyl5"},{"type":"code","lang":"python","value":"######################################################\n# Create and activate a new Python virtual environment\n######################################################\n\n\n!python3 -m venv .venv\n!source .venv/bin/activate\n\n## To deactivate later, run:\n!deactivate\n\n######################################################\n# install autogen in this section below\n# AutoGen Core is required in later phase\n# we will discuss this packages in details as we use\n######################################################\n# install autogen studio\n! pip install -U autogenstudio\n# install autogen chat\n! pip install -U \"autogen-agentchat\"\n# install autogen OpenAI for Model Client\n# !pip install \"autogen-ext[openai]\"\n# install autogen core\n# !pip install \"autogen-core\"\n\n######################################################\n# run AutoGen Studio GUI\n######################################################\n!autogenstudio ui --host \u003chost\u003e --port 8000","position":{"start":{"line":23,"column":1},"end":{"line":53,"column":1}},"key":"phKL5OIghx"},{"type":"heading","depth":2,"position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"children":[{"type":"text","value":"running LLM locally","position":{"start":{"line":55,"column":1},"end":{"line":55,"column":1}},"key":"XmitAM1RsC"}],"identifier":"running-llm-locally","label":"running LLM locally","html_id":"running-llm-locally","implicit":true,"key":"FLZ80jrHNJ"},{"type":"heading","depth":3,"position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"children":[{"type":"text","value":"ollama, Deepseek-R1, llama3.x models","position":{"start":{"line":57,"column":1},"end":{"line":57,"column":1}},"key":"f3eXLQbaAh"}],"identifier":"ollama-deepseek-r1-llama3-x-models","label":"ollama, Deepseek-R1, llama3.x models","html_id":"ollama-deepseek-r1-llama3-x-models","implicit":true,"key":"RxjaDnYRr1"},{"type":"code","lang":"python","value":"###################################################\n# install ollama to run deepseek-r1 | llama models\n###################################################\n\n! curl -fsSL https://ollama.com/install.sh | sh\n\n!ollama list\n!ollama pull deepseek-r1:7b\n!ollama list\n!ollama run deepseek-r1\n\n# please see, ollama by default serves at 0.0.0.0:11434\n# you can change this\n!sudo systemctl edit ollama.servicem\n#[Service]\nEnvironment=\"OLLAMA_HOST=0.0.0.0:8000\"\n\n!sudo systemctl daemon-reload\n!sudo systemctl restart ollama.service\n\n# also, for a quick one time change you can run ollama as\n!export OLLAMA_HOST=127.0.0.1:8000\n!ollama serve","position":{"start":{"line":59,"column":1},"end":{"line":83,"column":1}},"key":"SnwnwljB6p"},{"type":"heading","depth":3,"position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"children":[{"type":"text","value":"llama.cpp, Deepseek-R1, llama3.x models","position":{"start":{"line":85,"column":1},"end":{"line":85,"column":1}},"key":"gwTRwJUQCb"}],"identifier":"llama-cpp-deepseek-r1-llama3-x-models","label":"llama.cpp, Deepseek-R1, llama3.x models","html_id":"llama-cpp-deepseek-r1-llama3-x-models","implicit":true,"key":"p8MYHbKHh2"},{"type":"code","lang":"python","value":"######################################################\n# install llama.cpp to run deepseek-r1 | llama models\n######################################################\n\n!git clone https://github.com/ggerganov/llama.cpp\n!cd llama.cpp\n!make\n\n# Download the deepseek-r1 Model weights \n\n# Convert the Model (if necessary)\n# If the model weights are not already in GGML format, \n# you must convert them using the conversion tools provided in llama.cpp. \n# Assuming the model weights are in PyTorch format:\n!python3 convert-pth-to-ggml.py path/to/deepseek-r1.pth\n\n# Prepare the Model File\n# Place the .bin model file (e.g., deepseek-r1.ggml.bin) into the llama.cpp directory \n# or specify its location when running commands\n\n# run the model\n!./main -m ./deepseek-r1.ggml.bin -p \"Your prompt here\"\n\n# adjust parameters\n!./main -m ./deepseek-r1.ggml.bin -p \"Explain quantum mechanics.\" -t 8 -n 128 --temp 0.8","position":{"start":{"line":86,"column":1},"end":{"line":112,"column":1}},"key":"DuQmDVYXuo"},{"type":"heading","depth":2,"position":{"start":{"line":114,"column":1},"end":{"line":114,"column":1}},"children":[{"type":"text","value":"running LLM through API","position":{"start":{"line":114,"column":1},"end":{"line":114,"column":1}},"key":"rJ93HhXwFQ"}],"identifier":"running-llm-through-api","label":"running LLM through API","html_id":"running-llm-through-api","implicit":true,"key":"bpYnVysYAa"},{"type":"paragraph","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"children":[{"type":"text","value":"We’ll discuss few different approaches.","position":{"start":{"line":116,"column":1},"end":{"line":116,"column":1}},"key":"cufetDyory"}],"key":"cBOa8Dwowh"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":117,"column":1},"end":{"line":122,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":117,"column":1},"end":{"line":117,"column":1}},"children":[{"type":"strong","position":{"start":{"line":117,"column":1},"end":{"line":117,"column":1}},"children":[{"type":"text","value":"Approach 1","position":{"start":{"line":117,"column":1},"end":{"line":117,"column":1}},"key":"XoLwOPwklh"}],"key":"e2OYN8peLT"},{"type":"text","value":" - Setup Anthropic LLMs","position":{"start":{"line":117,"column":1},"end":{"line":117,"column":1}},"key":"q5zApbchAd"}],"key":"YNmA5xFhXp"},{"type":"listItem","spread":true,"position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"children":[{"type":"strong","position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"children":[{"type":"text","value":"Approach 2","position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"key":"UTTuJh7yVI"}],"key":"RqvV5RXLiu"},{"type":"text","value":" - Setup Open AI LLMs","position":{"start":{"line":118,"column":1},"end":{"line":118,"column":1}},"key":"MMnpnyt1WJ"}],"key":"oRVnwhJsXH"},{"type":"listItem","spread":true,"position":{"start":{"line":119,"column":1},"end":{"line":119,"column":1}},"children":[{"type":"strong","position":{"start":{"line":119,"column":1},"end":{"line":119,"column":1}},"children":[{"type":"text","value":"Approach 3","position":{"start":{"line":119,"column":1},"end":{"line":119,"column":1}},"key":"xG6BTE7KYk"}],"key":"OQ7xTVQF0l"},{"type":"text","value":" - Setup Google Gemini AI","position":{"start":{"line":119,"column":1},"end":{"line":119,"column":1}},"key":"wQSf9z01HR"}],"key":"U2ykpXv141"},{"type":"listItem","spread":true,"position":{"start":{"line":120,"column":1},"end":{"line":120,"column":1}},"children":[{"type":"strong","position":{"start":{"line":120,"column":1},"end":{"line":120,"column":1}},"children":[{"type":"text","value":"Approach 4","position":{"start":{"line":120,"column":1},"end":{"line":120,"column":1}},"key":"yu1eYuLGuG"}],"key":"efIu3WXNw2"},{"type":"text","value":" - Setup Groq API","position":{"start":{"line":120,"column":1},"end":{"line":120,"column":1}},"key":"S5vr3vYNll"}],"key":"QlS9fegnLI"},{"type":"listItem","spread":true,"position":{"start":{"line":121,"column":1},"end":{"line":122,"column":1}},"children":[{"type":"strong","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"children":[{"type":"text","value":"Approach 5","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"key":"n92XvQwXh3"}],"key":"oLkqTtltjJ"},{"type":"text","value":" - Setup xAI Grok 3.0 API","position":{"start":{"line":121,"column":1},"end":{"line":121,"column":1}},"key":"OnPc9rJwXZ"}],"key":"fHtJ2r0IPO"}],"key":"O0zHEtFq4B"},{"type":"paragraph","position":{"start":{"line":123,"column":1},"end":{"line":123,"column":1}},"children":[{"type":"text","value":"The selection of a Large Language Model (LLM) is influenced by factors such as your specific business needs, financial constraints, and personal tastes.","position":{"start":{"line":123,"column":1},"end":{"line":123,"column":1}},"key":"qZwNS55aNb"}],"key":"WuiRRM52AC"},{"type":"paragraph","position":{"start":{"line":125,"column":1},"end":{"line":126,"column":1}},"children":[{"type":"text","value":"In this section, I’ll present few distinct methods for establishing connections with various LLM service providers.\nAdditionally, I recommend utilizing this occasion as an avenue to evaluate Large Language Models against the backdrop of your unique inputs and industry-specific needs.","position":{"start":{"line":125,"column":1},"end":{"line":125,"column":1}},"key":"bBm96kLpW3"}],"key":"DrXUJPDEX8"},{"type":"heading","depth":3,"position":{"start":{"line":128,"column":1},"end":{"line":128,"column":1}},"children":[{"type":"text","value":"Approach 1 : Setup Anthropic LLMs","position":{"start":{"line":128,"column":1},"end":{"line":128,"column":1}},"key":"xGXOp43SCy"}],"identifier":"approach-1-setup-anthropic-llms","label":"Approach 1 : Setup Anthropic LLMs","html_id":"approach-1-setup-anthropic-llms","implicit":true,"key":"vH6IRXjZQ0"},{"type":"paragraph","position":{"start":{"line":129,"column":1},"end":{"line":129,"column":1}},"children":[{"type":"text","value":"Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.","position":{"start":{"line":129,"column":1},"end":{"line":129,"column":1}},"key":"lZTjBmKtZ4"}],"key":"wQdhYPLhIS"},{"type":"paragraph","position":{"start":{"line":131,"column":1},"end":{"line":131,"column":1}},"children":[{"type":"text","value":"Please signup using these links and get your own API Keys.","position":{"start":{"line":131,"column":1},"end":{"line":131,"column":1}},"key":"HXAVcdF99Y"}],"key":"WoXWhHdACf"},{"type":"paragraph","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"children":[{"type":"text","value":"**please note that PINECONE and VOYAGE are completely optional and are not required at this time. These will be needed later when we will use a vector database and embeddings, tokens to store in vector database","position":{"start":{"line":133,"column":1},"end":{"line":133,"column":1}},"key":"gIEXmKtIAy"}],"key":"Epdr7yLVtt"},{"type":"list","ordered":false,"spread":false,"position":{"start":{"line":134,"column":1},"end":{"line":137,"column":1}},"children":[{"type":"listItem","spread":true,"position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"children":[{"type":"link","url":"https://docs.anthropic.com/claude/reference/getting-started-with-the-api","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"children":[{"type":"text","value":"ANTHROPIC_API_KEY","position":{"start":{"line":134,"column":1},"end":{"line":134,"column":1}},"key":"MS1zaypMYB"}],"urlSource":"https://docs.anthropic.com/claude/reference/getting-started-with-the-api","key":"seakeUp8uL"}],"key":"FNaXLU1PJ3"},{"type":"listItem","spread":true,"position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"children":[{"type":"link","url":"https://docs.pinecone.io/docs/quickstart","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"children":[{"type":"text","value":"YOUR​_PINECONE​_API​_KEY","position":{"start":{"line":135,"column":1},"end":{"line":135,"column":1}},"key":"FWBRi7WMr9"}],"urlSource":"https://docs.pinecone.io/docs/quickstart","key":"la7BNigiS8"}],"key":"w0epKVScnr"},{"type":"listItem","spread":true,"position":{"start":{"line":136,"column":1},"end":{"line":137,"column":1}},"children":[{"type":"link","url":"https://docs.voyageai.com/docs/api-key-and-installation","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"children":[{"type":"text","value":"VOYAGE_API_KEY","position":{"start":{"line":136,"column":1},"end":{"line":136,"column":1}},"key":"gKuKQjea7E"}],"urlSource":"https://docs.voyageai.com/docs/api-key-and-installation","key":"iehqGUxFjE"}],"key":"fELKPhvTp4"}],"key":"b8MzYKI7av"},{"type":"code","lang":"python","value":"##########################################################################\n## Although not mandatory, \n## it is highly recommended to set up a new Python working environment\n##########################################################################\n## To create a virtual environment called `GenAI`, follow the steps:\n\n## On Windows: \n# !python -m venv GenAI GenAI\\Scripts\\activate\n\n## On macOS or Linux: \n# !python3 -m venv GenAI source GenAI/bin/activate\n\n## Then, install required packages using pip: \n# !pip install pandas numpy matplotlib seaborn tqdm beautifulsoup4\n\n## install only in case if you are using OpenAI\n# !pip install openai\n\n## install only in case if you are using Claude\n# !pip install anthropic datasets pinecone-client voyageai\n\n## in case if you fork this repo, just run\n# !pip install -r requirements.txt\n\n# !pip install --upgrade pip\n# !pip freeze \u003e requirements.txt","position":{"start":{"line":138,"column":1},"end":{"line":165,"column":1}},"key":"YqIqCHBfMB"},{"type":"code","lang":"python","value":"import platform;\nprint(platform.processor())\n\nimport os\n\n####################################################\n## always store your API Keys as environment vars\n## if you are using OpenAI LLMs\n## setup windows environment variable OPENAI_API_KEY\n####################################################\n# import openai\n# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\n####################################################\n## if you are using Anthropic Claude LLMs\n## sign up for API keys \u0026 setup windows environment variable \n## ANTHROPIC_API_KEY, PINECONE_API_KEY \u0026 VOYAGE_API_KEY\n####################################################\n# import anthropic\n\nif (not os.environ.get(\"ANTHROPIC_API_KEY\")) \n        | (not os.environ.get(\"PINECONE_API_KEY\")) \n        | (not os.environ.get(\"VOYAGE_API_KEY\")):\n    print(\"One of the api key is missing.\")\nelse:\n    print(\"All API Keys are in place.\")","position":{"start":{"line":167,"column":1},"end":{"line":194,"column":1}},"key":"Go68mzvZa8"},{"type":"code","lang":"python","value":"# Test LLM API\nimport anthropic\n\nclient = anthropic.Anthropic(\n    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n    # you don't need to pass api_key explicitly\n    api_key=os.environ.get(\"ANTHROPIC_API_KEY\")\n)\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1000,\n    temperature=0.0,\n    system=\"Respond only in Yoda-speak.\",\n    messages=[\n        {\n            \"role\": \"user\", \n            \"content\": \"\"\"how are args and keyword arguments\n                             defined in python?\"\"\"\n        }\n    ]\n)\nprint(message.content)","position":{"start":{"line":196,"column":1},"end":{"line":220,"column":1}},"key":"bNVyV0r0ON"},{"type":"heading","depth":3,"position":{"start":{"line":222,"column":1},"end":{"line":222,"column":1}},"children":[{"type":"text","value":"Approach 2 : Setup Open AI LLMs","position":{"start":{"line":222,"column":1},"end":{"line":222,"column":1}},"key":"seztzUIkJw"}],"identifier":"approach-2-setup-open-ai-llms","label":"Approach 2 : Setup Open AI LLMs","html_id":"approach-2-setup-open-ai-llms","implicit":true,"key":"TbCqUmqzSN"},{"type":"paragraph","position":{"start":{"line":224,"column":1},"end":{"line":224,"column":1}},"children":[{"type":"text","value":"Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.","position":{"start":{"line":224,"column":1},"end":{"line":224,"column":1}},"key":"b6z9fbak7C"}],"key":"qH4C7wuUAj"},{"type":"paragraph","position":{"start":{"line":226,"column":1},"end":{"line":226,"column":1}},"children":[{"type":"text","value":"Please signup and get your own API Keys.","position":{"start":{"line":226,"column":1},"end":{"line":226,"column":1}},"key":"uSnpc5AYVn"}],"key":"qVjMGdJQmd"},{"type":"paragraph","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"children":[{"type":"link","url":"https://platform.openai.com/docs/api-reference/introduction","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"children":[{"type":"text","value":"Open AI API Key","position":{"start":{"line":228,"column":1},"end":{"line":228,"column":1}},"key":"LAmVPpZHXw"}],"urlSource":"https://platform.openai.com/docs/api-reference/introduction","key":"WoMKiB9onV"}],"key":"FItPlyAcuV"},{"type":"code","lang":"python","value":"! pip install openai","position":{"start":{"line":230,"column":1},"end":{"line":232,"column":1}},"key":"pPi5zsFSFX"},{"type":"code","lang":"python","value":"# Let's make sure your API keys are properly setup.\nimport platform;\nprint(platform.processor())\nimport os\n\nif (not os.environ.get(\"OPENAI_API_KEY\")):\n    print(\"One of the api key is missing.\")\nelse:\n    print(\"All API Keys are in place.\")","position":{"start":{"line":234,"column":1},"end":{"line":244,"column":1}},"key":"dubsh2Sf7R"},{"type":"code","lang":"python","value":"# test LLM\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-4o-mini-2024-07-18\",\n  messages=[\n        {\n            \"role\": \"user\", \n            \"content\": \"\"\"how are args and keyword arguments\n                             defined in python?\"\"\"\n        }\n  ].\n  temperature=1,\n  max_tokens=256,\n  top_p=1,\n  frequency_penalty=0,\n  presence_penalty=0\n)","position":{"start":{"line":246,"column":1},"end":{"line":266,"column":1}},"key":"Svyu4afcty"},{"type":"heading","depth":3,"position":{"start":{"line":268,"column":1},"end":{"line":268,"column":1}},"children":[{"type":"text","value":"Approach 3 : Setup Google Gemini LLMs","position":{"start":{"line":268,"column":1},"end":{"line":268,"column":1}},"key":"i4P3PADRGb"}],"identifier":"approach-3-setup-google-gemini-llms","label":"Approach 3 : Setup Google Gemini LLMs","html_id":"approach-3-setup-google-gemini-llms","implicit":true,"key":"H8WrChtHgh"},{"type":"paragraph","position":{"start":{"line":270,"column":1},"end":{"line":270,"column":1}},"children":[{"type":"text","value":"Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.","position":{"start":{"line":270,"column":1},"end":{"line":270,"column":1}},"key":"EpLl4uDx4s"}],"key":"jJyyu5inUd"},{"type":"paragraph","position":{"start":{"line":272,"column":1},"end":{"line":272,"column":1}},"children":[{"type":"text","value":"Please signup and get your own API Keys.","position":{"start":{"line":272,"column":1},"end":{"line":272,"column":1}},"key":"G2eXSc6fq1"}],"key":"mmIfJU3Ub0"},{"type":"paragraph","position":{"start":{"line":274,"column":1},"end":{"line":274,"column":1}},"children":[{"type":"link","url":"https://ai.google.dev/gemini-api","position":{"start":{"line":274,"column":1},"end":{"line":274,"column":1}},"children":[{"type":"text","value":"Gemini API Key","position":{"start":{"line":274,"column":1},"end":{"line":274,"column":1}},"key":"DSDiTepsKb"}],"urlSource":"https://ai.google.dev/gemini-api","key":"B9DGdUg8ni"}],"key":"HX2BnMIdyo"},{"type":"code","lang":"python","value":"! python.exe -m pip install --upgrade pip\n! pip install -q -U google-generativeai","position":{"start":{"line":276,"column":1},"end":{"line":279,"column":1}},"key":"oIfwQOW3qr"},{"type":"code","lang":"python","value":"# export API_KEY=\u003cYOUR_API_KEY\u003e\n\nimport google.generativeai as genai\nimport os\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-1.5-flash')\n\nresponse = model.generate_content(\"Write a story about an AI and magic\")\nprint(response.text)","position":{"start":{"line":281,"column":1},"end":{"line":292,"column":1}},"key":"QkS3XkLmno"},{"type":"heading","depth":3,"position":{"start":{"line":294,"column":1},"end":{"line":294,"column":1}},"children":[{"type":"text","value":"Approach 4 - Running Groq Llama 3.3 API","position":{"start":{"line":294,"column":1},"end":{"line":294,"column":1}},"key":"F7dRlwMb2n"}],"identifier":"approach-4-running-groq-llama-3-3-api","label":"Approach 4 - Running Groq Llama 3.3 API","html_id":"approach-4-running-groq-llama-3-3-api","implicit":true,"key":"YLctZbuhrj"},{"type":"paragraph","position":{"start":{"line":296,"column":1},"end":{"line":296,"column":1}},"children":[{"type":"text","value":"Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.","position":{"start":{"line":296,"column":1},"end":{"line":296,"column":1}},"key":"XjUsWQ5Acp"}],"key":"Myn2Wr7DXq"},{"type":"paragraph","position":{"start":{"line":298,"column":1},"end":{"line":298,"column":1}},"children":[{"type":"text","value":"Please signup and get your own API Keys.","position":{"start":{"line":298,"column":1},"end":{"line":298,"column":1}},"key":"TxactHbK0B"}],"key":"IlrGmPOeUI"},{"type":"paragraph","position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"children":[{"type":"link","url":"https://console.groq.com/keys","position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"children":[{"type":"text","value":"Groq API Key","position":{"start":{"line":300,"column":1},"end":{"line":300,"column":1}},"key":"e2Fh8MTr9O"}],"urlSource":"https://console.groq.com/keys","key":"XwoGkRW7Yq"}],"key":"zREmbSov3b"},{"type":"code","lang":"python","value":"# !pip install groq","position":{"start":{"line":302,"column":1},"end":{"line":304,"column":1}},"key":"o9ny5NPU09"},{"type":"code","lang":"python","value":"from groq import Groq\n\nclient = Groq()\ncompletion = client.chat.completions.create(\n    model=\"llama3-8b-8192\",\n    messages=[\n        {\n        \"role\": \"user\",\n        \"content\": \"\"\n        }\n    ],\n    temperature=1,\n    max_tokens=1024,\n    top_p=1,\n    stream=True,\n    stop=None,\n)\n\nfor chunk in completion:\n    print(chunk.choices[0].delta.content or \"\", end=\"\")","position":{"start":{"line":306,"column":1},"end":{"line":327,"column":1}},"key":"l0MHqleNBi"},{"type":"heading","depth":3,"position":{"start":{"line":329,"column":1},"end":{"line":329,"column":1}},"children":[{"type":"text","value":"Approach 5 - Running xAI Grok 3.0","position":{"start":{"line":329,"column":1},"end":{"line":329,"column":1}},"key":"g31gnQeiHf"}],"identifier":"approach-5-running-xai-grok-3-0","label":"Approach 5 - Running xAI Grok 3.0","html_id":"approach-5-running-xai-grok-3-0","implicit":true,"key":"K3VVfzcfTV"},{"type":"paragraph","position":{"start":{"line":331,"column":1},"end":{"line":331,"column":1}},"children":[{"type":"text","value":"Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.","position":{"start":{"line":331,"column":1},"end":{"line":331,"column":1}},"key":"WIW1VcTowD"}],"key":"wnqnRCFH1V"},{"type":"paragraph","position":{"start":{"line":333,"column":1},"end":{"line":333,"column":1}},"children":[{"type":"text","value":"Please signup and get your own API Keys.","position":{"start":{"line":333,"column":1},"end":{"line":333,"column":1}},"key":"euTmv51Guj"}],"key":"vk8G2xSsvk"},{"type":"paragraph","position":{"start":{"line":335,"column":1},"end":{"line":335,"column":1}},"children":[{"type":"link","url":"https://console.x.ai/team/default/api-keys","position":{"start":{"line":335,"column":1},"end":{"line":335,"column":1}},"children":[{"type":"text","value":"Grok API Key","position":{"start":{"line":335,"column":1},"end":{"line":335,"column":1}},"key":"taF5IoYhmB"}],"urlSource":"https://console.x.ai/team/default/api-keys","key":"o9Dd8wkG7N"}],"key":"NPHqGp3LRU"},{"type":"code","lang":"python","value":"# In your terminal, first run:\n# pip install openai\n\nimport os\nfrom openai import OpenAI\n\nXAI_API_KEY = os.getenv(\"XAI_API_KEY\")\nclient = OpenAI(\n    api_key=XAI_API_KEY,\n    base_url=\"https://api.x.ai/v1\",\n)\n\ncompletion = client.chat.completions.create(\n    model=\"grok-2-latest\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"\"\"You are Grok, \n                        a chatbot inspired by\n                        the Hitchhikers Guide to the Galaxy.\"\"\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"\"\"What is the meaning of life, \n                        the universe, and everything?\"\"\"\n        },\n    ],\n)\n\nprint(completion.choices[0].message.content)","position":{"start":{"line":337,"column":1},"end":{"line":368,"column":1}},"key":"SMpMzKvxmJ"}],"key":"tfi3pOgrzh"}],"key":"D7k7zsgv4X"},"references":{"cite":{"order":[],"data":{}}},"footer":{"navigation":{"prev":{"title":"More Use Cases","url":"/moreusecases","group":"Use Cases"},"next":{"title":"Tool Functions","url":"/tools","group":"Tools"}}},"domain":"http://localhost:3004"},"project":{"bibliography":["references.bib"],"title":"Agents of AI","github":"https://github.com/AmitXShukla/AgentsOfAI","toc":[{"file":"intro.md"},{"file":"content/toc.md"},{"file":"content/security.md"},{"file":"content/whyautogen.md"},{"children":[{"file":"content/usecases.md"},{"file":"content/moreusecases.md"}],"title":"Use Cases"},{"file":"content/LLM.md"},{"children":[{"file":"content/tools.md"},{"file":"content/moretools.md"}],"title":"Tools"},{"file":"content/gettingstarted.md"},{"children":[{"file":"content/agent.md"},{"file":"content/actor.md"},{"file":"content/usecase.md"},{"file":"content/modelruntime.md"}],"title":"AI Agent"},{"children":[{"file":"content/implementation.md"},{"file":"content/messages.md"},{"file":"content/runtime.md"},{"file":"content/lifecycle.md"},{"file":"content/messaging.md"},{"file":"content/broadcast.md"}],"title":"AutoGen Core"},{"children":[{"file":"content/agentchat.md"},{"file":"content/agentchatagent.md"},{"file":"content/agentchatmodels.md"},{"file":"content/agentchatmessages.md"},{"file":"content/agentchatteam.md"}],"title":"Agent Chat"}],"thumbnail":"/build/logo-a36cb5c0d732407f82a97ea96df95f2a.png","exports":[],"index":"intro","pages":[{"slug":"toc","title":"Table of Contents","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"security","title":"Important Security Notice","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"slug":"whyautogen","title":"Why AutoGen","description":"","date":"","thumbnail":"/build/agent_frameworks-aee4bdbfc199b8e31ed7d48db596813f.png","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":1,"title":"Use Cases"},{"slug":"usecases","title":"Use Cases","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"moreusecases","title":"More Use Cases","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"llm","title":"Understanding LLM","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":1,"title":"Tools"},{"slug":"tools","title":"Tool Functions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"moretools","title":"More Tool Functions","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"gettingstarted","title":"Environment Setup","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":1},{"level":1,"title":"AI Agent"},{"slug":"agent","title":"Definition","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"actor","title":"Actor Model","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"usecase","title":"Use Case","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"modelruntime","title":"Model Runtime","description":"","date":"","thumbnail":"/build/dbc83861627470947570928b20e70773.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"AutoGen Core"},{"slug":"implementation","title":"Agent","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"messages","title":"Messages","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"runtime","title":"Runtime","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"lifecycle","title":"Agent Lifecyle","description":"","date":"","thumbnail":"/build/f1854a4e9d9fee0628be04e2a8c1faa5.svg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"messaging","title":"Direct Messages","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"broadcast","title":"Broadcasting","description":"","date":"","thumbnail":"","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"level":1,"title":"Agent Chat"},{"slug":"agentchat","title":"why AgentChat","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"agentchatagent","title":"Agent","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"agentchatmodels","title":"Models","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"agentchatmessages","title":"Messages","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2},{"slug":"agentchatteam","title":"Team","description":"","date":"","thumbnail":"/build/32546b5752839c6e4166bef6ec7d001c.jpeg","thumbnailOptimized":"","banner":"","bannerOptimized":"","tags":[],"level":2}]}}},"actionData":null,"errors":null},"future":{"unstable_dev":false,"unstable_postcss":false,"unstable_tailwind":false,"v2_errorBoundary":true,"v2_headers":true,"v2_meta":true,"v2_normalizeFormMethod":true,"v2_routeConvention":true}};</script><script type="module" async="">import "/build/manifest-B4831781.js";
import * as route0 from "/build/root-QGLRP2PL.js";
import * as route1 from "/build/routes/$-7JYT5576.js";
window.__remixRouteModules = {"root":route0,"routes/$":route1};

import("/build/entry.client-UNPC4GT3.js");</script></body></html>