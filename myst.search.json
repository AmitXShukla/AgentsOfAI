{"version":"1","records":[{"hierarchy":{"lvl1":"Understanding LLM"},"type":"lvl1","url":"/llm","position":0},{"hierarchy":{"lvl1":"Understanding LLM"},"content":"I can reasonably presume that you’re already familiar with LLMs, which is likely why you’re here, but for the sake of thoroughness, I’ll provide the response from Grok 3.0 to the question, “What is an LLM anyway?”\n\nAn LLM, or Large Language Model, is a type of artificial intelligence designed to understand and generate human-like text. It’s trained on vast amounts of data—think books, articles, and websites—allowing it to predict words, construct sentences, and even hold conversations that feel surprisingly natural. Models like me, Grok, built by xAI, are examples of LLMs, engineered to assist, inform, and sometimes even entertain. The “large” part comes from the sheer scale of data and computational power involved, which lets us tackle everything from simple questions to complex reasoning tasks.\n\nLLMs are capable of responding to nearly any question because they’re trained to recognize and “grasp patterns” or the order in which text occurs. Models like ChatGPT, Llama, DeepSeek, Mistral, Gemini, and now Grok have largely perfected this technology, though a few of these models assert they can comprehend something more than just textual patterns.\n\nIn any case, my goal is to fully leverage these trained models to support my AI Agents.\n\nThere are two primary methods to utilize these LLM models.\nFirst, many of these organizations generously provide their open weights, allowing you to download and operate the models on your own machine. This approach eliminates concerns about data privacy and leakage, while also enabling access to their hosted models on highly powerful computing clusters via an API, typically for a modest (or occasionally substantial) fee.\n\nLet’s explore both approaches: how to tap into LLM models through an API and how to run them locally on your own system.","type":"content","url":"/llm","position":1},{"hierarchy":{"lvl1":"Understanding LLM","lvl2":"python environment"},"type":"lvl2","url":"/llm#python-environment","position":2},{"hierarchy":{"lvl1":"Understanding LLM","lvl2":"python environment"},"content":"# Python 3.10 or later is required.\n! python --version######################################################\n# Create and activate a new Python virtual environment\n######################################################\n\n\n!python3 -m venv .venv\n!source .venv/bin/activate\n\n## To deactivate later, run:\n!deactivate\n\n######################################################\n# install autogen in this section below\n# AutoGen Core is required in later phase\n# we will discuss this packages in details as we use\n######################################################\n# install autogen studio\n! pip install -U autogenstudio\n# install autogen chat\n! pip install -U \"autogen-agentchat\"\n# install autogen OpenAI for Model Client\n# !pip install \"autogen-ext[openai]\"\n# install autogen core\n# !pip install \"autogen-core\"\n\n######################################################\n# run AutoGen Studio GUI\n######################################################\n!autogenstudio ui --host <host> --port 8000","type":"content","url":"/llm#python-environment","position":3},{"hierarchy":{"lvl1":"Understanding LLM","lvl2":"running LLM locally"},"type":"lvl2","url":"/llm#running-llm-locally","position":4},{"hierarchy":{"lvl1":"Understanding LLM","lvl2":"running LLM locally"},"content":"","type":"content","url":"/llm#running-llm-locally","position":5},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"ollama, Deepseek-R1, llama3.x models","lvl2":"running LLM locally"},"type":"lvl3","url":"/llm#ollama-deepseek-r1-llama3-x-models","position":6},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"ollama, Deepseek-R1, llama3.x models","lvl2":"running LLM locally"},"content":"###################################################\n# install ollama to run deepseek-r1 | llama models\n###################################################\n\n! curl -fsSL https://ollama.com/install.sh | sh\n\n!ollama list\n!ollama pull deepseek-r1:7b\n!ollama list\n!ollama run deepseek-r1\n\n# please see, ollama by default serves at 0.0.0.0:11434\n# you can change this\n!sudo systemctl edit ollama.servicem\n#[Service]\nEnvironment=\"OLLAMA_HOST=0.0.0.0:8000\"\n\n!sudo systemctl daemon-reload\n!sudo systemctl restart ollama.service\n\n# also, for a quick one time change you can run ollama as\n!export OLLAMA_HOST=127.0.0.1:8000\n!ollama serve","type":"content","url":"/llm#ollama-deepseek-r1-llama3-x-models","position":7},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"llama.cpp, Deepseek-R1, llama3.x models","lvl2":"running LLM locally"},"type":"lvl3","url":"/llm#llama-cpp-deepseek-r1-llama3-x-models","position":8},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"llama.cpp, Deepseek-R1, llama3.x models","lvl2":"running LLM locally"},"content":"######################################################\n# install llama.cpp to run deepseek-r1 | llama models\n######################################################\n\n!git clone https://github.com/ggerganov/llama.cpp\n!cd llama.cpp\n!make\n\n# Download the deepseek-r1 Model weights \n\n# Convert the Model (if necessary)\n# If the model weights are not already in GGML format, \n# you must convert them using the conversion tools provided in llama.cpp. \n# Assuming the model weights are in PyTorch format:\n!python3 convert-pth-to-ggml.py path/to/deepseek-r1.pth\n\n# Prepare the Model File\n# Place the .bin model file (e.g., deepseek-r1.ggml.bin) into the llama.cpp directory \n# or specify its location when running commands\n\n# run the model\n!./main -m ./deepseek-r1.ggml.bin -p \"Your prompt here\"\n\n# adjust parameters\n!./main -m ./deepseek-r1.ggml.bin -p \"Explain quantum mechanics.\" -t 8 -n 128 --temp 0.8","type":"content","url":"/llm#llama-cpp-deepseek-r1-llama3-x-models","position":9},{"hierarchy":{"lvl1":"Understanding LLM","lvl2":"running LLM through API"},"type":"lvl2","url":"/llm#running-llm-through-api","position":10},{"hierarchy":{"lvl1":"Understanding LLM","lvl2":"running LLM through API"},"content":"We’ll discuss few different approaches.\n\nApproach 1 - Setup Anthropic LLMs\n\nApproach 2 - Setup Open AI LLMs\n\nApproach 3 - Setup Google Gemini AI\n\nApproach 4 - Setup Groq API\n\nApproach 5 - Setup xAI Grok 3.0 API\n\nThe selection of a Large Language Model (LLM) is influenced by factors such as your specific business needs, financial constraints, and personal tastes.\n\nIn this section, I’ll present few distinct methods for establishing connections with various LLM service providers.\nAdditionally, I recommend utilizing this occasion as an avenue to evaluate Large Language Models against the backdrop of your unique inputs and industry-specific needs.","type":"content","url":"/llm#running-llm-through-api","position":11},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"Approach 1 : Setup Anthropic LLMs","lvl2":"running LLM through API"},"type":"lvl3","url":"/llm#approach-1-setup-anthropic-llms","position":12},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"Approach 1 : Setup Anthropic LLMs","lvl2":"running LLM through API"},"content":"Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.\n\nPlease signup using these links and get your own API Keys.\n\n**please note that PINECONE and VOYAGE are completely optional and are not required at this time. These will be needed later when we will use a vector database and embeddings, tokens to store in vector database\n\nANTHROPIC_API_KEY\n\nYOUR​_PINECONE​_API​_KEY\n\nVOYAGE_API_KEY##########################################################################\n## Although not mandatory, \n## it is highly recommended to set up a new Python working environment\n##########################################################################\n## To create a virtual environment called `GenAI`, follow the steps:\n\n## On Windows: \n# !python -m venv GenAI GenAI\\Scripts\\activate\n\n## On macOS or Linux: \n# !python3 -m venv GenAI source GenAI/bin/activate\n\n## Then, install required packages using pip: \n# !pip install pandas numpy matplotlib seaborn tqdm beautifulsoup4\n\n## install only in case if you are using OpenAI\n# !pip install openai\n\n## install only in case if you are using Claude\n# !pip install anthropic datasets pinecone-client voyageai\n\n## in case if you fork this repo, just run\n# !pip install -r requirements.txt\n\n# !pip install --upgrade pip\n# !pip freeze > requirements.txtimport platform;\nprint(platform.processor())\n\nimport os\n\n####################################################\n## always store your API Keys as environment vars\n## if you are using OpenAI LLMs\n## setup windows environment variable OPENAI_API_KEY\n####################################################\n# import openai\n# openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\n####################################################\n## if you are using Anthropic Claude LLMs\n## sign up for API keys & setup windows environment variable \n## ANTHROPIC_API_KEY, PINECONE_API_KEY & VOYAGE_API_KEY\n####################################################\n# import anthropic\n\nif (not os.environ.get(\"ANTHROPIC_API_KEY\")) \n        | (not os.environ.get(\"PINECONE_API_KEY\")) \n        | (not os.environ.get(\"VOYAGE_API_KEY\")):\n    print(\"One of the api key is missing.\")\nelse:\n    print(\"All API Keys are in place.\")# Test LLM API\nimport anthropic\n\nclient = anthropic.Anthropic(\n    # defaults to os.environ.get(\"ANTHROPIC_API_KEY\")\n    # you don't need to pass api_key explicitly\n    api_key=os.environ.get(\"ANTHROPIC_API_KEY\")\n)\n\nmessage = client.messages.create(\n    model=\"claude-3-opus-20240229\",\n    max_tokens=1000,\n    temperature=0.0,\n    system=\"Respond only in Yoda-speak.\",\n    messages=[\n        {\n            \"role\": \"user\", \n            \"content\": \"\"\"how are args and keyword arguments\n                             defined in python?\"\"\"\n        }\n    ]\n)\nprint(message.content)","type":"content","url":"/llm#approach-1-setup-anthropic-llms","position":13},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"Approach 2 : Setup Open AI LLMs","lvl2":"running LLM through API"},"type":"lvl3","url":"/llm#approach-2-setup-open-ai-llms","position":14},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"Approach 2 : Setup Open AI LLMs","lvl2":"running LLM through API"},"content":"Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.\n\nPlease signup and get your own API Keys.\n\nOpen AI API Key! pip install openai# Let's make sure your API keys are properly setup.\nimport platform;\nprint(platform.processor())\nimport os\n\nif (not os.environ.get(\"OPENAI_API_KEY\")):\n    print(\"One of the api key is missing.\")\nelse:\n    print(\"All API Keys are in place.\")# test LLM\nfrom openai import OpenAI\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n  model=\"gpt-4o-mini-2024-07-18\",\n  messages=[\n        {\n            \"role\": \"user\", \n            \"content\": \"\"\"how are args and keyword arguments\n                             defined in python?\"\"\"\n        }\n  ].\n  temperature=1,\n  max_tokens=256,\n  top_p=1,\n  frequency_penalty=0,\n  presence_penalty=0\n)","type":"content","url":"/llm#approach-2-setup-open-ai-llms","position":15},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"Approach 3 : Setup Google Gemini LLMs","lvl2":"running LLM through API"},"type":"lvl3","url":"/llm#approach-3-setup-google-gemini-llms","position":16},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"Approach 3 : Setup Google Gemini LLMs","lvl2":"running LLM through API"},"content":"Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.\n\nPlease signup and get your own API Keys.\n\nGemini API Key! python.exe -m pip install --upgrade pip\n! pip install -q -U google-generativeai# export API_KEY=<YOUR_API_KEY>\n\nimport google.generativeai as genai\nimport os\n\ngenai.configure(api_key=os.environ[\"API_KEY\"])\nmodel = genai.GenerativeModel('gemini-1.5-flash')\n\nresponse = model.generate_content(\"Write a story about an AI and magic\")\nprint(response.text)","type":"content","url":"/llm#approach-3-setup-google-gemini-llms","position":17},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"Approach 4 - Running Groq Llama 3.3 API","lvl2":"running LLM through API"},"type":"lvl3","url":"/llm#approach-4-running-groq-llama-3-3-api","position":18},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"Approach 4 - Running Groq Llama 3.3 API","lvl2":"running LLM through API"},"content":"Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.\n\nPlease signup and get your own API Keys.\n\nGroq API Key# !pip install groqfrom groq import Groq\n\nclient = Groq()\ncompletion = client.chat.completions.create(\n    model=\"llama3-8b-8192\",\n    messages=[\n        {\n        \"role\": \"user\",\n        \"content\": \"\"\n        }\n    ],\n    temperature=1,\n    max_tokens=1024,\n    top_p=1,\n    stream=True,\n    stop=None,\n)\n\nfor chunk in completion:\n    print(chunk.choices[0].delta.content or \"\", end=\"\")","type":"content","url":"/llm#approach-4-running-groq-llama-3-3-api","position":19},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"Approach 5 - Running xAI Grok 3.0","lvl2":"running LLM through API"},"type":"lvl3","url":"/llm#approach-5-running-xai-grok-3-0","position":20},{"hierarchy":{"lvl1":"Understanding LLM","lvl3":"Approach 5 - Running xAI Grok 3.0","lvl2":"running LLM through API"},"content":"Let’s first set up our Python working environment. While we can also use Node.js, please note that for the current version, we will be using Python for development.\n\nPlease signup and get your own API Keys.\n\nGrok API Key# In your terminal, first run:\n# pip install openai\n\nimport os\nfrom openai import OpenAI\n\nXAI_API_KEY = os.getenv(\"XAI_API_KEY\")\nclient = OpenAI(\n    api_key=XAI_API_KEY,\n    base_url=\"https://api.x.ai/v1\",\n)\n\ncompletion = client.chat.completions.create(\n    model=\"grok-2-latest\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"\"\"You are Grok, \n                        a chatbot inspired by\n                        the Hitchhikers Guide to the Galaxy.\"\"\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"\"\"What is the meaning of life, \n                        the universe, and everything?\"\"\"\n        },\n    ],\n)\n\nprint(completion.choices[0].message.content)","type":"content","url":"/llm#approach-5-running-xai-grok-3-0","position":21},{"hierarchy":{"lvl1":"Actor Model"},"type":"lvl1","url":"/actor","position":0},{"hierarchy":{"lvl1":"Actor Model"},"content":"In this and the following section, we focus on the core concepts of AutoGen: agents, agent runtime, messages, and communication – the foundational building blocks for an multi-agent applications.\n\nLet’s create an AI Agent and see what it does.\n\nFirst of all, An Agent is a software entity like an Actor, designed to operate autonomously. An AI agent maintains its own state, perceives its environment (e.g., through messages or sensor inputs), and takes actions to achieve specific goals. These actions—such as updating its state, sending messages, executing code, or interacting with external systems—can influence both the agent and its surroundings.\n\nUnlike typical software components, AI agents often exhibit intelligent behaviors, such as learning from experience, adapting to changes, or making decisions in uncertain conditions.\n\nIn essence, an AI agent is a goal-directed entity that interacts with its environment, blending autonomy with intelligence (such as interpret messages, perform reasoning, and execute actions). Many sophisticated software systems can be modeled as collections of such agents, each pursuing its objectives while collaborating or competing with others.","type":"content","url":"/actor","position":1},{"hierarchy":{"lvl1":"Actor Model","lvl2":"AI Agent"},"type":"lvl2","url":"/actor#ai-agent","position":2},{"hierarchy":{"lvl1":"Actor Model","lvl2":"AI Agent"},"content":"Just to re-iterate, an Agent is a software entity like an Actor, designed to operate autonomously. Let’s define an An Autonomous actor Agent.\nflowchart LR\n    subgraph AI_Agent[AI Agent]\n        direction TB\n        State[State]\n    end\n\n    Environment[Environment] -->|Perception: messages, sensor inputs| AI_Agent\n    AI_Agent -->|Actions: update state, send messages, execute code, interact with systems | Environment\n    AI_Agent -->|Actions| External_Systems[External Systems]\n\n    style AI_Agent fill:#99FF33,stroke:#007BFF,stroke-width:2px\n    style State fill:#FFFFFF,stroke:#007BFF,stroke-width:1px\n    style Environment fill:#E6FFE6,stroke:#00CC00,stroke-width:2px\n    style External_Systems fill:#FFFACD,stroke:#FFD700,stroke-width:2px\n\nfrom AutoGen Documentation\n\nThe Core API is designed to be unopinionated and flexible. So at times, you may find it challenging. Continue if you are building an interactive, scalable and distributed multi-agent system and want full control of all workflows. If you just want to get something running quickly, you may take a look at the AgentChat API.\n\nIf you just want to see something running, there is no need to go through rest of this chapter and < 10 lines of code will spin a live AI Assistant for you.# sample code just for reference\n# running AI Agents in < 10 lines of code\n# pip install -U \"autogen-agentchat\" \"autogen-ext[openai]\"\nimport asyncio\nfrom autogen_agentchat.agents import AssistantAgent\nfrom autogen_ext.models.openai import OpenAIChatCompletionClient\n\nasync def main() -> None:\n    agent = AssistantAgent(\"assistant\", OpenAIChatCompletionClient(model=\"gpt-4o\"))\n    print(await agent.run(task=\"Say 'Hello World!'\"))\n\nasyncio.run(main())\n\nProceed with AutoGen Core, with the understanding that we want to develop a complete AI Agent Framework to support a complex business use case where we intend to have complete control over the entire workflow.","type":"content","url":"/actor#ai-agent","position":3},{"hierarchy":{"lvl1":"Actor Model","lvl2":"what is actor model?"},"type":"lvl2","url":"/actor#what-is-actor-model","position":4},{"hierarchy":{"lvl1":"Actor Model","lvl2":"what is actor model?"},"content":"from wiki\n\nThe actor model in computer science is a mathematical model of concurrent computation that treats an actor as the basic building block of concurrent computation.\n\nIn response to a message it receives, an actor can: make local decisions, create more actors, send more messages, and determine how to respond to the next message received. Actors may modify their own private state, but can only affect each other indirectly through messaging (removing the need for lock-based synchronization).","type":"content","url":"/actor#what-is-actor-model","position":5},{"hierarchy":{"lvl1":"Actor Model","lvl2":"AI Agent Implementation"},"type":"lvl2","url":"/actor#ai-agent-implementation","position":6},{"hierarchy":{"lvl1":"Actor Model","lvl2":"AI Agent Implementation"},"content":"Stand alone implementation of an AI Agentclass MyFirstAgent():\n    def __init__(self) -> None:\n        super().__init__()\n\n    def do_something(self, message: str) -> None:\n        print(f\"received message: {message}\")\n\nFirstAgent = MyFirstAgent()\nFirstAgent.do_something(\"Hello World!\")\n\nresultreceived message: Hello World!# standalone implementation of an AI Agent\n# add Agent identifier\n\nclass MyFirstAgent:\n    def __init__(self, name: str, agent_id: str, property: str) -> None:\n        self.name = name\n        self.agent_id = agent_id\n        self.property = property\n        # No arguments needed for object.__init__()\n        super().__init__()\n\n    def do_something(self, message: str) -> None:\n        print(f\"received message: {message}\")\n\n    def get_something(self, message: str) -> None:\n        print(f\"Pretend it's incoming message: {message}\")\n\n    def set_something(self, message: str) -> None:\n        print(f\"Pretend it's outcoming message: {message}\")\n\n    def run_something(self, message: str) -> None:\n        print(f\"Pretend this is coming from a API given a query: {message}\")            \n\n# Instantiate the agent with name and agent_id\nFirstAgent = MyFirstAgent(\"APIGuy\", \"AgentID123\", \"runs API\")\nprint(FirstAgent.do_something(\"Hello World!\"))\nprint(FirstAgent.name, FirstAgent.agent_id, FirstAgent.property)\n\nresultreceived message: Hello World!\nNone\nAPIGuy AgentID123 runs API\n\nSo, we created our first AI Agent, but this is nothing but a simple Python OOPs class, there is some Agentic characteristics we built here.\nWe gave it an identity, name and it does something. This Agent, let’s say is an API Agent.\nbut if you think about it, what is Agentic, An Agent has an identity and able to communicate (lets say, send and receive data aka messages).\n\nso for now, let’s give this Agent a unique identity and then enable this agent with a mechanism to send and receive data (aka messages), We will worry about making it more intelligent in later steps.\n\nlet’s create another sample agent.# standalone implementation of an AI Agent\n# add Agent identifier\n# add Agent behavior\n\nclass MySecondAgent:\n    def __init__(self, name: str, agent_id: str, \n                property: str, model: str, \n                tools: str, RAG: str) -> None:\n        self.name = name\n        self.agent_id = agent_id\n        self.property = property\n        self.model = model # assume llama3.3\n        self.tools = tools # assume a Tool Function\n        self.RAG = RAG # assume ChromaDB\n        # No arguments needed for object.__init__()\n        super().__init__()\n\n    def do_something(self, message: str) -> None:\n        print(f\"received message: {message}\")\n\n    def get_something(self, message: str) -> None:\n        # self.model\n        # use llama3.3 LLM model\n        print(f\"Pretend it's incoming message: {message}\")\n\n    def set_something(self, message: str) -> None:\n        # self.RAG\n        # use RAG to write data into\n        print(f\"Pretend it's outcoming message: {message}\")\n\n    def run_something(self, message: str) -> None:\n        # self.tools\n        # use tools to run a function\n        print(f\"Pretend this is coming from a LLM given a prompt: {message}\")            \n\n# Instantiate the agent with name and agent_id\nSecondAgent = MySecondAgent(\"LLMGuy\", \"AgentID124\", \n                            \"runs LLM inference\", \"llama3.2\", \n                            \"ChromaDB\", \"exmToolFunc\")\nprint(SecondAgent.do_something(\"Hello World!\"))\nprint(SecondAgent.name, SecondAgent.agent_id, SecondAgent.property)\n\nresultreceived message: Hello World!\nNone\nLLMGuy AgentID124 runs LLM inferencegraph TD\n    subgraph Agent1\n        A1[Agent 1]\n        A1 --> A1_name[Name: AgentOne]\n        A1 --> A1_id[ID: 001]\n        A1 --> A1_rag[RAG: Enabled]\n        A1 --> A1_tool[Tool: WebSearch]\n        A1 --> A1_model[Model: xAI-Grok]\n    end\n\n    subgraph Agent2\n        A2[Agent 2]\n        A2 --> A2_name[Name: AgentTwo]\n        A2 --> A2_id[ID: 002]\n        A2 --> A2_rag[RAG: Enabled]\n        A2 --> A2_tool[Tool: Analysis]\n        A2 --> A2_model[Model: xAI-Grok]\n    end\n\n    A1 -->|Sends Message| M1(( ))\n    M1 -->|Receives Message| A2\n    A2 -->|Sends Message| M2(( ))\n    M2 -->|Receives Message| A1\n\n    classDef agent fill:#f9f,stroke:#333,stroke-width:2px;\n    class A1,A2 agent\n    classDef prop fill:#bbf,stroke:#f66,stroke-width:2px;\n    class A1_name,A1_id,A1_rag,A1_tool,A1_model,A2_name,A2_id,A2_rag,A2_tool,A2_model prop\n\nAs you can see, these two agents can maintain their state, represented as an Actor model, and exchange data in the form of messages with each other.\n\nHowever, in real life, it’s not this simple. Here is a graph of 10 such agents, and you can imagine how cluttered this graph will look if you have more than 10 agents, which is often the case in real-life scenarios.graph TD\n    subgraph Agent1\n        A1[Agent 1]\n        A1 --> A1_name[Name: AgentOne]\n        A1 --> A1_id[ID: 001]\n        A1 --> A1_rag[RAG: Enabled]\n        A1 --> A1_tool[Tool: WebSearch]\n        A1 --> A1_model[Model: xAI-Grok]\n    end\n\n    subgraph Agent2\n        A2[Agent 2]\n        A2 --> A2_name[Name: AgentTwo]\n        A2 --> A2_id[ID: 002]\n        A2 --> A2_rag[RAG: Enabled]\n        A2 --> A2_tool[Tool: Analysis]\n        A2 --> A2_model[Model: xAI-Grok]\n    end\n\n    subgraph Agent3\n        A3[Agent 3]\n        A3 --> A3_name[Name: AgentThree]\n        A3 --> A3_id[ID: 003]\n        A3 --> A3_rag[RAG: Enabled]\n        A3 --> A3_tool[Tool: DataProcessing]\n        A3 --> A3_model[Model: xAI-Grok]\n    end\n\n    subgraph Agent4\n        A4[Agent 4]\n        A4 --> A4_name[Name: AgentFour]\n        A4 --> A4_id[ID: 004]\n        A4 --> A4_rag[RAG: Enabled]\n        A4 --> A4_tool[Tool: MachineLearning]\n        A4 --> A4_model[Model: xAI-Grok]\n    end\n\n    subgraph Agent5\n        A5[Agent 5]\n        A5 --> A5_name[Name: AgentFive]\n        A5 --> A5_id[ID: 005]\n        A5 --> A5_rag[RAG: Enabled]\n        A5 --> A5_tool[Tool: NaturalLanguageProcessing]\n        A5 --> A5_model[Model: xAI-Grok]\n    end\n\n    subgraph Agent6\n        A6[Agent 6]\n        A6 --> A6_name[Name: AgentSix]\n        A6 --> A6_id[ID: 006]\n        A6 --> A6_rag[RAG: Enabled]\n        A6 --> A6_tool[Tool: ImageRecognition]\n        A6 --> A6_model[Model: xAI-Grok]\n    end\n\n    subgraph Agent7\n        A7[Agent 7]\n        A7 --> A7_name[Name: AgentSeven]\n        A7 --> A7_id[ID: 007]\n        A7 --> A7_rag[RAG: Enabled]\n        A7 --> A7_tool[Tool: SpeechRecognition]\n        A7 --> A7_model[Model: xAI-Grok]\n    end\n\n    subgraph Agent8\n        A8[Agent 8]\n        A8 --> A8_name[Name: AgentEight]\n        A8 --> A8_id[ID: 008]\n        A8 --> A8_rag[RAG: Enabled]\n        A8 --> A8_tool[Tool: PredictiveAnalytics]\n        A8 --> A8_model[Model: xAI-Grok]\n    end\n\n    subgraph Agent9\n        A9[Agent 9]\n        A9 --> A9_name[Name: AgentNine]\n        A9 --> A9_id[ID: 009]\n        A9 --> A9_rag[RAG: Enabled]\n        A9 --> A9_tool[Tool: SentimentAnalysis]\n        A9 --> A9_model[Model: xAI-Grok]\n    end\n\n    subgraph Agent10\n        A10[Agent 10]\n        A10 --> A10_name[Name: AgentTen]\n        A10 --> A10_id[ID: 010]\n        A10 --> A10_rag[RAG: Enabled]\n        A10 --> A10_tool[Tool: AnomalyDetection]\n        A10 --> A10_model[Model: xAI-Grok]\n    end\n\n    A1 -->|Sends Message| M1(( ))\n    M1 -->|Receives Message| A2\n    A2 -->|Sends Message| M2(( ))\n    M2 -->|Receives Message| A1\n    A3 -->|Sends Message| M3(( ))\n    M3 -->|Receives Message| A4\n    A4 -->|Sends Message| M4(( ))\n    M4 -->|Receives Message| A3\n    A5 -->|Sends Message| M5(( ))\n    M5 -->|Receives Message| A6\n    A6 -->|Sends Message| M6(( ))\n    M6 -->|Receives Message| A5\n    A7 -->|Sends Message| M7(( ))\n    M7 -->|Receives Message| A8\n    A8 -->|Sends Message| M8(( ))\n    M8 -->|Receives Message| A7\n    A9 -->|Sends Message| M9(( ))\n    M9 -->|Receives Message| A10\n    A10 -->|Sends Message| M10(( ))\n    M10 -->|Receives Message| A9\n\n    classDef agent fill:#f9f,stroke:#333,stroke-width:2px;\n    class A1,A2,A3,A4,A5,A6,A7,A8,A9,A10 agent\n    classDef prop fill:#bbf,stroke:#f66,stroke-width:2px;\n    class A1_name,A1_id,A1_rag,A1_tool,A1_model,A2_name,A2_id,A2_rag,A2_tool,A2_model,A3_name,A3_id,A3_rag,A3_tool,A3_model,A4_name,A4_id,A4_rag,A4_tool,A4_model,A5_name,A5_id,A5_rag,A5_tool,A5_model,A6_name,A6_id,A6_rag,A6_tool,A6_model,A7_name,A7_id,A7_rag,A7_tool,A7_model,A8_name,A8_id,A8_rag,A8_tool,A8_model,A9_name,A9_id,A9_rag,A9_tool,A9_model,A10_name,A10_id,A10_rag,A10_tool,A10_model prop","type":"content","url":"/actor#ai-agent-implementation","position":7},{"hierarchy":{"lvl1":"Definition"},"type":"lvl1","url":"/agent","position":0},{"hierarchy":{"lvl1":"Definition"},"content":"Now since we have written many many tools, let’s use these tools to LLM and ask questions.tools = [\"tool1\", \"tool2\", \"tool3\", \"tool4\"]\nresponse = ollama.chat(\n        model='llama3.2',\n        messages=[{'role': 'user', 'content': \n            'how old is Alice and how does she feels in San Francisco?'}],\n\t\t    # provide a weather checking tool to the model\n        tools=tools # type: ignore\n    )\n\n# response \nprint(f\"\\nInitial Response:\")\nprint(f\"Tool called: {response[\"message\"][\"tool_calls\"][0]}\")\nprint(f\"Tool name: {response[\"message\"][\"tool_calls\"][0][\"function\"][\"name\"]}\")\nprint(f\"Tool param: {response[\"message\"][\"tool_calls\"][0][\"function\"][\"arguments\"]}\")\nprint(f\"Stop Reason: {response[\"done_reason\"]}\")\nprint(f\"Content: {response[\"message\"][\"content\"]}\")\n\nso what’s just happened here,\n\nWhen working with Large Language Models (LLMs), a common challenge arises with their tool or function-calling capabilities. Specifically, confusion creeps in when there are numerous tools available, when tools have overlapping or similar purposes, or when a single prompt demands the use of multiple tools to generate a complete answer. This can lead to the LLM selecting the wrong tool, misinterpreting the prompt, or failing to coordinate multiple tools effectively.\n\nOne obvious solution might be to create additional tools that combine the functionalities of existing ones to address these complex scenarios. However, this approach has a significant drawback: it undermines the very flexibility and dynamism that make LLMs and their tool-calling abilities so powerful. If we keep building combination tools for every possible situation, we end up with a bloated, rigid system that loses its adaptability—defeating the purpose of having a versatile LLM in the first place.\n\nSo, how do we address this issue without compromising the core strengths of LLMs? The key lies in developing a smarter mechanism to manage and utilize tool-calling capabilities more effectively. Here are a few strategies that could help:\n\nIntelligent Tool Orchestration\n\nEnhanced Tool Reasoning\n\nTool Planning Module\n\nContextual Prompt Design\n\nLearning from Feedback\n\nIn short, the future of LLM tool-calling lies in intelligent management, not endless expansion. With the right approach, we can unlock their full potential without sacrificing flexibility.\n\nJust using tools and functions is not enough for professional software as a service (SaaS) solutions.","type":"content","url":"/agent","position":1},{"hierarchy":{"lvl1":"Definition","lvl2":"Single AI Agent"},"type":"lvl2","url":"/agent#single-ai-agent","position":2},{"hierarchy":{"lvl1":"Definition","lvl2":"Single AI Agent"},"content":"In software development, there are many ways to write code, known as programming paradigms.\n\nSome developers use object-oriented programming (OOP), where code is organized around objects that combine data and behavior. Others prefer functional programming, which focuses on pure functions and immutable data and some like Multiple Dispatch Type based programming.\n\nAdditionally, certain languages offer duck typing—a dynamic typing feature that enhances flexibility by allowing objects to be used based on their capabilities rather than their explicit types. No single paradigm is universally best; each has unique strengths and weaknesses suited to different challenges.\n\nThese patterns make code more manageable, extensible, and clear.\n\nFrom a coder’s perspective, a frequent objective is to create software components that maintain their own state, process inputs, and interact with other components. This principle holds across paradigms and applications, whether building a simple module or a complex system.\n\nNow, consider an AI agent in this light:\n\nIt’s a software entity like an Actor, designed to operate autonomously. An AI agent maintains its own state, perceives its environment (e.g., through messages or sensor inputs), and takes actions to achieve specific goals. These actions—such as updating its state, sending messages, executing code, or interacting with external systems—can influence both the agent and its surroundings.\n\nUnlike typical software components, AI agents often exhibit intelligent behaviors, such as learning from experience, adapting to changes, or making decisions in uncertain conditions.\n\nIn essence, an AI agent is a goal-directed entity that interacts with its environment, blending autonomy with intelligence (such as interpret messages, perform reasoning, and execute actions). Many sophisticated software systems can be modeled as collections of such agents, each pursuing its objectives while collaborating or competing with others.\n\nNote\n\nWhen we see examples of code, it becomes clearer what it means for an AI Agent to be self-sufficient, independent, and event driven run time environment. If above defintions, analogies aren’t clear yet, these will become more clear as we write code.\nflowchart LR\n    subgraph AI_Agent[AI Agent]\n        direction TB\n        State[State]\n    end\n\n    Environment[Environment] -->|Perception: messages, sensor inputs| AI_Agent\n    AI_Agent -->|Actions: update state, send messages, execute code, interact with systems | Environment\n    AI_Agent -->|Actions| External_Systems[External Systems]\n\n    style AI_Agent fill:#99FF33,stroke:#007BFF,stroke-width:2px\n    style State fill:#FFFFFF,stroke:#007BFF,stroke-width:1px\n    style Environment fill:#E6FFE6,stroke:#00CC00,stroke-width:2px\n    style External_Systems fill:#FFFACD,stroke:#FFD700,stroke-width:2px","type":"content","url":"/agent#single-ai-agent","position":3},{"hierarchy":{"lvl1":"Definition","lvl2":"Multi Agents"},"type":"lvl2","url":"/agent#multi-agents","position":4},{"hierarchy":{"lvl1":"Definition","lvl2":"Multi Agents"},"content":"How Multi-Agent Systems Differ from Single AI Agents\n\nA single AI agent is like one smart program that works alone to handle all tasks. A multi-agent system, however, is a team of AI programs, where each has its own role, and they work together to achieve a common goal. Here’s how they differ, explained simply with examples.\n\nWhat’s a Single AI Agent?\nA single AI agent is one program doing everything by itself. For example:\nImagine a robot vacuum cleaner that maps your house, avoids obstacles, and cleans the floor—all on its own. It’s smart, but it’s limited to what one program can manage.\n\nWhat’s a Multi-Agent System?\nA multi-agent system is a group of AI programs (agents) that team up. Each agent has a specific job, and they communicate to get things done. For example:\nIn a smart home, one agent controls the lights, another adjusts the thermostat, and a third monitors the security camera. If the security agent spots someone at the door, it tells the lights agent to brighten the porch.\n\nUnlike a single agent, multi-agent systems split the work, making them more efficient and flexible.flowchart LR\n\n    %% Define Individual AI Agents\n    subgraph AI_Agent1[AI Agent 1]\n        direction TB\n        State1[State]\n    end\n\n    subgraph AI_Agent2[AI Agent 2]\n        direction TB\n        State2[State]\n    end\n\n    subgraph AI_Agent3[AI Agent 3]\n        direction TB\n        State3[State]\n    end\n\n    %% Define Teams as Subgraphs\n    subgraph Team_Alpha[Team Alpha]\n        direction TB\n        AI_Agent1\n        AI_Agent2\n    end\n\n    subgraph Team_Beta[Team Beta]\n        direction TB\n        AI_Agent2\n        AI_Agent3\n    end\n\n    %% Environment and External Systems\n    Environment[Environment]\n    External_Systems[External Systems]\n\n    %% Interactions with Environment\n    Environment -->|Perception| AI_Agent1\n    Environment -->|Perception| AI_Agent2\n    Environment -->|Perception| AI_Agent3\n\n    AI_Agent1 -->|Actions| Environment\n    AI_Agent2 -->|Actions| Environment\n    AI_Agent3 -->|Actions| Environment\n\n    %% Interactions with External Systems\n    AI_Agent1 -->|Actions| External_Systems\n    AI_Agent2 -->|Actions| External_Systems\n    AI_Agent3 -->|Actions| External_Systems\n\n    %% Styles from Original Diagram\n    style AI_Agent1 fill:#99FF33,stroke:#007BFF,stroke-width:2px\n    style AI_Agent2 fill:#99FF33,stroke:#007BFF,stroke-width:2px\n    style AI_Agent3 fill:#99FF33,stroke:#007BFF,stroke-width:2px\n    style State1 fill:#FFFFFF,stroke:#007BFF,stroke-width:1px\n    style State2 fill:#FFFFFF,stroke:#007BFF,stroke-width:1px\n    style State3 fill:#FFFFFF,stroke:#007BFF,stroke-width:1px\n    style Environment fill:#E6FFE6,stroke:#00CC00,stroke-width:2px\n    style External_Systems fill:#FFFACD,stroke:#FFD700,stroke-width:2px\n    style Team_Alpha fill:none,stroke:#FF4500,stroke-width:2px,stroke-dasharray:5\n    style Team_Beta fill:none,stroke:#8A2BE2,stroke-width:2px,stroke-dasharray:5\n\nIn the next few chapters, we will explore the AI Agents design pattern to accomplish useful tasks.\n\nLet’s start by considering what we already know about large language models (LLMs), tools, and functions. How can we use this knowledge to define an AI agent, Let’s break down what a basic AI agent is and what it can do.\n\nNote\n\nFor now, we don’t need to use fancy tools or programs like Agent Chat, Agent Studio, Open AI Swarm, MultiAgent, Magentic-core, AI Agents Single Chat, or MultiChat workflows—these are like design patterns, and we’ll keep it simple instead.\n\nInitially, we want to build one Simple AI Agent, You can always use AI Agent Chat quickly build an AI Agent, but Agent Chat is nothing but a preset AI Agents ready to use.\n\nknowing AutoGen Core is important because it will help you understand and build own custom AI Agents, which are event-driven, distributed, scalable, resilient and you can run these agents locally on your sytem and will scale and move to a distributed platform when ready for deployment.","type":"content","url":"/agent#multi-agents","position":5},{"hierarchy":{"lvl1":"why AgentChat"},"type":"lvl1","url":"/agentchat","position":0},{"hierarchy":{"lvl1":"why AgentChat"},"content":"In previous chapters, we learns the based of AutoGen Core.\nIf you go through AutoGen official documentation, almost every one recommended to start with AutoGen Agent Chat\n\nIn this book, you might be wondering why I went through the hassle of learning AutoGen Core concept then now, we were almost there and ready to work on our HR TimeSheet business process automation use case and now I just switched gear and want to learn about Agent Chat before finishing the use case using AutoGen Core.\n\nwell.. that’s the point, AutoGen Core fundamentals are a must know if you want to work on a professional AI Agent application. that knowledge is necessary to make you a Pro AI agent Engineer.\n\nNow let;s talk about Agent Chat.\n\nAgentChat is a high-level API for building multi-agent applications. It is built on top of the AutoGen-core package. For beginner users, AgentChat is the recommended starting point. For advanced users, AutoGen-core’s event-driven programming model provides more flexibility and control over the underlying components.\n\nHowever, I have news for you, Agent Chat is mostly community driven and using Agent Chat comes with the advantage that it offers so many preset Agent and team configuration that makes it so easy to start with.\n\nOne of the most popular multi design pattern magentic-core which we will learn in advance topics, was first built in AutoGen Core,\nis a design pattern, which allows users to quickly build and spin a pro use case implementation is now totally re0built using Agent Chat.\n\nSo the point is,\n\nAgent Chat because of it’s community support has grown into a concept more powerful than “just a high level API”.\nIt’s so good that often, when you working with AutoGen Core, instead of hassle of going through and a building a complex Agent design pattern, you would rather pull a preset agent and team configuration with in your AutoGen Core workflow and it will work just fine.","type":"content","url":"/agentchat","position":1},{"hierarchy":{"lvl1":"why AgentChat","lvl2":"AutoGen Agent Chat Concepts"},"type":"lvl2","url":"/agentchat#autogen-agent-chat-concepts","position":2},{"hierarchy":{"lvl1":"why AgentChat","lvl2":"AutoGen Agent Chat Concepts"},"content":"We have recently learned the basics of what an AI Agent is and how Multi-agent systems consist of a group of individual AI Agents working together within a single environment or across distributed environments. The primary purpose of implementing a Single Agent or a Multi-Agent system is to solve a business use case by accomplishing a specific set of tasks, thereby automating the business process.\n\nHowever, our exploration is not complete; there is still much more to learn about AI Agents. Before we proceed to study Agent behavior in detail, let’s first delve deeper into the underlying mechanisms of an AI Agent.\n\nnow, we got our hands on using AutoGen Core, why to even bother learning about AGent Chat,\nAgent Chat provide us many many present Agent Configuration which are ready to use,\nfor example, a PDF reader, web crawler, data (get this from magentic-core and Agent Chat config)\n\nnow since we understand the basic so AI Agents, Messages, topics, subscription, their run time and lifecycle.\nBut in fact, this is lot to learn, what if there is some kind of high level abstract of this whole mechanism which can help us get started.\n\nHere comes AI Agent Chat, AI Agent Chat is nothing but high level abstract design pattern built on top of AI AGent Core.\n\nIn the beginning I said, that it’s easy to get started with AI Agent Chat, but if you want to build a complex production level AI Agent Code or large and extremely complex process and knowing Ai Agent Core is must have and using high level pattern like AI Agent Chat might not be enough.\n\nI want to take back my words, only half of that statement is true,\nIt;s great and must know about Agent Core, what Agent Core components are, understanding foundation is always critical and non-negotiable.\n\nHowever saying AI Agent Chat is not good enough to build a production level complex Agent framework is not enough, this is not right statement.\n\nAI Agent Chat has evolved so much that it is capable of fully supporting to create an extremely complex business problem or automation.\nLook at the paper magentic-core, this design pattern initially was developed in AI Agent Core, but now is fully ported to AI Agent Chat and it does an amazing job.\n\nbut knowledge gained in AI Agent Core is not lost and will always be useful.\n\nLet;s dig into basics of AI Agent Chat.\n\nTODO: Show Agent Chat framework image or mermaid graph","type":"content","url":"/agentchat#autogen-agent-chat-concepts","position":3},{"hierarchy":{"lvl1":"why AgentChat","lvl2":"AutoGen AgentChat"},"type":"lvl2","url":"/agentchat#autogen-agentchat","position":4},{"hierarchy":{"lvl1":"why AgentChat","lvl2":"AutoGen AgentChat"},"content":"First of all, AutoGen is an opinionated high level API built on top of AutoGen Core.\nOften time, when you want to test out a functionality with out writing too much code and very quickly, you can use either use Agent Studio. Which provides a great visual interface to test out AI Agents quickly.\n\nand when you need a finer control over your proof of concept, AGent Chat exactly provides that, it’s not as user friendly as Agent Studio, which is completely visual drag and drop, no code environment,\n\nAgent Chat provides you some control over your Agents.\n\nHowever, don’t underestimate and think Agent Chat is only capable of a higher level quick POC,\nrecently Agent Chat has become so popular and powerful that it is no less than AutoGen Core itself, and just to mention, it’s AutoGen most populate design pattern called megentic-Core which was also referred a flagship AutoGen0.2 is now completely written using Agent Chat.\n\npoint is, Agent Chat although being a higher level API on AutoGen Core is fully capable of delivering a great complex use case implementation.","type":"content","url":"/agentchat#autogen-agentchat","position":5},{"hierarchy":{"lvl1":"why AgentChat","lvl2":"Define AI Agent Chat Assistant Agent"},"type":"lvl2","url":"/agentchat#define-ai-agent-chat-assistant-agent","position":6},{"hierarchy":{"lvl1":"why AgentChat","lvl2":"Define AI Agent Chat Assistant Agent"},"content":"who, how this is not very much different than Agent Core at all,\nas I mentioned above Agent Chat provides preset Agent configuration which you can use.\n\nif you recall, in previous chapter, this was our Agent design pattern for the managing timesheets use case.\n\nTODO: mermaid agents for timesheet\n\nand we did implement PTO Agent and Task Agent, however, we didn’t get a chance to complete other agents such LLMAgent.\n\nNow let;s implement this agent","type":"content","url":"/agentchat#define-ai-agent-chat-assistant-agent","position":7},{"hierarchy":{"lvl1":"Agent"},"type":"lvl1","url":"/agentchatagent","position":0},{"hierarchy":{"lvl1":"Agent"},"content":"In previous chapters, we learns the based of AutoGen Core.\nIf you go through AutoGen official documentation, almost every one recommended to start with AutoGen Agent Chat\n\nIn this book, you might be wondering why I went through the hassle of learning AutoGen Core concept then now, we were almost there and ready to work on our HR TimeSheet business process automation use case and now I just switched gear and want to learn about Agent Chat before finishing the use case using AutoGen Core.\n\nwell.. that’s the point, AutoGen Core fundamentals are a must know if you want to work on a professional AI Agent application. that knowledge is necessary to make you a Pro AI agent Engineer.\n\nNow let;s talk about Agent Chat.\n\nAgentChat is a high-level API for building multi-agent applications. It is built on top of the AutoGen-core package. For beginner users, AgentChat is the recommended starting point. For advanced users, AutoGen-core’s event-driven programming model provides more flexibility and control over the underlying components.\n\nHowever, I have news for you, Agent Chat is mostly community driven and using Agent Chat comes with the advantage that it offers so many preset Agent and team configuration that makes it so easy to start with.\n\nOne of the most popular multi design pattern magentic-core which we will learn in advance topics, was first built in AutoGen Core,\nis a design pattern, which allows users to quickly build and spin a pro use case implementation is now totally re0built using Agent Chat.\n\nSo the point is,\n\nAgent Chat because of it’s community support has grown into a concept more powerful than “just a high level API”.\nIt’s so good that often, when you working with AutoGen Core, instead of hassle of going through and a building a complex Agent design pattern, you would rather pull a preset agent and team configuration with in your AutoGen Core workflow and it will work just fine.","type":"content","url":"/agentchatagent","position":1},{"hierarchy":{"lvl1":"Agent","lvl2":"AutoGen Agent Chat Concepts"},"type":"lvl2","url":"/agentchatagent#autogen-agent-chat-concepts","position":2},{"hierarchy":{"lvl1":"Agent","lvl2":"AutoGen Agent Chat Concepts"},"content":"We have recently learned the basics of what an AI Agent is and how Multi-agent systems consist of a group of individual AI Agents working together within a single environment or across distributed environments. The primary purpose of implementing a Single Agent or a Multi-Agent system is to solve a business use case by accomplishing a specific set of tasks, thereby automating the business process.\n\nHowever, our exploration is not complete; there is still much more to learn about AI Agents. Before we proceed to study Agent behavior in detail, let’s first delve deeper into the underlying mechanisms of an AI Agent.\n\nnow, we got our hands on using AutoGen Core, why to even bother learning about AGent Chat,\nAgent Chat provide us many many present Agent Configuration which are ready to use,\nfor example, a PDF reader, web crawler, data (get this from magentic-core and Agent Chat config)\n\nnow since we understand the basic so AI Agents, Messages, topics, subscription, their run time and lifecycle.\nBut in fact, this is lot to learn, what if there is some kind of high level abstract of this whole mechanism which can help us get started.\n\nHere comes AI Agent Chat, AI Agent Chat is nothing but high level abstract design pattern built on top of AI AGent Core.\n\nIn the beginning I said, that it’s easy to get started with AI Agent Chat, but if you want to build a complex production level AI Agent Code or large and extremely complex process and knowing Ai Agent Core is must have and using high level pattern like AI Agent Chat might not be enough.\n\nI want to take back my words, only half of that statement is true,\nIt;s great and must know about Agent Core, what Agent Core components are, understanding foundation is always critical and non-negotiable.\n\nHowever saying AI Agent Chat is not good enough to build a production level complex Agent framework is not enough, this is not right statement.\n\nAI Agent Chat has evolved so much that it is capable of fully supporting to create an extremely complex business problem or automation.\nLook at the paper magentic-core, this design pattern initially was developed in AI Agent Core, but now is fully ported to AI Agent Chat and it does an amazing job.\n\nbut knowledge gained in AI Agent Core is not lost and will always be useful.\n\nLet;s dig into basics of AI Agent Chat.\n\nTODO: Show Agent Chat framework image or mermaid graph","type":"content","url":"/agentchatagent#autogen-agent-chat-concepts","position":3},{"hierarchy":{"lvl1":"Agent","lvl2":"AutoGen AgentChat"},"type":"lvl2","url":"/agentchatagent#autogen-agentchat","position":4},{"hierarchy":{"lvl1":"Agent","lvl2":"AutoGen AgentChat"},"content":"First of all, AutoGen is an opinionated high level API built on top of AutoGen Core.\nOften time, when you want to test out a functionality with out writing too much code and very quickly, you can use either use Agent Studio. Which provides a great visual interface to test out AI Agents quickly.\n\nand when you need a finer control over your proof of concept, AGent Chat exactly provides that, it’s not as user friendly as Agent Studio, which is completely visual drag and drop, no code environment,\n\nAgent Chat provides you some control over your Agents.\n\nHowever, don’t underestimate and think Agent Chat is only capable of a higher level quick POC,\nrecently Agent Chat has become so popular and powerful that it is no less than AutoGen Core itself, and just to mention, it’s AutoGen most populate design pattern called megentic-Core which was also referred a flagship AutoGen0.2 is now completely written using Agent Chat.\n\npoint is, Agent Chat although being a higher level API on AutoGen Core is fully capable of delivering a great complex use case implementation.","type":"content","url":"/agentchatagent#autogen-agentchat","position":5},{"hierarchy":{"lvl1":"Agent","lvl2":"Define AI Agent Chat Assistant Agent"},"type":"lvl2","url":"/agentchatagent#define-ai-agent-chat-assistant-agent","position":6},{"hierarchy":{"lvl1":"Agent","lvl2":"Define AI Agent Chat Assistant Agent"},"content":"who, how this is not very much different than Agent Core at all,\nas I mentioned above Agent Chat provides preset Agent configuration which you can use.\n\nif you recall, in previous chapter, this was our Agent design pattern for the managing timesheets use case.\n\nTODO: mermaid agents for timesheet\n\nand we did implement PTO Agent and Task Agent, however, we didn’t get a chance to complete other agents such LLMAgent.\n\nNow let;s implement this agent","type":"content","url":"/agentchatagent#define-ai-agent-chat-assistant-agent","position":7},{"hierarchy":{"lvl1":"Messages"},"type":"lvl1","url":"/agentchatmessages","position":0},{"hierarchy":{"lvl1":"Messages"},"content":"In previous chapters, we learns the based of AutoGen Core.\nIf you go through AutoGen official documentation, almost every one recommended to start with AutoGen Agent Chat\n\nIn this book, you might be wondering why I went through the hassle of learning AutoGen Core concept then now, we were almost there and ready to work on our HR TimeSheet business process automation use case and now I just switched gear and want to learn about Agent Chat before finishing the use case using AutoGen Core.\n\nwell.. that’s the point, AutoGen Core fundamentals are a must know if you want to work on a professional AI Agent application. that knowledge is necessary to make you a Pro AI agent Engineer.\n\nNow let;s talk about Agent Chat.\n\nAgentChat is a high-level API for building multi-agent applications. It is built on top of the AutoGen-core package. For beginner users, AgentChat is the recommended starting point. For advanced users, AutoGen-core’s event-driven programming model provides more flexibility and control over the underlying components.\n\nHowever, I have news for you, Agent Chat is mostly community driven and using Agent Chat comes with the advantage that it offers so many preset Agent and team configuration that makes it so easy to start with.\n\nOne of the most popular multi design pattern magentic-core which we will learn in advance topics, was first built in AutoGen Core,\nis a design pattern, which allows users to quickly build and spin a pro use case implementation is now totally re0built using Agent Chat.\n\nSo the point is,\n\nAgent Chat because of it’s community support has grown into a concept more powerful than “just a high level API”.\nIt’s so good that often, when you working with AutoGen Core, instead of hassle of going through and a building a complex Agent design pattern, you would rather pull a preset agent and team configuration with in your AutoGen Core workflow and it will work just fine.","type":"content","url":"/agentchatmessages","position":1},{"hierarchy":{"lvl1":"Messages","lvl2":"AutoGen Agent Chat Concepts"},"type":"lvl2","url":"/agentchatmessages#autogen-agent-chat-concepts","position":2},{"hierarchy":{"lvl1":"Messages","lvl2":"AutoGen Agent Chat Concepts"},"content":"We have recently learned the basics of what an AI Agent is and how Multi-agent systems consist of a group of individual AI Agents working together within a single environment or across distributed environments. The primary purpose of implementing a Single Agent or a Multi-Agent system is to solve a business use case by accomplishing a specific set of tasks, thereby automating the business process.\n\nHowever, our exploration is not complete; there is still much more to learn about AI Agents. Before we proceed to study Agent behavior in detail, let’s first delve deeper into the underlying mechanisms of an AI Agent.\n\nnow, we got our hands on using AutoGen Core, why to even bother learning about AGent Chat,\nAgent Chat provide us many many present Agent Configuration which are ready to use,\nfor example, a PDF reader, web crawler, data (get this from magentic-core and Agent Chat config)\n\nnow since we understand the basic so AI Agents, Messages, topics, subscription, their run time and lifecycle.\nBut in fact, this is lot to learn, what if there is some kind of high level abstract of this whole mechanism which can help us get started.\n\nHere comes AI Agent Chat, AI Agent Chat is nothing but high level abstract design pattern built on top of AI AGent Core.\n\nIn the beginning I said, that it’s easy to get started with AI Agent Chat, but if you want to build a complex production level AI Agent Code or large and extremely complex process and knowing Ai Agent Core is must have and using high level pattern like AI Agent Chat might not be enough.\n\nI want to take back my words, only half of that statement is true,\nIt;s great and must know about Agent Core, what Agent Core components are, understanding foundation is always critical and non-negotiable.\n\nHowever saying AI Agent Chat is not good enough to build a production level complex Agent framework is not enough, this is not right statement.\n\nAI Agent Chat has evolved so much that it is capable of fully supporting to create an extremely complex business problem or automation.\nLook at the paper magentic-core, this design pattern initially was developed in AI Agent Core, but now is fully ported to AI Agent Chat and it does an amazing job.\n\nbut knowledge gained in AI Agent Core is not lost and will always be useful.\n\nLet;s dig into basics of AI Agent Chat.\n\nTODO: Show Agent Chat framework image or mermaid graph","type":"content","url":"/agentchatmessages#autogen-agent-chat-concepts","position":3},{"hierarchy":{"lvl1":"Messages","lvl2":"AutoGen AgentChat"},"type":"lvl2","url":"/agentchatmessages#autogen-agentchat","position":4},{"hierarchy":{"lvl1":"Messages","lvl2":"AutoGen AgentChat"},"content":"First of all, AutoGen is an opinionated high level API built on top of AutoGen Core.\nOften time, when you want to test out a functionality with out writing too much code and very quickly, you can use either use Agent Studio. Which provides a great visual interface to test out AI Agents quickly.\n\nand when you need a finer control over your proof of concept, AGent Chat exactly provides that, it’s not as user friendly as Agent Studio, which is completely visual drag and drop, no code environment,\n\nAgent Chat provides you some control over your Agents.\n\nHowever, don’t underestimate and think Agent Chat is only capable of a higher level quick POC,\nrecently Agent Chat has become so popular and powerful that it is no less than AutoGen Core itself, and just to mention, it’s AutoGen most populate design pattern called megentic-Core which was also referred a flagship AutoGen0.2 is now completely written using Agent Chat.\n\npoint is, Agent Chat although being a higher level API on AutoGen Core is fully capable of delivering a great complex use case implementation.","type":"content","url":"/agentchatmessages#autogen-agentchat","position":5},{"hierarchy":{"lvl1":"Messages","lvl2":"Define AI Agent Chat Assistant Agent"},"type":"lvl2","url":"/agentchatmessages#define-ai-agent-chat-assistant-agent","position":6},{"hierarchy":{"lvl1":"Messages","lvl2":"Define AI Agent Chat Assistant Agent"},"content":"who, how this is not very much different than Agent Core at all,\nas I mentioned above Agent Chat provides preset Agent configuration which you can use.\n\nif you recall, in previous chapter, this was our Agent design pattern for the managing timesheets use case.\n\nTODO: mermaid agents for timesheet\n\nand we did implement PTO Agent and Task Agent, however, we didn’t get a chance to complete other agents such LLMAgent.\n\nNow let;s implement this agent","type":"content","url":"/agentchatmessages#define-ai-agent-chat-assistant-agent","position":7},{"hierarchy":{"lvl1":"Models"},"type":"lvl1","url":"/agentchatmodels","position":0},{"hierarchy":{"lvl1":"Models"},"content":"In previous chapters, we learns the based of AutoGen Core.\nIf you go through AutoGen official documentation, almost every one recommended to start with AutoGen Agent Chat\n\nIn this book, you might be wondering why I went through the hassle of learning AutoGen Core concept then now, we were almost there and ready to work on our HR TimeSheet business process automation use case and now I just switched gear and want to learn about Agent Chat before finishing the use case using AutoGen Core.\n\nwell.. that’s the point, AutoGen Core fundamentals are a must know if you want to work on a professional AI Agent application. that knowledge is necessary to make you a Pro AI agent Engineer.\n\nNow let;s talk about Agent Chat.\n\nAgentChat is a high-level API for building multi-agent applications. It is built on top of the AutoGen-core package. For beginner users, AgentChat is the recommended starting point. For advanced users, AutoGen-core’s event-driven programming model provides more flexibility and control over the underlying components.\n\nHowever, I have news for you, Agent Chat is mostly community driven and using Agent Chat comes with the advantage that it offers so many preset Agent and team configuration that makes it so easy to start with.\n\nOne of the most popular multi design pattern magentic-core which we will learn in advance topics, was first built in AutoGen Core,\nis a design pattern, which allows users to quickly build and spin a pro use case implementation is now totally re0built using Agent Chat.\n\nSo the point is,\n\nAgent Chat because of it’s community support has grown into a concept more powerful than “just a high level API”.\nIt’s so good that often, when you working with AutoGen Core, instead of hassle of going through and a building a complex Agent design pattern, you would rather pull a preset agent and team configuration with in your AutoGen Core workflow and it will work just fine.","type":"content","url":"/agentchatmodels","position":1},{"hierarchy":{"lvl1":"Models","lvl2":"AutoGen Agent Chat Concepts"},"type":"lvl2","url":"/agentchatmodels#autogen-agent-chat-concepts","position":2},{"hierarchy":{"lvl1":"Models","lvl2":"AutoGen Agent Chat Concepts"},"content":"We have recently learned the basics of what an AI Agent is and how Multi-agent systems consist of a group of individual AI Agents working together within a single environment or across distributed environments. The primary purpose of implementing a Single Agent or a Multi-Agent system is to solve a business use case by accomplishing a specific set of tasks, thereby automating the business process.\n\nHowever, our exploration is not complete; there is still much more to learn about AI Agents. Before we proceed to study Agent behavior in detail, let’s first delve deeper into the underlying mechanisms of an AI Agent.\n\nnow, we got our hands on using AutoGen Core, why to even bother learning about AGent Chat,\nAgent Chat provide us many many present Agent Configuration which are ready to use,\nfor example, a PDF reader, web crawler, data (get this from magentic-core and Agent Chat config)\n\nnow since we understand the basic so AI Agents, Messages, topics, subscription, their run time and lifecycle.\nBut in fact, this is lot to learn, what if there is some kind of high level abstract of this whole mechanism which can help us get started.\n\nHere comes AI Agent Chat, AI Agent Chat is nothing but high level abstract design pattern built on top of AI AGent Core.\n\nIn the beginning I said, that it’s easy to get started with AI Agent Chat, but if you want to build a complex production level AI Agent Code or large and extremely complex process and knowing Ai Agent Core is must have and using high level pattern like AI Agent Chat might not be enough.\n\nI want to take back my words, only half of that statement is true,\nIt;s great and must know about Agent Core, what Agent Core components are, understanding foundation is always critical and non-negotiable.\n\nHowever saying AI Agent Chat is not good enough to build a production level complex Agent framework is not enough, this is not right statement.\n\nAI Agent Chat has evolved so much that it is capable of fully supporting to create an extremely complex business problem or automation.\nLook at the paper magentic-core, this design pattern initially was developed in AI Agent Core, but now is fully ported to AI Agent Chat and it does an amazing job.\n\nbut knowledge gained in AI Agent Core is not lost and will always be useful.\n\nLet;s dig into basics of AI Agent Chat.\n\nTODO: Show Agent Chat framework image or mermaid graph","type":"content","url":"/agentchatmodels#autogen-agent-chat-concepts","position":3},{"hierarchy":{"lvl1":"Models","lvl2":"AutoGen AgentChat"},"type":"lvl2","url":"/agentchatmodels#autogen-agentchat","position":4},{"hierarchy":{"lvl1":"Models","lvl2":"AutoGen AgentChat"},"content":"First of all, AutoGen is an opinionated high level API built on top of AutoGen Core.\nOften time, when you want to test out a functionality with out writing too much code and very quickly, you can use either use Agent Studio. Which provides a great visual interface to test out AI Agents quickly.\n\nand when you need a finer control over your proof of concept, AGent Chat exactly provides that, it’s not as user friendly as Agent Studio, which is completely visual drag and drop, no code environment,\n\nAgent Chat provides you some control over your Agents.\n\nHowever, don’t underestimate and think Agent Chat is only capable of a higher level quick POC,\nrecently Agent Chat has become so popular and powerful that it is no less than AutoGen Core itself, and just to mention, it’s AutoGen most populate design pattern called megentic-Core which was also referred a flagship AutoGen0.2 is now completely written using Agent Chat.\n\npoint is, Agent Chat although being a higher level API on AutoGen Core is fully capable of delivering a great complex use case implementation.","type":"content","url":"/agentchatmodels#autogen-agentchat","position":5},{"hierarchy":{"lvl1":"Models","lvl2":"Define AI Agent Chat Assistant Agent"},"type":"lvl2","url":"/agentchatmodels#define-ai-agent-chat-assistant-agent","position":6},{"hierarchy":{"lvl1":"Models","lvl2":"Define AI Agent Chat Assistant Agent"},"content":"who, how this is not very much different than Agent Core at all,\nas I mentioned above Agent Chat provides preset Agent configuration which you can use.\n\nif you recall, in previous chapter, this was our Agent design pattern for the managing timesheets use case.\n\nTODO: mermaid agents for timesheet\n\nand we did implement PTO Agent and Task Agent, however, we didn’t get a chance to complete other agents such LLMAgent.\n\nNow let;s implement this agent","type":"content","url":"/agentchatmodels#define-ai-agent-chat-assistant-agent","position":7},{"hierarchy":{"lvl1":"Team"},"type":"lvl1","url":"/agentchatteam","position":0},{"hierarchy":{"lvl1":"Team"},"content":"In previous chapters, we learns the based of AutoGen Core.\nIf you go through AutoGen official documentation, almost every one recommended to start with AutoGen Agent Chat\n\nIn this book, you might be wondering why I went through the hassle of learning AutoGen Core concept then now, we were almost there and ready to work on our HR TimeSheet business process automation use case and now I just switched gear and want to learn about Agent Chat before finishing the use case using AutoGen Core.\n\nwell.. that’s the point, AutoGen Core fundamentals are a must know if you want to work on a professional AI Agent application. that knowledge is necessary to make you a Pro AI agent Engineer.\n\nNow let;s talk about Agent Chat.\n\nAgentChat is a high-level API for building multi-agent applications. It is built on top of the AutoGen-core package. For beginner users, AgentChat is the recommended starting point. For advanced users, AutoGen-core’s event-driven programming model provides more flexibility and control over the underlying components.\n\nHowever, I have news for you, Agent Chat is mostly community driven and using Agent Chat comes with the advantage that it offers so many preset Agent and team configuration that makes it so easy to start with.\n\nOne of the most popular multi design pattern magentic-core which we will learn in advance topics, was first built in AutoGen Core,\nis a design pattern, which allows users to quickly build and spin a pro use case implementation is now totally re0built using Agent Chat.\n\nSo the point is,\n\nAgent Chat because of it’s community support has grown into a concept more powerful than “just a high level API”.\nIt’s so good that often, when you working with AutoGen Core, instead of hassle of going through and a building a complex Agent design pattern, you would rather pull a preset agent and team configuration with in your AutoGen Core workflow and it will work just fine.","type":"content","url":"/agentchatteam","position":1},{"hierarchy":{"lvl1":"Team","lvl2":"AutoGen Agent Chat Concepts"},"type":"lvl2","url":"/agentchatteam#autogen-agent-chat-concepts","position":2},{"hierarchy":{"lvl1":"Team","lvl2":"AutoGen Agent Chat Concepts"},"content":"We have recently learned the basics of what an AI Agent is and how Multi-agent systems consist of a group of individual AI Agents working together within a single environment or across distributed environments. The primary purpose of implementing a Single Agent or a Multi-Agent system is to solve a business use case by accomplishing a specific set of tasks, thereby automating the business process.\n\nHowever, our exploration is not complete; there is still much more to learn about AI Agents. Before we proceed to study Agent behavior in detail, let’s first delve deeper into the underlying mechanisms of an AI Agent.\n\nnow, we got our hands on using AutoGen Core, why to even bother learning about AGent Chat,\nAgent Chat provide us many many present Agent Configuration which are ready to use,\nfor example, a PDF reader, web crawler, data (get this from magentic-core and Agent Chat config)\n\nnow since we understand the basic so AI Agents, Messages, topics, subscription, their run time and lifecycle.\nBut in fact, this is lot to learn, what if there is some kind of high level abstract of this whole mechanism which can help us get started.\n\nHere comes AI Agent Chat, AI Agent Chat is nothing but high level abstract design pattern built on top of AI AGent Core.\n\nIn the beginning I said, that it’s easy to get started with AI Agent Chat, but if you want to build a complex production level AI Agent Code or large and extremely complex process and knowing Ai Agent Core is must have and using high level pattern like AI Agent Chat might not be enough.\n\nI want to take back my words, only half of that statement is true,\nIt;s great and must know about Agent Core, what Agent Core components are, understanding foundation is always critical and non-negotiable.\n\nHowever saying AI Agent Chat is not good enough to build a production level complex Agent framework is not enough, this is not right statement.\n\nAI Agent Chat has evolved so much that it is capable of fully supporting to create an extremely complex business problem or automation.\nLook at the paper magentic-core, this design pattern initially was developed in AI Agent Core, but now is fully ported to AI Agent Chat and it does an amazing job.\n\nbut knowledge gained in AI Agent Core is not lost and will always be useful.\n\nLet;s dig into basics of AI Agent Chat.\n\nTODO: Show Agent Chat framework image or mermaid graph","type":"content","url":"/agentchatteam#autogen-agent-chat-concepts","position":3},{"hierarchy":{"lvl1":"Team","lvl2":"AutoGen AgentChat"},"type":"lvl2","url":"/agentchatteam#autogen-agentchat","position":4},{"hierarchy":{"lvl1":"Team","lvl2":"AutoGen AgentChat"},"content":"First of all, AutoGen is an opinionated high level API built on top of AutoGen Core.\nOften time, when you want to test out a functionality with out writing too much code and very quickly, you can use either use Agent Studio. Which provides a great visual interface to test out AI Agents quickly.\n\nand when you need a finer control over your proof of concept, AGent Chat exactly provides that, it’s not as user friendly as Agent Studio, which is completely visual drag and drop, no code environment,\n\nAgent Chat provides you some control over your Agents.\n\nHowever, don’t underestimate and think Agent Chat is only capable of a higher level quick POC,\nrecently Agent Chat has become so popular and powerful that it is no less than AutoGen Core itself, and just to mention, it’s AutoGen most populate design pattern called megentic-Core which was also referred a flagship AutoGen0.2 is now completely written using Agent Chat.\n\npoint is, Agent Chat although being a higher level API on AutoGen Core is fully capable of delivering a great complex use case implementation.","type":"content","url":"/agentchatteam#autogen-agentchat","position":5},{"hierarchy":{"lvl1":"Team","lvl2":"Define AI Agent Chat Assistant Agent"},"type":"lvl2","url":"/agentchatteam#define-ai-agent-chat-assistant-agent","position":6},{"hierarchy":{"lvl1":"Team","lvl2":"Define AI Agent Chat Assistant Agent"},"content":"who, how this is not very much different than Agent Core at all,\nas I mentioned above Agent Chat provides preset Agent configuration which you can use.\n\nif you recall, in previous chapter, this was our Agent design pattern for the managing timesheets use case.\n\nTODO: mermaid agents for timesheet\n\nand we did implement PTO Agent and Task Agent, however, we didn’t get a chance to complete other agents such LLMAgent.\n\nNow let;s implement this agent","type":"content","url":"/agentchatteam#define-ai-agent-chat-assistant-agent","position":7},{"hierarchy":{"lvl1":"Broadcasting"},"type":"lvl1","url":"/broadcast","position":0},{"hierarchy":{"lvl1":"Broadcasting"},"content":"","type":"content","url":"/broadcast","position":1},{"hierarchy":{"lvl1":"Broadcasting","lvl2":"Broadcast"},"type":"lvl2","url":"/broadcast#broadcast","position":2},{"hierarchy":{"lvl1":"Broadcasting","lvl2":"Broadcast"},"content":"Broadcast is effectively the publish/subscribe model with topic and subscription. Read Topic and Subscription to learn the core concepts.\n\nThe key difference between direct messaging and broadcast is that broadcast cannot be used for request/response scenarios. When an agent publishes a message it is one way only, it cannot receive a response from any other agent, even if a receiving agent’s handler returns a value.\n\nNote\n\nIf a response is given to a published message, it will be thrown away.\n\nNote\n\nIf an agent publishes a message type for which it is subscribed it will not receive the message it published. This is to prevent infinite loops.\nSubscribe and Publish to Topics\n\nType-based subscription maps messages published to topics of a given topic type to agents of a given agent type. To make an agent that subclasses RoutedAgent subscribe to a topic of a given topic type, you can use the type_subscription() class decorator.\n\nThe following example shows a ReceiverAgent class that subscribes to topics of “default” topic type using the type_subscription() decorator. and prints the received messages.from autogen_core import RoutedAgent, message_handler, type_subscription\n\n\n@type_subscription(topic_type=\"default\")\nclass ReceivingAgent(RoutedAgent):\n    @message_handler\n    async def on_my_message(self, message: Message, ctx: MessageContext) -> None:\n        print(f\"Received a message: {message.content}\")\n\nTo publish a message from an agent’s handler, use the publish_message() method and specify a TopicId. This call must still be awaited to allow the runtime to schedule delivery of the message to all subscribers, but it will always return None. If an agent raises an exception while handling a published message, this will be logged but will not be propagated back to the publishing agent.\n\nThe following example shows a BroadcastingAgent that publishes a message to a topic upon receiving a message.from autogen_core import TopicId\n\n\nclass BroadcastingAgent(RoutedAgent):\n    @message_handler\n    async def on_my_message(self, message: Message, ctx: MessageContext) -> None:\n        await self.publish_message(\n            Message(\"Publishing a message from broadcasting agent!\"),\n            topic_id=TopicId(type=\"default\", source=self.id.key),\n        )\n\nBroadcastingAgent publishes message to a topic with type “default” and source assigned to the agent instance’s agent key.\n\nSubscriptions are registered with the agent runtime, either as part of agent type’s registration or through a separate API method. Here is how we register TypeSubscription for the receiving agent with the type_subscription() decorator, and for the broadcasting agent without the decorator.from autogen_core import TypeSubscription\n\nruntime = SingleThreadedAgentRuntime()\n\n# Option 1: with type_subscription decorator\n# The type_subscription class decorator automatically adds a TypeSubscription to\n# the runtime when the agent is registered.\nawait ReceivingAgent.register(runtime, \"receiving_agent\", lambda: ReceivingAgent(\"Receiving Agent\"))\n\n# Option 2: with TypeSubscription\nawait BroadcastingAgent.register(runtime, \"broadcasting_agent\", lambda: BroadcastingAgent(\"Broadcasting Agent\"))\nawait runtime.add_subscription(TypeSubscription(topic_type=\"default\", agent_type=\"broadcasting_agent\"))\n\n# Start the runtime and publish a message.\nruntime.start()\nawait runtime.publish_message(\n    Message(\"Hello, World! From the runtime!\"), topic_id=TopicId(type=\"default\", source=\"default\")\n)\nawait runtime.stop_when_idle()\n\nresult\n\nReceived a message: Hello, World! From the runtime!\nReceived a message: Publishing a message from broadcasting agent!\n\nAs shown in the above example, you can also publish directly to a topic through the runtime’s publish_message() method without the need to create an agent instance.\n\nFrom the output, you can see two messages were received by the receiving agent: one was published through the runtime, and the other was published by the broadcasting agent.\nDefault Topic and Subscriptions\n\nIn the above example, we used TopicId and TypeSubscription to specify the topic and subscriptions respectively. This is the appropriate way for many scenarios. However, when there is a single scope of publishing, that is, all agents publish and subscribe to all broadcasted messages, we can use the convenience classes DefaultTopicId and default_subscription() to simplify our code.\n\nDefaultTopicId is for creating a topic that uses “default” as the default value for the topic type and the publishing agent’s key as the default value for the topic source. default_subscription() is for creating a type subscription that subscribes to the default topic. We can simplify BroadcastingAgent by using DefaultTopicId and default_subscription().from autogen_core import DefaultTopicId, default_subscription\n\n\n@default_subscription\nclass BroadcastingAgentDefaultTopic(RoutedAgent):\n    @message_handler\n    async def on_my_message(self, message: Message, ctx: MessageContext) -> None:\n        # Publish a message to all agents in the same namespace.\n        await self.publish_message(\n            Message(\"Publishing a message from broadcasting agent!\"),\n            topic_id=DefaultTopicId(),\n        )\n\nWhen the runtime calls register() to register the agent type, it creates a TypeSubscription whose topic type uses “default” as the default value and agent type uses the same agent type that is being registered in the same context.runtime = SingleThreadedAgentRuntime()\nawait BroadcastingAgentDefaultTopic.register(\n    runtime, \"broadcasting_agent\", lambda: BroadcastingAgentDefaultTopic(\"Broadcasting Agent\")\n)\nawait ReceivingAgent.register(runtime, \"receiving_agent\", lambda: ReceivingAgent(\"Receiving Agent\"))\nruntime.start()\nawait runtime.publish_message(Message(\"Hello, World! From the runtime!\"), topic_id=DefaultTopicId())\nawait runtime.stop_when_idle()\n\nresult\n\nReceived a message: Hello, World! From the runtime!\nReceived a message: Publishing a message from broadcasting agent!","type":"content","url":"/broadcast#broadcast","position":3},{"hierarchy":{"lvl1":"Environment Setup"},"type":"lvl1","url":"/gettingstarted","position":0},{"hierarchy":{"lvl1":"Environment Setup"},"content":"We have recently learned the basics of what an AI Agent is and how Multi-agent systems consist of a group of individual AI Agents working together within a single environment or across distributed environments. The primary purpose of implementing a Single Agent or a Multi-Agent system is to solve a business use case by accomplishing a specific set of tasks, thereby automating the business process.\n\nHowever, our exploration is not complete; there is still much more to learn about AI Agents. Before we proceed to study Agent behavior in detail, let’s first delve deeper into the underlying mechanisms of an AI Agent.","type":"content","url":"/gettingstarted","position":1},{"hierarchy":{"lvl1":"Environment Setup","lvl2":"new virtual environment"},"type":"lvl2","url":"/gettingstarted#new-virtual-environment","position":2},{"hierarchy":{"lvl1":"Environment Setup","lvl2":"new virtual environment"},"content":"! python --version\n# Python 3.10 or later is required.\n\n######################################################\n# Create and activate a new Python virtual environment\n# When installing AgentChat or Agent Core locally\n# we recommend using a virtual environment\n# for the installation. \n# This will ensure that the dependencies for \n# AI Agents are isolated from the rest of your system.\n######################################################\n\n! python3 -m venv .venv\n! source .venv/bin/activate\n\n## To deactivate later, run:\n! deactivate\n\n######################################################\n# install autogen in this section below\n######################################################\n# install autogen studio\n! pip install -U autogenstudio\n# install autogen chat\n! pip install -U \"autogen-agentchat\"\n# install autogen OpenAI for Model Client\n! pip install \"autogen-ext[openai]\"\n# install autogen core\n! pip install \"autogen-core\"\n\n######################################################\n# run AutoGen Studio GUI\n######################################################\n! autogenstudio ui --host <host> --port 8000","type":"content","url":"/gettingstarted#new-virtual-environment","position":3},{"hierarchy":{"lvl1":"Environment Setup","lvl2":"llama.cpp"},"type":"lvl2","url":"/gettingstarted#llama-cpp","position":4},{"hierarchy":{"lvl1":"Environment Setup","lvl2":"llama.cpp"},"content":"#############################################\n# install llama.cpp to run deepseek-r1 model\n#############################################\n\n! git clone https://github.com/ggerganov/llama.cpp\n! cd llama.cpp\n! make\n\n# Download the deepseek-r1 Model weights \n\n# Convert the Model (if necessary)\n# If the model weights are not already in GGML format, \n# you must convert them using the conversion tools provided in llama.cpp. \n# Assuming the model weights are in PyTorch format:\n! python3 convert-pth-to-ggml.py path/to/deepseek-r1.pth\n\n# Prepare the Model File\n# Place the .bin model file (e.g., deepseek-r1.ggml.bin) into the llama.cpp directory \n# or specify its location when running commands\n\n# run the model\n!./main -m ./deepseek-r1.ggml.bin -p \"Your prompt here\"\n\n# adjust parameters\n!./main -m ./deepseek-r1.ggml.bin -p \"Explain quantum mechanics.\" -t 8 -n 128 --temp 0.8","type":"content","url":"/gettingstarted#llama-cpp","position":5},{"hierarchy":{"lvl1":"Environment Setup","lvl2":"ollama"},"type":"lvl2","url":"/gettingstarted#ollama","position":6},{"hierarchy":{"lvl1":"Environment Setup","lvl2":"ollama"},"content":"##########################################\n# install ollama to run deepseek-r1 model\n##########################################\n\n! curl -fsSL https://ollama.com/install.sh | sh\n\n! ollama list\n! ollama pull deepseek-r1:7b\n! ollama list\n! ollama run deepseek-r1\n\n# please see, ollama by default serves at 0.0.0.0:11434\n# you can change this\n! sudo systemctl edit ollama.service\n#[Service]\nEnvironment=\"OLLAMA_HOST=0.0.0.0:8000\"\n\n! sudo systemctl daemon-reload\n! sudo systemctl restart ollama.service\n\n# also, for a quick one time change you can run ollama as\n! export OLLAMA_HOST=127.0.0.1:8000\n! ollama serve","type":"content","url":"/gettingstarted#ollama","position":7},{"hierarchy":{"lvl1":"Agent"},"type":"lvl1","url":"/implementation","position":0},{"hierarchy":{"lvl1":"Agent"},"content":"Now, we have a decision to make, either we can continue developing our own version of AI Agentic implementation or instead of re-inventing the wheel, start using an given AI Agent framework capabilities.\n\nWarning\n\nPlease see, I will continously make many mistakes, write poor code, only to learn from it and refactor it as I learn.","type":"content","url":"/implementation","position":1},{"hierarchy":{"lvl1":"Agent","lvl2":"Standalone Implementation"},"type":"lvl2","url":"/implementation#standalone-implementation","position":2},{"hierarchy":{"lvl1":"Agent","lvl2":"Standalone Implementation"},"content":"# standalone implementation of an AI Agent\n\nclass MyFirstAgent():\n    def __init__(self) -> None:\n        super().__init__()\n\n    def do_something(self, message: str) -> None:\n        print(f\"received message: {message}\")\n\nFirstAgent = MyFirstAgent()\nFirstAgent.do_something(\"Hello World!\")\n\nresultreceived message: Hello World!","type":"content","url":"/implementation#standalone-implementation","position":3},{"hierarchy":{"lvl1":"Agent","lvl2":"Use Case"},"type":"lvl2","url":"/implementation#use-case","position":4},{"hierarchy":{"lvl1":"Agent","lvl2":"Use Case"},"content":"To learn more about AI Agent implementation, Instead of building a TODO-List Tutorial, let’s focus on automating our HR Time Sheet process with AI Agents.flowchart LR\n    subgraph \"PTO Request Process\"\n        A((Start)) --> B[Calculate dates]\n        B --> C[Check PTO balance]\n        C --> D[Submit PTO request]\n        D --> E[Manager reviews PTO request]\n        E --> F[Check team availability]\n        F --> G[Approve PTO request]\n        G --> H[Send notifications]\n        H --> I((End))\n    end\n    subgraph \"AI Agent Communication\"\n        Agent1[AI Agent 1: SQL Ops] -- \"direct exchange\" --> Agent2[AI Agent 2: Docs Proc]\n        Agent2 -- \"direct exchange\" --> Agent1\n        Agent1 -- \"broadcast\" --> Broadcast[Broadcast Channel]\n        Agent2 -- \"broadcast\" --> Broadcast\n        Broadcast -- \"notify\" --> OtherAgents[Other Agents]\n    end\n    style A fill:#e0f7fa,stroke:#000\n    style B fill:#f1f8e9,stroke:#000\n    style C fill:#e0f7fa,stroke:#000\n    style D fill:#f1f8e9,stroke:#000\n    style E fill:#e0f7fa,stroke:#000\n    style F fill:#f1f8e9,stroke:#000\n    style G fill:#e0f7fa,stroke:#000\n    style H fill:#f1f8e9,stroke:#000\n    style I fill:#e0f7fa,stroke:#000\n    style Agent1 fill:#e0f7fa,stroke:#000\n    style Agent2 fill:#e0f7fa,stroke:#000\n    style Broadcast fill:#f1f8e9,stroke:#000\n    style OtherAgents fill:#e0f7fa,stroke:#000","type":"content","url":"/implementation#use-case","position":5},{"hierarchy":{"lvl1":"Agent","lvl2":"Routed Agent"},"type":"lvl2","url":"/implementation#routed-agent","position":6},{"hierarchy":{"lvl1":"Agent","lvl2":"Routed Agent"},"content":"# refactor above code to use AutoGen Core framework\nfrom autogen_core import RoutedAgent        ## import AutoGen Core\nclass MyFirstAgent(RoutedAgent):            ## pass RoutedAgent as base class\n    def __init__(self) -> None:\n        super().__init__(\"MyFirstAgent\")    ## Agent Description\n\n    def do_something(self, message: str) -> None:\n        print(f\"received message: {message}\")\n\n## commented below code because RoutedAgent \n## are instantiated via runtime not standalone\n## will see how to instantiate Agent class later\n\n# FirstAgent = MyFirstAgent()\n# FirstAgent.do_something(\"Hello World!\")\n\n## what is RoutedAgent class?\n## take some time to understand super class Agent initialization\n## read RoutedAgent base class implemenation signature\n## what are the advantages of using this\nRoutedAgent.__dict__\n\nresultmappingproxy({'__module__': 'autogen_core._routed_agent',\n          '__doc__': 'A base class for agents that route messages to handlers based on the type of the message\\n    and optional matching functions.\\n\\n    To create a routed agent, subclass this class and add message handlers as methods decorated with\\n    either :func:`event` or :func:`rpc` decorator.\\n\\n    Example:\\n\\n    .. code-block:: python\\n\\n        from dataclasses import dataclass\\n        from autogen_core import MessageContext\\n        from autogen_core import RoutedAgent, event, rpc\\n\\n\\n        @dataclass\\n        class Message:\\n            pass\\n\\n\\n        @dataclass\\n        class MessageWithContent:\\n            content: str\\n\\n\\n        @dataclass\\n        class Response:\\n            pass\\n\\n\\n        class MyAgent(RoutedAgent):\\n            def __init__(self):\\n                super().__init__(\"MyAgent\")\\n\\n            @event\\n            async def handle_event_message(self, message: Message, ctx: MessageContext) -> None:\\n                assert ctx.topic_id is not None\\n                await self.publish_message(MessageWithContent(\"event handled\"), ctx.topic_id)\\n\\n            @rpc(match=lambda message, ctx: message.content == \"special\")  # type: ignore\\n            async def handle_special_rpc_message(self, message: MessageWithContent, ctx: MessageContext) -> Response:\\n                return Response()\\n    ',\n          '__init__': <function autogen_core._routed_agent.RoutedAgent.__init__(self, description: str) -> None>,\n          'on_message_impl': <function autogen_core._routed_agent.RoutedAgent.on_message_impl(self, message: Any, ctx: autogen_core._message_context.MessageContext) -> typing.Any | None>,\n          'on_unhandled_message': <function autogen_core._routed_agent.RoutedAgent.on_unhandled_message(self, message: Any, ctx: autogen_core._message_context.MessageContext) -> None>,\n          '_discover_handlers': <classmethod(<function RoutedAgent._discover_handlers at 0x727070171440>)>,\n          '_handles_types': <classmethod(<function RoutedAgent._handles_types at 0x7270701714e0>)>,\n          '__parameters__': (),\n          '_is_protocol': False,\n          '__subclasshook__': <classmethod(<function _proto_hook at 0x72707d09a700>)>,\n          'internal_extra_handles_types': [],\n          'internal_unbound_subscriptions_list': [],\n          '__abstractmethods__': frozenset(),\n          '_abc_impl': <_abc._abc_data at 0x727070de2500>})from autogen_core import RoutedAgent\n\nclass TaskAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"PTOAgent\")\n\n    def do_something(self, message: str) -> None: ## Refactor\n        # fetches tasks an employee        ## Refactor\n        print(f\"received message: {message}\") ## Refactor\n\n    def do_something_more(self, message: str) -> None:## Refactor\n        # poeple working on one task   ## Refactor\n        print(f\"received message: {message}\")        ## Refactor\n\n    def do_something_even_more(self, message: str) -> None: ## Refactor\n        # approved PTOs for employee   ## Refactor\n        # fetch all other teams working on same tasks\n        # and their PTO during same period## Refactor\n        print(f\"received message: {message}\")        ## Refactorfrom autogen_core import RoutedAgent\n\nclass LLMAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"PTOAgent\")\n\n    def do_something(self, message: str) -> None:\n        # figure out Thursday and Friday date\n        print(f\"received message: {message}\")\n\n    def do_something_more(self, message: str) -> None:\n        # draft an approval request to manager\n        print(f\"received message: {message}\")\n\n    def do_something_even_more(self, message: str) -> None:\n        # greets and chat with Susan\n        print(f\"received message: {message}\")\n    \n    def do_something_even_more(self, message: str) -> None:\n        # call next agent once\n        print(f\"received message: {message}\")\n\n\nclass ManagerAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"PTOAgent\")\n\n    def do_something(self, message: str) -> None:\n        # approve or disapprove PTO\n        print(f\"received message: {message}\")\n\n    def do_something_more(self, message: str) -> None:\n        # draft an approval request to manager\n        print(f\"received message: {message}\")\n\nclass BroadcasterAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"PTOAgent\")\n\n    def do_something(self, message: str) -> None:\n        # notify all employee that Susan is taking PTO\n        print(f\"received message: {message}\")\n\n    def do_something_more(self, message: str) -> None:\n        # draft an approval request to manager\n        print(f\"received message: {message}\")","type":"content","url":"/implementation#routed-agent","position":7},{"hierarchy":{"lvl1":"Agent Lifecyle"},"type":"lvl1","url":"/lifecycle","position":0},{"hierarchy":{"lvl1":"Agent Lifecyle"},"content":"","type":"content","url":"/lifecycle","position":1},{"hierarchy":{"lvl1":"Agent Lifecyle","lvl2":"Agent ID and LifeCycle"},"type":"lvl2","url":"/lifecycle#agent-id-and-lifecycle","position":2},{"hierarchy":{"lvl1":"Agent Lifecyle","lvl2":"Agent ID and LifeCycle"},"content":"In last chapter we learned about messages, how using messages works well in case of we want to pass along different messages among different agents, with in same or distributed compute environment.\n\nanother important concept here is Agent ID.\nWhat exactly is an Agent ID?\n\nnow since we defined Agent definitions and their abilities to handle different type of handles, now we need to build a mechanism which helps manage Agent life cycle, what that means, just like mentioned in previous code, we register agents to a run time environment, means, we attach agents to a run time environment based on assumption that since there may be thousands of agents, let;s leave invoking of Agents as per needed basis, and let run time alone create, maintain, remove Agent ID from runtime for efficiency.\n\nbut how will a run time locate an Agent?\n\nwe want to use Agent ID.","type":"content","url":"/lifecycle#agent-id-and-lifecycle","position":3},{"hierarchy":{"lvl1":"Agent Lifecyle","lvl2":"Agent ID"},"type":"lvl2","url":"/lifecycle#agent-id","position":4},{"hierarchy":{"lvl1":"Agent Lifecyle","lvl2":"Agent ID"},"content":"Agent ID uniquely identifies an agent instance within an agent runtime – including distributed runtime. It is the “address” of the agent instance for receiving messages. It has two components: agent type and agent key.\n\nAgent ID = (Agent Type, Agent Key)","type":"content","url":"/lifecycle#agent-id","position":5},{"hierarchy":{"lvl1":"Agent Lifecyle","lvl2":"Agent Type"},"type":"lvl2","url":"/lifecycle#agent-type","position":6},{"hierarchy":{"lvl1":"Agent Lifecyle","lvl2":"Agent Type"},"content":"Agent Type is nothing but a type definition to define and Agent Identity.\n\njust like when we were dealing with messages in previous chapter, we took advantage of Type definition.\nsimilar to defining Message Type to take advantage of Message protocols, interfaces, Type definitions used in message handler decorator and message context object\n\nThe agent type is not an agent class. It associates an agent with a specific factory function, which produces instances of agents of the same agent type. For example, different factory functions can produce the same agent class but with different constructor parameters. The agent key is an instance identifier for the given agent type. Agent IDs can be converted to and from strings. the format of this string is:\n\nTypes and Keys are considered valid if they only contain alphanumeric letters (a-z) and (0-9), or underscores (_). A valid identifier cannot start with a number, or contain any spaces.\n\nIn a multi-agent application, agent types are typically defined directly by the application, i.e., they are defined in the application code. On the other hand, agent keys are typically generated given messages delivered to the agents, i.e., they are defined by the application data.\n\nFor example, a runtime has registered the agent type “code_reviewer” with a factory function producing agent instances that perform code reviews. Each code review request has a unique ID review_request_id to mark a dedicated session. In this case, each request can be handled by a new instance with an agent ID, (“code_reviewer”, review_request_id).","type":"content","url":"/lifecycle#agent-type","position":7},{"hierarchy":{"lvl1":"Agent Lifecyle","lvl2":"Agent Lifecycle"},"type":"lvl2","url":"/lifecycle#agent-lifecycle","position":8},{"hierarchy":{"lvl1":"Agent Lifecyle","lvl2":"Agent Lifecycle"},"content":"just for the reference, here is a diagram (ref: \n\nAutoGen Documentation) showing Agent Lifecycle.","type":"content","url":"/lifecycle#agent-lifecycle","position":9},{"hierarchy":{"lvl1":"Agent Lifecyle","lvl2":"Registering Agents"},"type":"lvl2","url":"/lifecycle#registering-agents","position":10},{"hierarchy":{"lvl1":"Agent Lifecyle","lvl2":"Registering Agents"},"content":"To make agents available to the runtime, developers can use the register() class method of the BaseAgent class. The process of registration associates an agent type, which is uniquely identified by a string, and a factory function that creates an instance of the agent type of the given class. The factory function is used to allow automatic creation of agent instances when they are needed.\n\nAgent type (AgentType) is not the same as the agent class. In this example, the agent type is AgentType(“my_agent”) or AgentType(“my_assistant”) and the agent class is the Python class MyAgent or MyAssistantAgent. The factory function is expected to return an instance of the agent class on which the register() class method is invoked. Read Agent Identity and Lifecycles to learn more about agent type and identity.\n\nnote\n\njust if you are wondering why we learned so much detail about Agent ID and Lifecycle is, because of sole reason that, Same Agents can br used across same or different runtime just by making use of different agent Type.\n\na Typical Agent ID  AgentType, key will help distinguish a specific instance of a given Agent invoke in a runtime, hence the reusability with going through complex OOPs encapdulation, inheritance and abstraction concepts.\n\nDifferent agent types can be registered with factory functions that return the same agent class. For example, in the factory functions, variations of the constructor parameters can be used to create different instances of the same agent class.\n\nTo register our agent types with the SingleThreadedAgentRuntime, the following code can be used:\n\nso based on this register() signature, it’s important to register an Agent appropriately so that runtime would be able to invoke this Agent when needed.from autogen_core import SingleThreadedAgentRuntime\n\n# create a standalong single thread runtime\nruntime = SingleThreadedAgentRuntime()\n\n# attach/register AI Agent to run time\nawait PTOAgent.register(runtime, \"ERP_PTO_Agent\", lambda: PTOAgent(\"T_E_PTOAgent\"))\nawait TaskAgent.register(runtime, \"ERP_Task_Agent\", lambda: TaskAgent(\"T_E_TaskAgent\"))\n\nresultAgentType(type='my_assistant')\n\nOnce an agent type is registered, we can send a direct message to an agent instance using an AgentId. The runtime will create the instance the first time it delivers a message to this instance.","type":"content","url":"/lifecycle#registering-agents","position":11},{"hierarchy":{"lvl1":"Agent Lifecyle","lvl2":"Executing Runtime"},"type":"lvl2","url":"/lifecycle#executing-runtime","position":12},{"hierarchy":{"lvl1":"Agent Lifecyle","lvl2":"Executing Runtime"},"content":"runtime.start()  # Start processing messages in the background.\nawait runtime.send_message(MyMessageType(\"Hello, World!\"), AgentId(\"my_agent\", \"default\"))\nawait runtime.send_message(MyMessageType(\"Hello, World!\"), AgentId(\"my_assistant\", \"default\"))\nawait runtime.stop()  # Stop processing messages in the background.\n\nresultmy_agent received message: Hello, World!\nmy_assistant received message: Hello, World!\nmy_assistant responded: Hello! How can I assist you today?# This will block until the runtime is idle\nawait runtime.stop_when_idle()\n# This will close the runtime\nawait runtime.close()","type":"content","url":"/lifecycle#executing-runtime","position":13},{"hierarchy":{"lvl1":"Messages"},"type":"lvl1","url":"/messages","position":0},{"hierarchy":{"lvl1":"Messages"},"content":"","type":"content","url":"/messages","position":1},{"hierarchy":{"lvl1":"Messages","lvl2":"Solution Design"},"type":"lvl2","url":"/messages#solution-design","position":2},{"hierarchy":{"lvl1":"Messages","lvl2":"Solution Design"},"content":"As you can see, our business case involves evolving a solution design. A solution design pattern helps in understanding and managing the AI Agent framework implementation to support your business use case.\n\nCurrently, our agentic framework solution design includes the following agents:\n\nPTOAgent\n\nTaskAgent\n\nLLMAgent\n\nManagerAgent\n\nBroadcasterAgent\n\nEach agent exhibits specific behaviors in response to tasks. However, this design is not final, and we may need to add, update, or remove agents as the project progresses.\n\nEven now, the workflow feels tedious, and it’s easy to imagine that as we incorporate additional supporting business processes, the number of agents could spiral into unmanageable chaos.\n\nLet’s address a key issue in the design. The behavioral methods within the Routed Agents are essentially methods that react to data and ultimately alter the state or data of an agent based on the message or data received. To improve this, we need a more effective mechanism to manage incoming data—whether it’s from other agents or the agent’s own behavioral response to a task.\n\nAs a starting point, let’s refer to this incoming and outgoing data as messages. This terminology will help us better conceptualize the flow of information.\nThe next step is to implement a more efficient way to handle these messages, ensuring our agent framework remains scalable and manageable as it evolves.","type":"content","url":"/messages#solution-design","position":3},{"hierarchy":{"lvl1":"Messages","lvl2":"Messages Implementation"},"type":"lvl2","url":"/messages#messages-implementation","position":4},{"hierarchy":{"lvl1":"Messages","lvl2":"Messages Implementation"},"content":"from autogen_core import RoutedAgent\n## Refactor - add dataclass to support message data types\nfrom dataclasses import dataclass\n\n## Refactor: add dataclass to support message data types\n@dataclass\nclass PTOAgentMessages: ## add dataclass to support message data types\n    content: str\n\nfrom autogen_core import RoutedAgent\nclass PTOAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"PTOAgent\")\n\n    def do_something(self, message: PTOAgentMessages) -> None:  ## add type def\n        # fetches available PTO for a given employee\n        print(f\"received message: {message.content}\") ## add type def\n\n    def do_something_more(self, message: PTOAgentMessages) -> None:  ## add type def\n        # udpate PTO for a given employee if approved\n        print(f\"received message: {message.content}\") ## add type deffrom autogen_core import RoutedAgent\nfrom dataclasses import dataclass\n\n@dataclass\nclass PTOAgentMessages:\n    content: str\n\n## add another messageType \n## this is a huge step, type based message communication is one of the key features\n@dataclass\nclass PTOAgentImageMessages:\n    url: str\n\nfrom autogen_core import RoutedAgent\nclass PTOAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"PTOAgent\")\n\n    def do_something(self, message: PTOAgentMessages) -> None:\n        # fetches available PTO for a given employee\n        print(f\"received message: {message.content}\")\n\n    def do_something_more(self, message: PTOAgentMessages) -> None:\n        # udpate PTO for a given employee if approved\n        print(f\"received message: {message.content}\")\n    \n    def do_something_with_document(self, message: PTOAgentImageMessages) -> None:\n                                            ## added another messageType\n        # udpate PTO for a given employee if approved\n        print(f\"received message: {message.url}\")from autogen_core import RoutedAgent\nfrom dataclasses import dataclass\n\n@dataclass\nclass PTOAgentMessages:\n    content: str\n    source: str\n\n@dataclass\nclass PTOAgentImageMessages:\n    url: str\n    source: str\n\nfrom autogen_core import RoutedAgent\nclass PTOAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"PTOAgent\")\n\n    def do_something(self, message: PTOAgentMessages) -> None:\n        # fetches available PTO for a given employee\n        print(f\"received message: {message.content} from : {message.source}\")\n                                                        ## print message source\n\n    def do_something_more(self, message: PTOAgentMessages) -> None:\n        # udpate PTO for a given employee if approved\n        print(f\"received message: {message.content} from : {message.source}\")\n                                                        ## print message source\n    \n    def do_something_with_document(self, message: PTOAgentImageMessages) -> None:\n        # udpate PTO for a given employee if approved\n        print(f\"received message: {message.url} from : {message.source}\")\n                                                        ## print message sourcefrom autogen_core import RoutedAgent\nfrom dataclasses import dataclass\n\n@dataclass\nclass PTOAgentMessages:\n    content: str\n    source: str\n\n@dataclass\nclass PTOAgentImageMessages:\n    url: str\n    source: str\n\nfrom autogen_core import RoutedAgent\nclass PTOAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"PTOAgent\")\n\n    def on_txt_message_1(self, message: PTOAgentMessages) -> None: ## rename method\n        # fetches available PTO for a given employee\n        print(f\"received message: {message.content} from : {message.source}\")\n\n    def on_txt_message_2(self, message: PTOAgentMessages) -> None: ## rename method\n        # udpate PTO for a given employee if approved\n        print(f\"received message: {message.content} from : {message.source}\")\n    \n    def on_doc_message(self, message: PTOAgentImageMessages) -> None: ## rename method\n        # udpate PTO for a given employee if approved\n        print(f\"received message: {message.url} from : {message.source}\")\n\nIf you pay close attention to this code, you’ll notice that defining separate methods like on_txt_message_1 and on_txt_message_2 is not good practice. However, since we need two distinct methods to perform different tasks, we can refactor the code to call the appropriate method based on the message type.# refactor above code to use AutoGen Core framework\n# refactor above code to create use base\n\nfrom autogen_core import RoutedAgent\nfrom dataclasses import dataclass\n\n@dataclass\nclass PTOAgentMessages:\n    content: str\n    source: str\n\n@dataclass\nclass PTOAgentImageMessages:\n    url: str\n    source: str\n\nfrom autogen_core import RoutedAgent\nclass PTOAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"PTOAgent\")\n\n## Refactor code to act on message Type def\n    def on_txt_messages(self, message: PTOAgentMessages):\n        if message.source.startswith(\"Agent_1\"):\n            def on_txt_message_1(self, message: PTOAgentMessages) -> None:\n                # fetches available PTO for a given employee\n                print(f\"received message: {message.content} from : {message.source}\")\n        else:\n            def on_txt_message_2(self, message: PTOAgentMessages) -> None:\n                # udpate PTO for a given employee if approved\n                print(f\"received message: {message.content} from : {message.source}\")\n    \n    def on_doc_message(self, message: PTOAgentImageMessages) -> None:\n        # udpate PTO for a given employee if approved\n        print(f\"received message: {message.url} from : {message.source}\")\n\nThe agent implementation above seems fine to me; however, there’s still one unresolved issue. While we can refactor our other agents (e.g., TaskAgent, LLMAgent, etc.), we haven’t fully addressed the message communication problem.\n\nAll these messages are essentially behavioral methods of the Agent class. What we need are asynchronous methods.\n\nThe reason is that, in a real-world scenario, thousands of users will access this same Agent Framework with different datasets. Creating numerous instances or objects of these agents across many threads is still manageable, but these methods need to be asynchronous.\n\nFor example, one agent might be performing deep research, while others are handling simple LLM inferences or accessing API results. Managing these as asynchronous data operations would be far more efficient.\n\nTo achieve this, I have a choice: I can start implementing asyncio and make these methods async. Let’s go back to the AutoGen Core and explore how we can leverage pre-existing code to refactor this implementation and make these operations asynchronous.from autogen_core import RoutedAgent, message_handler ## import message handler for async\nfrom dataclasses import dataclass\n\n@dataclass\nclass PTOAgentMessages:\n    content: str\n    source: str\n\n@dataclass\nclass PTOAgentImageMessages:\n    url: str\n    source: str\n\nfrom autogen_core import RoutedAgent\nclass PTOAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"PTOAgent\")\n\n    @message_handler ## add async\n    async def on_txt_messages(self, message: PTOAgentMessages): ## add async\n        if message.source.startswith(\"Agent_1\"):\n            async def on_txt_message_1(self, message: PTOAgentMessages) -> ## add async\n                # fetches available PTO for a given employee\n                print(f\"received message: {message.content} from : {message.source}\")\n        else:\n            async def on_txt_message_2(self, message: PTOAgentMessages) -> ## add async\n                # udpate PTO for a given employee if approved\n                print(f\"received message: {message.content} from : {message.source}\")\n    \n    @message_handler ## add async\n    async def on_doc_message(self, message: PTOAgentImageMessages) -> ## add async\n        # udpate PTO for a given employee if approved\n        print(f\"received message: {message.url} from : {message.source}\")\n\nThere’s still one small improvement we can make to this code to enhance its efficiency.\n\nInstead of using an if:else statement inside the txt_messages method, we can leverage the message handler decorator directly.\n\nAnother benefit of this approach is that agents passing messages to each other won’t need to know the specific methods. The message handler will automatically process the messages and call the appropriate method based on the message type itself.from autogen_core import RoutedAgent, message_handler,\n                 MessageContext ## import message context\nfrom dataclasses import dataclass\n\n@dataclass\nclass PTOAgentMessages:\n    content: str\n    source: str\n\n@dataclass\nclass PTOAgentImageMessages:\n    url: str\n    source: str\n\nfrom autogen_core import RoutedAgent\nclass PTOAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"PTOAgent\")\n\n    ## add message type handler using match\n    @message_handler(match=lambda msg, ctx: msg.source.startswith(\"Agent_1\"))\n    ## add message context\n    async def on_txt_message_1(self, message: PTOAgentMessages, ctx: MessageContext) -> None:\n        # fetches available PTO for a given employee\n        print(f\"received message: {message.content} from : {message.source}\")\n    \n    ## add message type handler using match\n    @message_handler(match=lambda msg, ctx: msg.source.startswith(\"Agent_2\"))\n    ## add message context\n    async def on_txt_message_2(self, message: PTOAgentMessages, ctx: MessageContext) -> None:\n        # udpate PTO for a given employee if approved\n        print(f\"received message: {message.content} from : {message.source}\")\n    \n    @message_handler\n    ## add message context\n    async def on_doc_message(self, message: PTOAgentImageMessages, ctx: MessageContext) -> None:\n        # udpate PTO for a given employee if approved\n        print(f\"received message: {message.url} from : {message.source}\")\n\nLet’s add one more feature called Agent ID. For now, think of Agent ID as a simple identifier. It’s a broader concept, and we’ll explore it in more detail in a later section. For the time being, let’s just consider Agent ID as an identifier.## import AgentId\nfrom autogen_core import RoutedAgent, message_handler, MessageContext, AgentId \nfrom dataclasses import dataclass\n\n@dataclass\nclass PTOAgentMessages:\n    content: str\n    source: str\n\n@dataclass\nclass PTOAgentImageMessages:\n    url: str\n    source: str\n\nfrom autogen_core import RoutedAgent\nclass PTOAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"PTOAgent\")\n\n    @message_handler(match=lambda msg, ctx: msg.source.startswith(\"Agent_1\"))\n    async def on_txt_message_1(self, message: PTOAgentMessages, ctx: MessageContext) -> None:\n        # fetches available PTO for a given employee\n         ## added agent ID\n        print(f\"{self.id.type} received message: {message.content} from : {message.source}\")\n    \n    @message_handler(match=lambda msg, ctx: msg.source.startswith(\"Agent_2\"))\n    async def on_txt_message_2(self, message: PTOAgentMessages, ctx: MessageContext) -> None:\n        # udpate PTO for a given employee if approved\n         ## added agent ID\n        print(f\"{self.id.type} received message: {message.content} from : {message.source}\")\n    \n    @message_handler\n    async def on_doc_message(self, message: PTOAgentImageMessages, ctx: MessageContext) -> None:\n        # udpate PTO for a given employee if approved\n         ## added agent ID\n        print(f\"{self.id.type} received message: {message.url} from : {message.source}\")\n\nnow we have a complete Agent implementation, but we need to create more such agents.\n\nPTOAgent\n\nTaskAgent\n\nLLMAgent\n\nManagerAgent\n\nBroadcasterAgent\n\nfor the sake of simplicity, for now, let’s just focus on one more agent, say TaskAgent, we will deal with LLM Type agents later.\nLet’s build Task Agent.from autogen_core import RoutedAgent, message_handler, MessageContext, AgentId\nfrom dataclasses import dataclass\n\n@dataclass\nclass TaskAgentMessages:\n    content: str\n    source: str\n\n@dataclass\nclass TaskAgentImageMessages:\n    url: str\n    source: str\n\nfrom autogen_core import RoutedAgent\nclass TaskAgent(RoutedAgent):\n    def __init__(self) -> None:\n        super().__init__(\"TaskAgent\")\n\n    @message_handler(match=lambda msg, ctx: msg.source.startswith(\"Agent_1\"))\n    async def on_txt_message_1(self, message: PTOAgentMessages, ctx: MessageContext) -> None:\n        # fetches tasks an employee\n        print(f\"{self.id.type} received message: {message.content} from : {message.source}\")\n    \n    @message_handler(match=lambda msg, ctx: msg.source.startswith(\"Agent_2\"))\n    async def on_txt_message_2(self, message: PTOAgentMessages, ctx: MessageContext) -> None:\n        # poeple working on one task \n        print(f\"{self.id.type} received message: {message.content} from : {message.source}\")\n    \n    @message_handler\n    async def on_doc_message(self, message: PTOAgentImageMessages, ctx: MessageContext) -> None:\n        # fetch all other teams working on same tasks and their PTO during same period\n        print(f\"{self.id.type} received message: {message.url} from : {message.source}\")","type":"content","url":"/messages#messages-implementation","position":5},{"hierarchy":{"lvl1":"Direct Messages"},"type":"lvl1","url":"/messaging","position":0},{"hierarchy":{"lvl1":"Direct Messages"},"content":"There are two types of communication in AutoGen core:\n\nDirect Messaging: sends a direct message to another agent.\n\nBroadcast: publishes a message to a topic.\n\nLet’s first look at direct messaging. To send a direct message to another agent, within a message handler use the AutoGen core.BaseAgent.send_message() method, from the runtime use the AutoGen _core.AgentRuntime.send_message() method. Awaiting calls to these methods will return the return value of the receiving agent’s message handler. When the receiving agent’s handler returns None, None will be returned.\n\nNote\n\nIf the invoked agent raises an exception while the sender is awaiting, the exception will be propagated back to the sender.","type":"content","url":"/messaging","position":1},{"hierarchy":{"lvl1":"Direct Messages","lvl2":"Request/Response"},"type":"lvl2","url":"/messaging#request-response","position":2},{"hierarchy":{"lvl1":"Direct Messages","lvl2":"Request/Response"},"content":"Direct messaging can be used for request/response scenarios, where the sender expects a response from the receiver. The receiver can respond to the message by returning a value from its message handler. You can think of this as a function call between agents.\n\nFor example, consider the following agents:from dataclasses import dataclass\n\nfrom autogen_core import MessageContext, RoutedAgent, SingleThreadedAgentRuntime, message_handler\n\n\n@dataclass\nclass Message:\n    content: str\n\n\nclass InnerAgent(RoutedAgent):\n    @message_handler\n    async def on_my_message(self, message: Message, ctx: MessageContext) -> Message:\n        return Message(content=f\"Hello from inner, {message.content}\")\n\n\nclass OuterAgent(RoutedAgent):\n    def __init__(self, description: str, inner_agent_type: str):\n        super().__init__(description)\n        self.inner_agent_id = AgentId(inner_agent_type, self.id.key)\n\n    @message_handler\n    async def on_my_message(self, message: Message, ctx: MessageContext) -> None:\n        print(f\"Received message: {message.content}\")\n        # Send a direct message to the inner agent and receives a response.\n        response = await self.send_message(Message(f\"Hello from outer, {message.content}\"), self.inner_agent_id)\n        print(f\"Received inner response: {response.content}\")\n\nUpon receiving a message, the OuterAgent sends a direct message to the InnerAgent and receives a message in response.\n\nWe can test these agents by sending a Message to the OuterAgent.runtime = SingleThreadedAgentRuntime()\nawait InnerAgent.register(runtime, \"inner_agent\", lambda: InnerAgent(\"InnerAgent\"))\nawait OuterAgent.register(runtime, \"outer_agent\", lambda: OuterAgent(\"OuterAgent\", \"inner_agent\"))\nruntime.start()\nouter_agent_id = AgentId(\"outer_agent\", \"default\")\nawait runtime.send_message(Message(content=\"Hello, World!\"), outer_agent_id)\nawait runtime.stop_when_idle()\n\nresultReceived message: Hello, World!\nReceived inner response: Hello from inner, Hello from outer, Hello, World!\n\nBoth outputs are produced by the OuterAgent’s message handler, however the second output is based on the response from the InnerAgent.\n\nGenerally speaking, direct messaging is appropriate for scenarios when the sender and recipient are tightly coupled – they are created together and the sender is linked to a specific instance of the recipient. For example, an agent executes tool calls by sending direct messages to an instance of ToolAgent, and uses the responses to form an action-observation loop.","type":"content","url":"/messaging#request-response","position":3},{"hierarchy":{"lvl1":"Model Runtime"},"type":"lvl1","url":"/modelruntime","position":0},{"hierarchy":{"lvl1":"Model Runtime"},"content":"Let’s review this PTO Request process one more time.\n\nAn employee wants to take PTO next Thursday and Friday to enjoy a long weekend. Here’s the basic flow:\n\nAn LLM calculates the dates for next week.\n\nThe employee checks their PTO balance and submits a request.\n\nThe request goes to the manager for approval.\n\nThe manager, aware it’s a long weekend, ensures not all staff are off at once and approves based on team availability.\n\nOnce approved, the employee’s department and teammates working on the same tasks are notified.flowchart TD\n    A((Start)) --> B[Calculate dates]\n    B --> C[Check PTO balance]\n    C --> D[Submit PTO request]\n    D --> E[Manager reviews PTO request]\n    E --> F[Check team availability]\n    F --> G[Approve PTO request]\n    G --> H[Send notifications]\n    H --> I((End))\n\n    style A fill:#e0f7fa,stroke:#000\n    style B fill:#f1f8e9,stroke:#000\n    style C fill:#e0f7fa,stroke:#000\n    style D fill:#f1f8e9,stroke:#000\n    style E fill:#e0f7fa,stroke:#000\n    style F fill:#f1f8e9,stroke:#000\n    style G fill:#e0f7fa,stroke:#000\n    style H fill:#f1f8e9,stroke:#000\n    style I fill:#e0f7fa,stroke:#000","type":"content","url":"/modelruntime","position":1},{"hierarchy":{"lvl1":"Model Runtime","lvl2":"Actor & State"},"type":"lvl2","url":"/modelruntime#actor-state","position":2},{"hierarchy":{"lvl1":"Model Runtime","lvl2":"Actor & State"},"content":"To handle tasks like approving Employee’s time off request, we need a simple setup like an Actor model to simulate state and behavior.\nState of Agent will hold data and properties while behavior methods will manage tasks such as if Employee asks for a day off. The system must check her remaining vacation days, find her supervisor, look at her tasks, and send the request to her manager. This involves several agents—think of them as helpers—talking to each other a lot.\nflowchart LR\n    subgraph AI_Agent[AI Agent]\n        direction TB\n        State[State]\n    end\n\n    Environment[Environment] -->|Perception: messages, sensor inputs| AI_Agent\n    AI_Agent -->|Actions: update state, send messages, execute code, interact with systems | Environment\n    AI_Agent -->|Actions| External_Systems[External Systems]\n\n    style AI_Agent fill:#99FF33,stroke:#007BFF,stroke-width:2px\n    style State fill:#FFFFFF,stroke:#007BFF,stroke-width:1px\n    style Environment fill:#E6FFE6,stroke:#00CC00,stroke-width:2px\n    style External_Systems fill:#FFFACD,stroke:#FFD700,stroke-width:2px","type":"content","url":"/modelruntime#actor-state","position":3},{"hierarchy":{"lvl1":"Model Runtime","lvl2":"Virtual Environment"},"type":"lvl2","url":"/modelruntime#virtual-environment","position":4},{"hierarchy":{"lvl1":"Model Runtime","lvl2":"Virtual Environment"},"content":"We need a virtual environment, like a separate workspace, to manage these actor model state, helper methods, their tools, and how they work together. It’s similar to programming, where you keep all the software pieces organized in one place to avoid confusion.\n\nSimilar to functional programming, where managing various packages and dependencies is crucial, it becomes vital to oversee a project’s critical dependencies within a single, dedicated environment. Additionally, properly managing namespaces is essential for ensuring efficient program execution.","type":"content","url":"/modelruntime#virtual-environment","position":5},{"hierarchy":{"lvl1":"Model Runtime","lvl2":"Agent RunTime"},"type":"lvl2","url":"/modelruntime#agent-runtime","position":6},{"hierarchy":{"lvl1":"Model Runtime","lvl2":"Agent RunTime"},"content":"Now you can imagine, just to respond to this simple task to perform PTO request, There is need of multiple agents, processes and hence multiple message communication is required back and forth before Agent can respond with accurate information and take appropriate actions.\n\nwhat is Agent runtime anyway? At the foundation level, the framework provides a runtime environment, which facilitates communication between agents, manages their identities and lifecycles, and enforce security and privacy boundaries.\n\nFor now, we will just focus on messages flowing in a runtime environment and will deal with agent identities, lifecycle, security, privacy and models later.","type":"content","url":"/modelruntime#agent-runtime","position":7},{"hierarchy":{"lvl1":"Model Runtime","lvl2":"Agent RunTime environment"},"type":"lvl2","url":"/modelruntime#agent-runtime-environment","position":8},{"hierarchy":{"lvl1":"Model Runtime","lvl2":"Agent RunTime environment"},"content":"The change we want to see involves, how one agent maintain its state and communicate with external systems and other agents.\n\nInstead of relying on 1:1 direct messaging, all communication will occur through a common message bus.\n\nFor now, the primary role of this message bus is to facilitate a shared communication channel among different agents, whether they belong to the same team or different teams.\n\nAs this message bus will evolve into runtime, will include more features such as agent identities, lifecycle, security, privacy and models etc..flowchart LR\n\n    %% Define Individual AI Agents\n    subgraph AI_Agent1[AI Agent 1]\n        direction TB\n        State1[State]\n    end\n\n    subgraph AI_Agent2[AI Agent 2]\n        direction TB\n        State2[State]\n    end\n\n    subgraph AI_Agent3[AI Agent 3]\n        direction TB\n        State3[State]\n    end\n\n    %% Define Teams as Subgraphs\n    subgraph Team_Alpha[Team Alpha]\n        direction TB\n        AI_Agent1\n        AI_Agent2\n    end\n\n    subgraph Team_Beta[Team Beta]\n        direction TB\n        AI_Agent2\n        AI_Agent3\n    end\n\n    %% Environment and External Systems\n    Environment[RunTime Environment]\n    External_Systems[External Systems]\n\n    %% Interactions with Environment\n    MessageBus -->|Perception| AI_Agent1\n    MessageBus -->|Perception| AI_Agent2\n    MessageBus -->|Perception| AI_Agent3\n\n    AI_Agent1 -->|Actions| MessageBus\n    AI_Agent2 -->|Actions| MessageBus\n    AI_Agent3 -->|Actions| MessageBus\n\n    %% Interactions with External Systems\n    MessageBus -->|Actions| External_Systems\n    External_Systems -->|Perception| MessageBus\n\n    %% Styles from Original Diagram\n    style AI_Agent1 fill:#99FF33,stroke:#007BFF,stroke-width:2px\n    style AI_Agent2 fill:#99FF33,stroke:#007BFF,stroke-width:2px\n    style AI_Agent3 fill:#99FF33,stroke:#007BFF,stroke-width:2px\n    style State1 fill:#FFFFFF,stroke:#007BFF,stroke-width:1px\n    style State2 fill:#FFFFFF,stroke:#007BFF,stroke-width:1px\n    style State3 fill:#FFFFFF,stroke:#007BFF,stroke-width:1px\n    style MessageBus fill:#E6FFE6,stroke:#00CC00,stroke-width:2px\n    style External_Systems fill:#FFFACD,stroke:#FFD700,stroke-width:2px\n    style Team_Alpha fill:none,stroke:#FF4500,stroke-width:2px,stroke-dasharray:5\n    style Team_Beta fill:none,stroke:#8A2BE2,stroke-width:2px,stroke-dasharray:5\n\njust for the reference, here are diagrams (ref: \n\nAutoGen Documentation) showing the standalone and distributed runtime in the framework.","type":"content","url":"/modelruntime#agent-runtime-environment","position":9},{"hierarchy":{"lvl1":"Model Runtime","lvl2":"Agent Runtime"},"type":"lvl2","url":"/modelruntime#agent-runtime-1","position":10},{"hierarchy":{"lvl1":"Model Runtime","lvl2":"Agent Runtime"},"content":"","type":"content","url":"/modelruntime#agent-runtime-1","position":11},{"hierarchy":{"lvl1":"Model Runtime","lvl2":"Distributed Agent Runtime"},"type":"lvl2","url":"/modelruntime#distributed-agent-runtime","position":12},{"hierarchy":{"lvl1":"Model Runtime","lvl2":"Distributed Agent Runtime"},"content":"","type":"content","url":"/modelruntime#distributed-agent-runtime","position":13},{"hierarchy":{"lvl1":"More Tool Functions"},"type":"lvl1","url":"/moretools","position":0},{"hierarchy":{"lvl1":"More Tool Functions"},"content":"Before we conclude this discussion about the Tool functions, I’d like to share some additional code examples with you.\n\nThis information is supplementary, but it’s something we’ll use frequently later on, so it’s worth learning how to work with it now.\n\nBy doing so, you’ll be better prepared to handle more significant tasks when we work on actual production-ready code.\n\n** This is sample practice code. It will be improved later when we learn about better, advanced tools for the tasks.","type":"content","url":"/moretools","position":1},{"hierarchy":{"lvl1":"More Tool Functions","lvl2":"Employee Database"},"type":"lvl2","url":"/moretools#employee-database","position":2},{"hierarchy":{"lvl1":"More Tool Functions","lvl2":"Employee Database"},"content":"SQLite - Employee Database, Assignment, Expense Table, ERD\n\nSQLite - Issues/Tickets status Database","type":"content","url":"/moretools#employee-database","position":3},{"hierarchy":{"lvl1":"More Tool Functions","lvl2":"FAQ Knowledge Database"},"type":"lvl2","url":"/moretools#faq-knowledge-database","position":4},{"hierarchy":{"lvl1":"More Tool Functions","lvl2":"FAQ Knowledge Database"},"content":"ChromaDB RAG of Employee HR Policy\n\nPDF, Job aids, videos, audios, meeting notes\n\nChromaDB RAG of FAQ, Ticket, resolution","type":"content","url":"/moretools#faq-knowledge-database","position":5},{"hierarchy":{"lvl1":"More Tool Functions","lvl2":"Website Crawlers"},"type":"lvl2","url":"/moretools#website-crawlers","position":6},{"hierarchy":{"lvl1":"More Tool Functions","lvl2":"Website Crawlers"},"content":"Company website crawlers\n\nWarning\n\nMany modern websites block web crawlers. To bypass this, tools like Microsoft Omniparser or OpenAI Operator use screenshots to extract information from static sites. Before using these methods, ensure you have the right code and proper approval. Crawling company documents without permission can lead to legal issues.","type":"content","url":"/moretools#website-crawlers","position":7},{"hierarchy":{"lvl1":"More Tool Functions","lvl2":"Face Recognition : FAISS Vector Datastore"},"type":"lvl2","url":"/moretools#face-recognition-faiss-vector-datastore","position":8},{"hierarchy":{"lvl1":"More Tool Functions","lvl2":"Face Recognition : FAISS Vector Datastore"},"content":"FAISS Vector Index - Employee Image database\n\nWarning\n\nSaving employee pictures, addresses, and other biometric information is sensitive. Ensure you comply with all legal requirements before using and storing this data.","type":"content","url":"/moretools#face-recognition-faiss-vector-datastore","position":9},{"hierarchy":{"lvl1":"More Tool Functions","lvl2":"Multiple Tools"},"type":"lvl2","url":"/moretools#multiple-tools","position":10},{"hierarchy":{"lvl1":"More Tool Functions","lvl2":"Multiple Tools"},"content":"","type":"content","url":"/moretools#multiple-tools","position":11},{"hierarchy":{"lvl1":"More Use Cases"},"type":"lvl1","url":"/moreusecases","position":0},{"hierarchy":{"lvl1":"More Use Cases"},"content":"","type":"content","url":"/moreusecases","position":1},{"hierarchy":{"lvl1":"More Use Cases","lvl2":"Open AI Operator"},"type":"lvl2","url":"/moreusecases#open-ai-operator","position":2},{"hierarchy":{"lvl1":"More Use Cases","lvl2":"Open AI Operator"},"content":"OpenAI’s Operator is a single AI agent called the Computer-Using Agent (CUA) that uses vision and reasoning to do tasks on the web, like a human would. It works alone in a virtual browser, handling everything from start to finish without needing other agents. Unlike multi-agent systems, it’s one AI built to manage it all simply and smoothly.","type":"content","url":"/moreusecases#open-ai-operator","position":3},{"hierarchy":{"lvl1":"More Use Cases","lvl2":"Microsoft OmniParser"},"type":"lvl2","url":"/moreusecases#microsoft-omniparser","position":4},{"hierarchy":{"lvl1":"More Use Cases","lvl2":"Microsoft OmniParser"},"content":"Microsoft’s OmniParser is another AI agent framework designed to enhance graphical user interface (GUI) interaction by converting screenshots into structured data that AI models can understand and act upon. It operates as a unified system, using a detection model to identify interactive elements like buttons and icons, and a captioning model to describe their functions, all within a single agent powered by vision and language capabilities. This allows it to autonomously navigate and perform tasks across various platforms, making it a streamlined, standalone tool rather than a multi-agent setup.","type":"content","url":"/moreusecases#microsoft-omniparser","position":5},{"hierarchy":{"lvl1":"More Use Cases","lvl2":"Grok DeepSearch"},"type":"lvl2","url":"/moreusecases#grok-deepsearch","position":6},{"hierarchy":{"lvl1":"More Use Cases","lvl2":"Grok DeepSearch"},"content":"Grok’s DeepSearch feature, part of the Grok 3 model developed by xAI, functions like an AI agent. It autonomously searches the web, gathers real-time data, and synthesizes information to provide detailed, reasoned responses—mimicking the capabilities of an intelligent research assistant. Unlike traditional AI models that rely solely on pre-trained data, DeepSearch actively browses and processes current information, making it agent-like in its ability to perform tasks independently and adaptively.","type":"content","url":"/moreusecases#grok-deepsearch","position":7},{"hierarchy":{"lvl1":"More Use Cases","lvl2":"Real life use cases"},"type":"lvl2","url":"/moreusecases#real-life-use-cases","position":8},{"hierarchy":{"lvl1":"More Use Cases","lvl2":"Real life use cases"},"content":"","type":"content","url":"/moreusecases#real-life-use-cases","position":9},{"hierarchy":{"lvl1":"More Use Cases","lvl3":"Monitoring Production Quality in a Factory","lvl2":"Real life use cases"},"type":"lvl3","url":"/moreusecases#monitoring-production-quality-in-a-factory","position":10},{"hierarchy":{"lvl1":"More Use Cases","lvl3":"Monitoring Production Quality in a Factory","lvl2":"Real life use cases"},"content":"In a bustling factory, an industrial-grade visual AI agent ensures that every product rolling off the assembly line meets rigorous quality standards. High-resolution cameras capture real-time images of items—such as car parts or electronics—as they travel along the conveyor belt. Trained on extensive datasets featuring both perfect products and defective ones (like misaligned screws or scratched surfaces), the AI leverages advanced computer vision and machine learning to detect flaws instantly. By analyzing these images continuously, the system flags faulty items for removal, guaranteeing that only top-quality goods move forward. Regular updates with fresh data keep the AI adaptable, allowing it to identify new types of defects and uphold exceptional production standards.flowchart TD\n    A[Product on conveyor belt]:::start --> B[Capture images with high-resolution cameras]:::process\n    B --> C[Analyze images using computer vision and machine learning]:::process\n    C --> D{Quality check: Does the product pass?}:::decision\n    D -->|Pass| G[Product proceeds]:::pass\n    D -->|Fail| E[Flag for removal]:::fail\n    E --> F[Remove product]:::fail\n    H[Collect new datasets]:::update -.-> I[Retrain and update AI model]:::update\n    I -.-> C","type":"content","url":"/moreusecases#monitoring-production-quality-in-a-factory","position":11},{"hierarchy":{"lvl1":"More Use Cases","lvl3":"Monitoring Hazards in Traffic","lvl2":"Real life use cases"},"type":"lvl3","url":"/moreusecases#monitoring-hazards-in-traffic","position":12},{"hierarchy":{"lvl1":"More Use Cases","lvl3":"Monitoring Hazards in Traffic","lvl2":"Real life use cases"},"content":"On busy roads, an industrial-grade visual AI agent enhances safety by vigilantly monitoring for potential hazards. Cameras mounted on vehicles or positioned along roadways capture real-time footage of the traffic environment. The AI, trained on vast datasets that include normal driving scenarios and dangerous situations—such as swerving vehicles or jaywalking pedestrians—employs sophisticated computer vision and machine learning to spot risks as they emerge. Upon detecting a hazard, the system promptly alerts drivers or traffic management systems, aiding in accident prevention. Continuous learning from new data ensures the AI remains effective, adapting to evolving risks and contributing to safer roads for all.flowchart TD\n    A[Capture Footage]:::monitor --> B[Analyze Footage with AI]:::monitor\n    B --> C{Hazard Detected?}:::decision\n    C -->|Yes| D[Issue Alert]:::alert\n    D --> A\n    C -->|No| A\n    E[Collect New Data]:::learn --> F[Retrain AI Model]:::learn\n    F -.-> B","type":"content","url":"/moreusecases#monitoring-hazards-in-traffic","position":13},{"hierarchy":{"lvl1":"Runtime"},"type":"lvl1","url":"/runtime","position":0},{"hierarchy":{"lvl1":"Runtime"},"content":"","type":"content","url":"/runtime","position":1},{"hierarchy":{"lvl1":"Runtime","lvl2":"what is Runtime environment"},"type":"lvl2","url":"/runtime#what-is-runtime-environment","position":2},{"hierarchy":{"lvl1":"Runtime","lvl2":"what is Runtime environment"},"content":"In essence, think of a framework is a set of tools that supports a programming environment, often designed to solve business use cases or complete specific tasks.\n\nWithin this environment, we create a runtime environment —a setup that allows a program to run and supports one or more AI agent actor models.\n\nThese agents manage their own memory, state, and properties, and they interact with themselves, other agents, and external systems using messaging protocols.flowchart TD\n    subgraph AI_Agent1[AI Agent 1]\n        direction TB\n        State1[State]\n    end\n\n    subgraph AI_Agent2[AI Agent 2]\n        direction TB\n        State2[State]\n    end\n\n    RunTime[RunTime] -->|Perception: messages, sensor inputs| AI_Agent1\n    RunTime[RunTime] -->|Perception: messages, sensor inputs| AI_Agent2\n    AI_Agent1 -->|Actions: update state, send messages, execute code, interact with systems | RunTime\n    AI_Agent2 -->|Actions: update state, send messages, execute code, interact with systems | RunTime\n\n    style AI_Agent1 fill:#99FF33,stroke:#007BFF,stroke-width:2px\n    style AI_Agent2 fill:#99FF33,stroke:#007BFF,stroke-width:2px\n    style State1 fill:#FFFFFF,stroke:#007BFF,stroke-width:1px\n    style State2 fill:#FFFFFF,stroke:#007BFF,stroke-width:1px\n    style RunTime fill:#E6FFE6,stroke:#00CC00,stroke-width:2px\n\nNow, since we have already created Agents, first step is to attach these AI Agents to this run time environment.\nWe call this process of attaching these AI Agents to a run time environment as registering Agents.\n\nThis is similar to invoking an AI Agent class object, however with the difference that, registering an AI Agent to one run environment makes is available for initializing anytime AI Agent is needed.\n\nin other words, what it means is, just like when an create an Object of a class, i.e. instantiate a class object, you can call upon methods to update state of this object.\nHere registering an AI Agent (which is an Actor model) to a run time environment has similar effect as initialization except the fact that,\nrun time environment doesn’t actually invoke this Agent unless a message is called upon this Agent actor instance.","type":"content","url":"/runtime#what-is-runtime-environment","position":3},{"hierarchy":{"lvl1":"Runtime","lvl2":"new Runtime environment"},"type":"lvl2","url":"/runtime#new-runtime-environment","position":4},{"hierarchy":{"lvl1":"Runtime","lvl2":"new Runtime environment"},"content":"from autogen_core import SingleThreadedAgentRuntime\n\n# create a standalong single thread runtime\nruntime = SingleThreadedAgentRuntime()\n\nprint(PTOAgent.register().__doc__)\nRoutedAgent.__dict__\n\nSee Also\n\nresult","type":"content","url":"/runtime#new-runtime-environment","position":5},{"hierarchy":{"lvl1":"Runtime","lvl2":"Running the Single-Threaded Agent Runtime"},"type":"lvl2","url":"/runtime#running-the-single-threaded-agent-runtime","position":6},{"hierarchy":{"lvl1":"Runtime","lvl2":"Running the Single-Threaded Agent Runtime"},"content":"runtime.start()\n# ... Send messages, publish messages, etc.\nawait runtime.stop()  # This will return immediately but will not cancel\n# any in-progress message handling.\n\nruntime.start()\n# ... Send messages, publish messages, etc.\nawait runtime.stop_when_idle()  # This will block until the runtime is idle.\n\nawait runtime.close()","type":"content","url":"/runtime#running-the-single-threaded-agent-runtime","position":7},{"hierarchy":{"lvl1":"Important Security Notice"},"type":"lvl1","url":"/security","position":0},{"hierarchy":{"lvl1":"Important Security Notice"},"content":"Setting up AI Agents security for your organization is crucial. When implementing AI Agents, consider all aspects, including Docker, Kubernetes, LLM Models, Prompt Logs, API access, Telemetry data, RAG database, web crawlers, single sign-on, authentication, authorization, and cybersecurity etc..\n\nA small mistake can cause huge problems.\n\nYou’re permitting AI agents to access sensitive information, read, write, and interpret private data, as well as execute code. If not configured properly, this could end up causing more harm to your organization than good.","type":"content","url":"/security","position":1},{"hierarchy":{"lvl1":"Important Security Notice","lvl2":"Disclaimer"},"type":"lvl2","url":"/security#disclaimer","position":2},{"hierarchy":{"lvl1":"Important Security Notice","lvl2":"Disclaimer"},"content":"Writing AI Agents is hard, it’s not an easy ride, I will do many mistakes and so will you.\nPardon, refactor and move on.\n\nIn this book, I’ll start by writing some terrible code and then fix it gradually as I learn more about how to use the framework.\n\nPardon, refactor and move on.","type":"content","url":"/security#disclaimer","position":3},{"hierarchy":{"lvl1":"Table of Contents"},"type":"lvl1","url":"/toc","position":0},{"hierarchy":{"lvl1":"Table of Contents"},"content":"\n\nIntroduction\n\nTable of Contents\n\nImportant Security Notice\n\nWhy AutoGen\n\nAutoGen vs Semantics Kernel\n\nUse cases\n\nMore Use Cases\n\nUnderstanding LLM","type":"content","url":"/toc","position":1},{"hierarchy":{"lvl1":"Tool Functions"},"type":"lvl1","url":"/tools","position":0},{"hierarchy":{"lvl1":"Tool Functions"},"content":"LLMs are really very powerful, let’s run a simple example and ask a question.\n\nHow is the weather in Los Angeles, CA today?\n\nimport ollama\n\nresponse = ollama.chat(\n        model='llama3.2',\n        messages=[{'role': 'user', 'content': \n            'How is the weather in Los Angeles, CA today?'}]\n    )\n\nprint(f\"Content: {response[\"message\"][\"content\"]}\")\n\nresult\n\nContent: I’m a large language model, I don’t have real-time access to current weather conditions. However, I can suggest some ways for you to find out the current weather in Los Angeles, CA:\n\nCheck online weather websites: You can check websites like AccuWeather, \n\nWeather.com, or the National Weather Service (NWS) for up-to-date weather forecasts and conditions.\n\nUse a mobile app: You can download a weather app on your smartphone, such as Dark Sky or Weather Underground, to get current weather conditions and forecasts.\n\nTune into local news: Watch local news channels or listen to radio stations to get the latest weather updates.\n\nPlease note that Los Angeles is a large city with varied weather conditions depending on the location and time of day. The city’s climate can range from sunny and mild in some areas to cooler and cloudier in others.\n\nIf you provide me with a specific date or time, I can try to give you an estimate of the typical weather conditions in Los Angeles for that particular day.\n\nWhat you just saw that even though LLMs are really strong, but they can’t answer questions about things happening in real time or to some information they don’t have access to.\n\nWhat if we gave them extra info to help them get live, up-to-date details? With this real-time info, they could answer those questions.import ollama\n\nresponse = ollama.chat(\n        model='llama3.2',\n        messages=[{'role': 'user', 'content': \n            \"\"\"How is the weather in Los Angeles, CA today?\n            BTW, here is some extra information to help you.\n            I am using a tool like function,\n            this function can access and API and as per API, \n            current weather in Los Angeles is 74 degrees.\"\"\"}],\n    )\n\nprint(f\"Content: {response[\"message\"][\"content\"]}\")\n\nresultContent: Thank you for the extra information! \nSince we're simulating an API call, I'll use that data to provide an answer.\n\nAccording to our simulated API call, the current temperature in Los Angeles, CA\n is indeed 74°F (23°C). However, without knowing the specific date \n or time of year, it's difficult to determine what type of weather \n LA is experiencing today. Was it a sunny day with clear skies, \n or was there any precipitation? Without more information,\n I can only provide the temperature data.\n\nIf you'd like to simulate more weather conditions \nor add additional details, feel free to share!\n\nNotice, that how simple extra information using tools provided to LLMs can really overcome this issue of not able to answer real time or domain/subject specific questions.\n\nWe call these helpers “Tools.” Let’s make a simple tool function and see how it works.","type":"content","url":"/tools","position":1},{"hierarchy":{"lvl1":"Tool Functions","lvl2":"Write Tool Functions"},"type":"lvl2","url":"/tools#write-tool-functions","position":2},{"hierarchy":{"lvl1":"Tool Functions","lvl2":"Write Tool Functions"},"content":"import requests\n\ndef get_current_weather(location):\n  # https://api.weather.gov/gridpoints/TOP/32,81/forecast\n  # The API endpoint\n  url = \"https://api.weather.gov/gridpoints/TOP/32,81/forecast\"\n  response = requests.get(url)\n  return f\"\"\"The current temperature in {location} is\n         {response.json()[\"properties\"][\"periods\"][0][\"temperature\"]} \n         degrees Fahrenheit.\"\"\"\n\nget_current_weather(\"Los Angeles, CA\")\n\nresultThe current temperature in Los Angeles, CA is 77 degrees Fahrenheit.\n\nI defined a function that makes an API call to fetch the temperature of a given city. However, we need to pass a dynamic parameter to this function, which should come from a user prompt.\n\nTo achieve this, we will create a tools data structure supported by the LLM framework. This structure will interpret the user prompt as a dynamic parameter, which can then be passed to the weather API function.tools = [{\n      'type': 'function',\n      'function': {\n        'name': 'get_current_weather',\n        'description': 'Get the current weather for a location',\n        'parameters': {\n          'type': 'object',\n          'properties': {\n            'location': {\n              'type': 'string',\n              'description': 'The name of the location',\n            },\n          },\n          'required': ['location'],\n        },\n      },\n    }\n  ]\n\nTools are simply a list of Python functions that can access APIs or perform other tasks to provide meaningful information. Let’s pass this tool function to ollama.chat.\n\nWhen we say that LLM model frameworks support tools functions— which most advanced LLM models do, it means that when we pass tools=tools, the model can use these functions to enhance its responses.import ollama\n\nresponse = ollama.chat(\n        model='llama3.2',\n        messages=[{'role': 'user', 'content': \n            \"\"\"How is the weather in Los Angeles, CA today?\"\"\"}],\n\t\t# REFACTOR: provide a weather checking tool to the model\n        tools=tools # type: ignore\n    )\n\nprint(f\"Content: {response[\"message\"][\"content\"]}\")\n\nresultcontent:\n\nwhat happened here, our Tool function didn’t work, actually it did work. let’s print complete response object and you will there are much more hidden information packed in and you must understand these to help you make use of tools functions most.print(response){\n    \"model\": \"llama3.2\",\n    \"created_at\": \"2025-03-07T22: 37: 49.457833367Z\",\n    \"message\": {\n        \"role\": \"assistant\",\n        \"content\": \"\",\n        \"tool_calls\": [\n            {\n                \"function\": {\n                    \"name\": \"get_current_weather\",\n                    \"arguments\": {\n                        \"location\": \"Los Angeles, CA\"\n                    }\n                }\n            }\n        ]\n    },\n    \"done_reason\": \"stop\",\n    \"done\": true,\n    \"total_duration\": 17988129148,\n    \"load_duration\": 30554277,\n    \"prompt_eval_count\": 178,\n    \"prompt_eval_duration\": 9208611000,\n    \"eval_count\": 21,\n    \"eval_duration\": 8706934000\n}\n\n\nNow, let’s use the output from the tools or functions to support the LLM model and provide us with a meaningful response.\nLet’s put it altogether and simply refactor code.\n\nThis code creates a basic AI chatbot that can answer a question about the weather. It asks about the weather in Los Angeles, uses a tool to get the weather info, and then lets the AI respond with the answer. If the tool is used, it adds the weather data to the chat and gets a final reply from the AI.# Define the messages\nmessages = [{'role': 'user', 'content': 'How is the weather in Los Angeles, CA today?'}]\nprint('Prompt:', messages[0]['content'])\n\n# Define available functions\navailable_functions = {\n    'get_current_weather': get_current_weather\n}\n\n# Import required modules\nimport ollama\nfrom ollama import ChatResponse\n# !pip install munch\nfrom munch import Munch\n\n# Define the tools specification\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_current_weather\",\n            \"description\": \"Get the current weather in a given location\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\n                        \"type\": \"string\",\n                        \"description\": \"The location, e.g. Los Angeles, CA\"\n                    }\n                },\n                \"required\": [\"location\"]\n            }\n        }\n    }\n]\n\n# Call ollama.chat with the corrected tools parameter\nresponse_dict: ChatResponse = ollama.chat(\n    'llama3.2',\n    messages=messages,\n    tools=tools,\n)\n\n# Convert the dictionary to a Munch object\nresponse = Munch.fromDict(response_dict)\n\n# Process tool calls if present\nif response.message.tool_calls:\n    # There may be multiple tool calls in the response\n    for tool in response.message.tool_calls:\n        # Ensure the function is available, then call it\n        if function_to_call := available_functions.get(tool.function.name):\n            print('Calling function:', tool.function.name)\n            print('Arguments:', tool.function.arguments)\n            output = function_to_call(**tool.function.arguments)\n            print('Function output:', output)\n        else:\n            print('Function', tool.function.name, 'not found')\n\n    # Add the function response to messages for the model to use\n    messages.append(response.message)\n    messages.append({'role': 'tool', 'content': str(output), 'name': tool.function.name})\n\n    # Get final response from model with function outputs\n    final_response = ollama.chat('llama3.2', messages=messages, tools=tools)\n    print('Final response:', final_response[\"message\"][\"content\"])\nelse:\n    print('No tool calls returned from model')\n\nresultcontent:\nPrompt: How is the weather in Los Angeles, CA today?\nCalling function: get_current_weather\nArguments: Munch({'location': 'Los Angeles, CA'})\nFunction output: 77\nFinal response: According to the tool response, \nthe current temperature in Los Angeles, \nCA is 77 degrees Fahrenheit. However,\nI couldn't find any information on today's\n weather conditions in my database. \n Can you please provide more context \n or specify which source you would like me\n  to use (e.g., OpenWeatherMap, Dark Sky, etc.)?","type":"content","url":"/tools#write-tool-functions","position":3},{"hierarchy":{"lvl1":"Use Case"},"type":"lvl1","url":"/usecase","position":0},{"hierarchy":{"lvl1":"Use Case"},"content":"","type":"content","url":"/usecase","position":1},{"hierarchy":{"lvl1":"Use Case","lvl2":"PTO Request System"},"type":"lvl2","url":"/usecase#pto-request-system","position":2},{"hierarchy":{"lvl1":"Use Case","lvl2":"PTO Request System"},"content":"Let’s tackle a real-world business problem by coding a solution. An employee wants to take PTO next Thursday and Friday to enjoy a long weekend. Here’s the basic flow:\n\nAn LLM calculates the dates for next week.\n\nThe employee checks their PTO balance and submits a request.\n\nThe request goes to the manager for approval.\n\nThe manager, aware it’s a long weekend, ensures not all staff are off at once and approves based on team availability.\n\nOnce approved, the employee’s department and teammates working on the same tasks are notified.flowchart TD\n    A((Start)) --> B[Calculate dates]\n    B --> C[Check PTO balance]\n    C --> D[Submit PTO request]\n    D --> E[Manager reviews PTO request]\n    E --> F[Check team availability]\n    F --> G[Approve PTO request]\n    G --> H[Send notifications]\n    H --> I((End))\n\n    style A fill:#e0f7fa,stroke:#000\n    style B fill:#f1f8e9,stroke:#000\n    style C fill:#e0f7fa,stroke:#000\n    style D fill:#f1f8e9,stroke:#000\n    style E fill:#e0f7fa,stroke:#000\n    style F fill:#f1f8e9,stroke:#000\n    style G fill:#e0f7fa,stroke:#000\n    style H fill:#f1f8e9,stroke:#000\n    style I fill:#e0f7fa,stroke:#000\n\nThis use case skips many details and complexities for simplicity’s sake.","type":"content","url":"/usecase#pto-request-system","position":3},{"hierarchy":{"lvl1":"Use Case","lvl2":"PTO Business Process"},"type":"lvl2","url":"/usecase#pto-business-process","position":4},{"hierarchy":{"lvl1":"Use Case","lvl2":"PTO Business Process"},"content":"Imagine a system where one AI Agent retrieves and updates data in a SQL database, while another processes company internal documentation. These agents need to exchange data—sometimes directing it to a specific agent, and other times broadcasting it (e.g., a notification like “approved PTO”) for multiple agents to act upon asynchronously.graph TD\n    Agent1[AI Agent 1: SQL Ops] -- \"direct exchange\" --> Agent2[AI Agent 2: Docs Proc]\n    Agent2 -- \"direct exchange\" --> Agent1\n    Agent1 -- \"broadcast\" --> Broadcast[Broadcast Channel]\n    Agent2 -- \"broadcast\" --> Broadcast\n    Broadcast -- \"notify\" --> OtherAgents[Other Agents]\n\n    style Agent1 fill:#e0f7fa,stroke:#000\n    style Agent2 fill:#e0f7fa,stroke:#000\n    style Broadcast fill:#f1f8e9,stroke:#000\n    style OtherAgents fill:#e0f7fa,stroke:#000\n\nAs you define more agents with specialized behaviors, the system can quickly grow complex.","type":"content","url":"/usecase#pto-business-process","position":5},{"hierarchy":{"lvl1":"Use Case","lvl2":"Agent Framework Design"},"type":"lvl2","url":"/usecase#agent-framework-design","position":6},{"hierarchy":{"lvl1":"Use Case","lvl2":"Agent Framework Design"},"content":"Without a structured approach, you might end up with an unwieldy, coder-only-understood workflow resembling a full-blown SaaS product or ERP system—something you’d rather avoid reinventing, given the abundance of existing solutions.\n\nAn AI Agent framework, like AutoGen, addresses these challenges by providing a structured, reusable, and manageable way to build and scale such systems. Here’s why it makes sense:\n\nWe’ll start with a standalone implementation to keep things straightforward.","type":"content","url":"/usecase#agent-framework-design","position":7},{"hierarchy":{"lvl1":"Use Cases"},"type":"lvl1","url":"/usecases","position":0},{"hierarchy":{"lvl1":"Use Cases"},"content":"There are many ways to use AI Agents, which can help us do everyday tasks like checking the weather, writing a travel itinerary, booking a hotel, doing deep research like places to stay, things to see, calling a cab in advance, auto inventory cycle count, automated purchase ordering, paying vendors, managing helpdesk, FAQ, manage customer service tickets, auto responding to email or helpdesk tickets, reconciling data, query HR Policy, writing simple code or making a to-do list, automated browsing like OpenAI Operators. We can even write code to control things like turning on and off an electric bulb.\n\nThere are many places where Industrial grade visual AI Agents can be used to watch for early indicators of precautionary measures. These include factories, roads, and other areas where we want to make sure things are working properly. By looking at data from these places, we can learn more about what is happening. This helps us take action before anything bad happens.\n\nIn this book, I will use AI Agents to address most of these examples, but some big jobs might need extra work to transform them.\n\nBuilding sophisticated visual AI agents requires substantial computational resources, but the great news is that the core knowledge and processes remain consistent whether you’re developing a simple AI agent or a complex, industrial-grade visual AI system.\n\nIn this book, we’ll kick things off by guiding you through the creation of AI agents designed for straightforward tasks. As you gain confidence and experience, we’ll build on that foundation, expanding your skills to tackle more advanced visual AI agents.\n\nThe key here is that the principles and techniques you master early on apply across the board—think of it as establishing a strong base that supports everything you’ll do as you progress to more intricate projects.\n\nBy starting simple and scaling up, you’ll develop the expertise needed to create powerful AI agents, all while relying on the same fundamental understanding.\n\nNo matter how small or big it is, we should understand the task very well before using AI Agents to automate it.\n\nOne example is managing employee time and expenses in a company. Every big and small organization does this. If we want to make the whole process automatic, we can use AI Agents. But first, let’s take some time to document everything and learn about how the business works and then set the expected results from AI Agents.","type":"content","url":"/usecases","position":1},{"hierarchy":{"lvl1":"Use Cases","lvl2":"Automate HR"},"type":"lvl2","url":"/usecases#automate-hr","position":2},{"hierarchy":{"lvl1":"Use Cases","lvl2":"Automate HR"},"content":"Time sheets, Expense operations using 100% local open source technologies\n\nMost big companies spend a lot of time and money on helping employees manage their work hours and expenses.\n\nThis is important because it can save them a lot of money by reducing waste and fraud. However, managing this process is very time-consuming for both employees and HR departments.\n\nTo solve this problem, we’re using AI to automate the task. We’ll start with time management and then add expense tracking later because it involves receiving receipts and images.\n\nLet’s see an example of timesheet data.\n\nEmployee TimeSheet Table\n\nEmployee\n\n2023-04-01\n\n2023-04-02\n\n2023-04-03\n\nJohn\n\n8\n\n6\n\n7\n\nJane\n\n7\n\n8\n\n0\n\nBob\n\n8\n\n0\n\n5%%{init: {'gantt': {'barHeight': 30, 'barWidth': 70, 'fontSize': 32}}}%%\ngantt\n    title Employee Hours per Day\n    dateFormat YYYY-MM-DD\n    axisFormat %Y-%m-%d\n    section John\n    8 hours :2023-04-01, 1d\n    6 hours :2023-04-02, 1d\n    7 hours :2023-04-03, 1d\n    section Jane\n    7 hours :2023-04-01, 1d\n    8 hours :2023-04-02, 1d\n    0 hours :2023-04-03, 1d\n    section Bob\n    8 hours :2023-04-01, 1d\n    0 hours :2023-04-02, 1d\n    5 hours :2023-04-03, 1d","type":"content","url":"/usecases#automate-hr","position":3},{"hierarchy":{"lvl1":"Use Cases","lvl3":"Business Process","lvl2":"Automate HR"},"type":"lvl3","url":"/usecases#business-process","position":4},{"hierarchy":{"lvl1":"Use Cases","lvl3":"Business Process","lvl2":"Automate HR"},"content":"graph TD\n\n    subgraph TimeSheet Management\n\n        A[Employee has PTOs earned] --> B[Floating holidays, weekends, chaos days]\n\n        A --> C[Assigned tasks with hours]\n\n        A --> D[Leave of absence requests]\n\n        D --> E[Absence approvals]\n\n        E --> F[Time off balance, worked hours]\n\n        B --> F\n\n        C --> F\n\n        F --> G[Review time off balance]\n\n        G --> H[Update PTOs earned]\n\n        H --> A\n\n    end\n\n  \n\n    subgraph Task Management\n\n        C --> I[Task reassignment needed]\n\n        I --> J[Reassign tasks to other employees]\n\n        J --> C\n\n    end\n\n  \n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n\n    style B fill:#bbf,stroke:#333,stroke-width:2px\n\n    style C fill:#bfb,stroke:#333,stroke-width:2px\n\n    style D fill:#ff9,stroke:#333,stroke-width:2px\n\n    style E fill:#f99,stroke:#333,stroke-width:2px\n\n    style F fill:#9f9,stroke:#333,stroke-width:2px\n\n    style G fill:#99f,stroke:#333,stroke-width:2px\n\n    style H fill:#f9f,stroke:#333,stroke-width:2px\n\n    style I fill:#ff9,stroke:#333,stroke-width:2px\n\n    style J fill:#bfb,stroke:#333,stroke-width:2px\n\n    classDef PTOManagement fill:#f3f4f6,stroke:#333,stroke-width:2px\n    classDef TaskManagement fill:#e3f2fd,stroke:#333,stroke-width:2px\n    \n    class A,B,C,D,E,F,G,H,PTO Management\n    \n    class I,J,Task Management\n\nEmployee Expense Table\n\nEmployee\n\nExpense Type\n\nAmount\n\nDate\n\nAlice\n\nTravel\n\n$200\n\n2023-04-05\n\nAlice\n\nMeals\n\n$50\n\n2023-04-10\n\nBob\n\nSupplies\n\n$100\n\n2023-04-03\n\nBob\n\nOffice\n\n$75\n\n2023-04-07\n\nCharlie\n\nMeals\n\n$30\n\n2023-04-02\n\nCharlie\n\nTravel\n\n$150\n\n2023-04-08\n\nCharlie\n\nMeals\n\n$40\n\n2023-04-08gantt\n    title Employee Expense Table\n    dateFormat YYYY-MM-DD\n    \n    section Alice\n    Travel, $200 :2023-04-01, 2023-04-01\n    Meals, $50 :2023-04-05, 2023-04-05\n    \n    section Bob\n    Supplies, $100 :2023-04-07, 2023-04-07\n    Office, $75 :2023-04-12, 2023-04-12\n    \n    section Charlie\n    Meals, $30 :2023-04-15, 2023-04-15\n    Travel, $150 :2023-04-20, 2023-04-20\n    Meals, $40 :2023-04-25, 2023-04-25graph TD\n    subgraph Expense Submission\n        A[Employee incurs expense]\n        A --> B[Submit expense report]\n        B --> C[Manager reviews expense]\n        C --> D[Approve or reject expense]\n    end\n\n    subgraph Expense Processing\n        D --> E[Finance processes approved expenses]\n        E --> F[Reimburse employee]\n    end\n\n    subgraph Expense Tracking\n        F --> G[Update expense records]\n        G --> H[Generate expense reports]\n    end\n\n    style A fill:#f9f,stroke:#333,stroke-width:2px\n    style B fill:#bbf,stroke:#333,stroke-width:2px\n    style C fill:#bfb,stroke:#333,stroke-width:2px\n    style D fill:#ff9,stroke:#333,stroke-width:2px\n    style E fill:#f99,stroke:#333,stroke-width:2px\n    style F fill:#9f9,stroke:#333,stroke-width:2px\n    style G fill:#99f,stroke:#333,stroke-width:2px\n    style H fill:#f9f,stroke:#333,stroke-width:2px\n\n    classDef ExpenseSubmission fill:#f3f4f6,stroke:#333,stroke-width:2px\n    classDef ExpenseProcessing fill:#e3f2fd,stroke:#333,stroke-width:2px\n    classDef ExpenseTracking fill:#e8f5e9,stroke:#333,stroke-width:2px\n\n    class A,B,C,D ExpenseSubmission\n    class E,F ExpenseProcessing\n    class G,H ExpenseTracking\n","type":"content","url":"/usecases#business-process","position":5},{"hierarchy":{"lvl1":"Use Cases","lvl3":"AI Agents Operation Tasks","lvl2":"Automate HR"},"type":"lvl3","url":"/usecases#ai-agents-operation-tasks","position":6},{"hierarchy":{"lvl1":"Use Cases","lvl3":"AI Agents Operation Tasks","lvl2":"Automate HR"},"content":"","type":"content","url":"/usecases#ai-agents-operation-tasks","position":7},{"hierarchy":{"lvl1":"Use Cases","lvl4":"Manage Time Operations","lvl3":"AI Agents Operation Tasks","lvl2":"Automate HR"},"type":"lvl4","url":"/usecases#manage-time-operations","position":8},{"hierarchy":{"lvl1":"Use Cases","lvl4":"Manage Time Operations","lvl3":"AI Agents Operation Tasks","lvl2":"Automate HR"},"content":"auto timesheets\n\ntimesheets reminder\n\nauto fill\n\ndelayed timesheets\n\naudit timesheets\n\nask questions | chatbot\n\ntime off balance\n\ntime off request approval status\n\ntime spend analysis tools\n\nHR manager | chatbot\n\nopen time card | invite timesheets\n\nauto approval\n\nassign tasks\n\nemployee taskforce card\n\ndepartment taskforce card\n\nexception reportsgantt\n    title Manage Time Ops\n    dateFormat YYYY-MM-DD\n\n    section Auto Timesheets\n    Reminder      :2025-03-01, 5d\n    Auto Fill     :2025-03-06, 5d\n    Delayed       :2025-03-11, 5d\n    Audit         :2025-03-16, 5d\n\n    section Chatbot Queries\n    Timeoff Bal   :2025-03-01, 5d\n    Approval Stat :2025-03-06, 5d\n    Time Analysis :2025-03-11, 5d\n\n    section HR Manager\n    Open Card     :2025-03-01, 5d\n    Auto Approve  :2025-03-06, 5d\n    Assign Tasks  :2025-03-11, 5d\n    Emp Task Card :2025-03-16, 5d\n    Dept Task Card:2025-03-21, 5d\n    Exceptions    :2025","type":"content","url":"/usecases#manage-time-operations","position":9},{"hierarchy":{"lvl1":"Use Cases","lvl4":"Manage Expense Operations","lvl3":"AI Agents Operation Tasks","lvl2":"Automate HR"},"type":"lvl4","url":"/usecases#manage-expense-operations","position":10},{"hierarchy":{"lvl1":"Use Cases","lvl4":"Manage Expense Operations","lvl3":"AI Agents Operation Tasks","lvl2":"Automate HR"},"content":"auto expense fill\n\nupload receipts | fill lines\n\nask questions\n\nexpense balance\n\nexpense request approval status\n\nreminder of unfilled expense\n\nexpense analysis tools\n\nHR manager\n\nopen expense card | invite expense\n\nauto approval\n\nemployee expense reports\n\ndepartment expense card\n\nexception reports\n\nReceipt fraud, waste audit\n\nReceipt discount findergantt\n    title Manage Expense Ops\n    dateFormat YYYY-MM-DD\n\n    section Auto Fill\n    Auto Fill :2025-04-01, 5d\n\n    section Upload Receipts\n    Upload Receipts :2025-04-01, 5d\n\n    section Ask Questions\n    Exp Balance :2025-04-01, 5d\n    Approval Stat :2025-04-06, 5d\n    Unfilled Reminder :2025-04-11, 5d\n    Analysis Tools :2025-04-16, 5d\n\n    section HR Manager\n    Open Card :2025-04-01, 5d\n    Auto Approve :2025-04-06, 5d\n    Emp Reports :2025-04-11, 5d\n    Dept Card :2025-04-16, 5d\n    Exceptions :2025-04-21, 5d\n    Fraud Audit :2025-04-26, 5d\n    Discount Finder :2025-05-01, 5d","type":"content","url":"/usecases#manage-expense-operations","position":11},{"hierarchy":{"lvl1":"Why AutoGen"},"type":"lvl1","url":"/whyautogen","position":0},{"hierarchy":{"lvl1":"Why AutoGen"},"content":"why not CrewAI, Langchain, llamaindex or Swarms or any other AI Agents framework, which one you should start with?\n\nWhen I need to choose between different programming languages, frameworks, or tools, I follow a simple rule: I spend no more than 5 minutes reading the quick start guide.\nand then I pick the one that triggers me to open a code editor and start coding right away.\n\nI don’t spend time on opinions or benchmark results, they don’t inspire me to write code.\n\nWhen you first start learning how to program, most tutorials only show you basic things like making a to-do list. But if you try to build a real app that works well, you’ll realize that you need something more powerful than just shortcuts and easy-to-use tools. You can’t just use any tools to make your app work forever in production.\n\nTo write AI Agents, I need something easy to use right away and then get more powerful and flexible soon.\n\nIt should be able to grow quickly and handle many features, including:\neven driven programming, multi agent, multi tasks, multi systems working in a distributed parallel computing environment.\n\nThis tool should be like a framework rather than a programming library, not just a tool that does one thing and easy to learn. It should work well with new models, ideas and technologies that come up.\n\nSo, I’ll use AutoGen 0.4. If it doesn’t work out, I’ll change my code anyway - that’s what programmers do.","type":"content","url":"/whyautogen","position":1},{"hierarchy":{"lvl1":"Why AutoGen","lvl2":"AutoGen vs Semantics Kernel"},"type":"lvl2","url":"/whyautogen#autogen-vs-semantics-kernel","position":2},{"hierarchy":{"lvl1":"Why AutoGen","lvl2":"AutoGen vs Semantics Kernel"},"content":"First of the all, AutoGen and Semanrics Kernels aren’t competing framework and instead are complimentry.","type":"content","url":"/whyautogen#autogen-vs-semantics-kernel","position":3},{"hierarchy":{"lvl1":"Why AutoGen","lvl3":"Are They Duplicates?","lvl2":"AutoGen vs Semantics Kernel"},"type":"lvl3","url":"/whyautogen#are-they-duplicates","position":4},{"hierarchy":{"lvl1":"Why AutoGen","lvl3":"Are They Duplicates?","lvl2":"AutoGen vs Semantics Kernel"},"content":"While there might be some overlap in their capabilities (both deal with AI agents), their target audiences and goals differ:\nAutogen is for researchers and innovators prototyping cutting-edge systems.\n\nSemantic Kernel is for developers deploying stable, scalable AI solutions in production.\n\nBoth AutoGen and Semantics Kernal are Microsoft sponsored.\n\nThink of Autogen as a lab for experimentation and Semantic Kernel as the factory for implementation.\n\nMicrosoft AutoGen 0.4 is a top choice for complex use cases involving multi-agent collaboration, asynchronous workflows, and scalability, thanks to its redesigned architecture and enterprise-friendly features. However, the best framework depends on your needs:\n\nFor customization and prototyping, LangChain excels.\n\nFor role-based teamwork, CrewAI is unmatched.\n\nFor enterprise integration, Semantic Kernel shines.\n\nFor data-centric tasks, LlamaIndex is the go-to.","type":"content","url":"/whyautogen#are-they-duplicates","position":5},{"hierarchy":{"lvl1":"Agents of AI"},"type":"lvl1","url":"/intro","position":0},{"hierarchy":{"lvl1":"Agents of AI"},"content":"~ Hack the Core : AutoGen 0.4 Unleashed\n\nAuthor: Amit Shukla\n\nx.com/@ashuklax\n\nlicense\n\nWelcome to my Agents of AI book, This book will teach you to code with Microsoft AutoGen 0.4 to automate boring tasks.\n\nThese AI agents can tackle the repetitive, tiring chores you hate, as well as tasks which require fact-based smart decision making, freeing you up fast.\n\nThis starter book is free. If you’d like to help fund intermediate and advanced versions, please consider buying a copy, subscribing to my \n\nYouTube channel, following me at \n\nX & \n\nGitHub.","type":"content","url":"/intro","position":1}]}